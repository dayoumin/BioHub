# RAG í”ŒëŸ¬ê·¸ì¸ ì•„í‚¤í…ì²˜

**ì‘ì„±ì¼**: 2025-11-15
**ëª©ì **: ìƒˆë¡œìš´ RAG ê¸°ìˆ ì„ ì‰½ê²Œ í…ŒìŠ¤íŠ¸í•˜ê³  êµì²´í•  ìˆ˜ ìˆëŠ” í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°

---

## ğŸ¯ í•µì‹¬ ì›ì¹™

### 1. Strategy Pattern ê¸°ë°˜
- ê° RAG êµ¬ì„± ìš”ì†Œë¥¼ ë…ë¦½ì ì¸ ì „ëµìœ¼ë¡œ ë¶„ë¦¬
- ëŸ°íƒ€ì„ì— ì „ëµ êµì²´ ê°€ëŠ¥
- ì„±ëŠ¥ ë¹„êµ ë° A/B í…ŒìŠ¤íŠ¸ ì§€ì›

### 2. í”ŒëŸ¬ê·¸ì¸ ê°€ëŠ¥ ì»´í¬ë„ŒíŠ¸
```
RAG Pipeline:
  Document Loader (Docling ë“±)
    â†“
  Chunking Strategy (Semantic, Fixed, Agentic ë“±)
    â†“
  Embedding Model (Ollama, OpenAI ë“±)
    â†“
  Vector Store (SQLite, Chroma, Pinecone ë“±)
    â†“
  Retrieval Strategy (Hybrid, Vector, BM25 ë“±)
    â†“
  Reranking (LLM, Cross-Encoder ë“±)
    â†“
  Generation (Ollama, GPT-4 ë“±)
```

### 3. ì„¤ì • ê¸°ë°˜ ì „í™˜
```typescript
// config/rag-strategies.ts
export const RAG_STRATEGIES = {
  chunking: 'semantic',      // 'semantic' | 'fixed' | 'agentic'
  embedding: 'nomic',        // 'nomic' | 'openai' | 'qwen3'
  retrieval: 'hybrid',       // 'hybrid' | 'vector' | 'bm25'
  reranking: 'llm'           // 'llm' | 'cross-encoder' | 'none'
}
```

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

### Phase 1: í˜„ì¬ êµ¬ì¡° (Monolithic)

```
OllamaProvider
â”œâ”€â”€ hardcoded chunking (ë¬¸ì¥ ê²½ê³„)
â”œâ”€â”€ hardcoded embedding (Ollama)
â”œâ”€â”€ hardcoded search (Hybrid)
â””â”€â”€ hardcoded reranking (LLM)
```

**ë¬¸ì œì **:
- ìƒˆ ë°©ë²• ì¶”ê°€ ì‹œ ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • í•„ìš”
- A/B í…ŒìŠ¤íŠ¸ ì–´ë ¤ì›€
- ì„±ëŠ¥ ë¹„êµ ë¶ˆê°€ëŠ¥

---

### Phase 2: í”ŒëŸ¬ê·¸ì¸ ì•„í‚¤í…ì²˜ (ì œì•ˆ)

```typescript
// lib/rag/strategies/base-strategy.ts

export interface ChunkingStrategy {
  name: string
  chunk(document: Document): Promise<Chunk[]>
  getMetadata(): StrategyMetadata
}

export interface EmbeddingStrategy {
  name: string
  embed(text: string): Promise<number[]>
  getDimensions(): number
}

export interface RetrievalStrategy {
  name: string
  search(query: string, limit: number): Promise<SearchResult[]>
}

export interface RerankingStrategy {
  name: string
  rerank(query: string, candidates: SearchResult[], topK: number): Promise<SearchResult[]>
}
```

---

## ğŸ“¦ í”ŒëŸ¬ê·¸ì¸ êµ¬í˜„ ì˜ˆì‹œ

### 1. Chunking Strategies

#### A. Semantic Chunking (í˜„ì¬ êµ¬í˜„)
```typescript
// lib/rag/strategies/chunking/semantic-chunking.ts
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters"

export class SemanticChunkingStrategy implements ChunkingStrategy {
  name = 'semantic'

  private splitter = new RecursiveCharacterTextSplitter({
    chunkSize: 512,
    chunkOverlap: 100,
    separators: ["\n\n\n", "\n\n", "\n", ". ", " ", ""]
  })

  async chunk(document: Document): Promise<Chunk[]> {
    const texts = await this.splitter.splitText(document.content)
    return texts.map((text, i) => ({
      doc_id: `${document.doc_id}_chunk_${i}`,
      content: text,
      chunk_index: i,
      total_chunks: texts.length
    }))
  }

  getMetadata(): StrategyMetadata {
    return {
      name: 'Semantic Chunking',
      version: '1.0',
      params: { chunkSize: 512, overlap: 100 },
      paper: 'https://arxiv.org/abs/...'
    }
  }
}
```

#### B. Agentic Chunking (ì‹ ê·œ - 2025 íŠ¸ë Œë“œ)
```typescript
// lib/rag/strategies/chunking/agentic-chunking.ts
export class AgenticChunkingStrategy implements ChunkingStrategy {
  name = 'agentic'

  async chunk(document: Document): Promise<Chunk[]> {
    // LLMì´ ë¬¸ì„œ êµ¬ì¡°ë¥¼ ì´í•´í•˜ê³  ìµœì ì˜ ê²½ê³„ ê²°ì •
    const propositions = await this.llm.extractPropositions(document.content)
    return this.mergePropositions(propositions)
  }

  getMetadata(): StrategyMetadata {
    return {
      name: 'Agentic Chunking',
      version: '1.0',
      paper: 'https://github.com/anthropics/anthropic-cookbook/blob/main/skills/contextual-embeddings/guide.ipynb'
    }
  }
}
```

#### C. Docling Structure-Aware Chunking (PDFìš©)
```typescript
// lib/rag/strategies/chunking/docling-chunking.ts
import { DoclingParser } from '@docling/core'

export class DoclingChunkingStrategy implements ChunkingStrategy {
  name = 'docling'

  async chunk(document: Document): Promise<Chunk[]> {
    // Doclingì´ PDF êµ¬ì¡° ë¶„ì„ (ì œëª©, í‘œ, ê·¸ë¦¼ ë“±)
    const parsed = await DoclingParser.parse(document.pdfPath)

    // êµ¬ì¡° ê¸°ë°˜ ì²­í‚¹
    return [
      ...this.chunkSections(parsed.sections),
      ...this.chunkTables(parsed.tables),
      ...this.chunkFigures(parsed.figures)
    ]
  }

  getMetadata(): StrategyMetadata {
    return {
      name: 'Docling Structure-Aware Chunking',
      version: '1.0',
      supports: ['pdf', 'docx'],
      url: 'https://github.com/DS4SD/docling'
    }
  }
}
```

---

### 2. Reranking Strategies

#### A. LLM Reranking (í˜„ì¬ êµ¬í˜„)
```typescript
// lib/rag/strategies/reranking/llm-reranking.ts
export class LLMRerankingStrategy implements RerankingStrategy {
  name = 'llm'

  async rerank(query: string, candidates: SearchResult[], topK: number): Promise<SearchResult[]> {
    // Ollama LLMìœ¼ë¡œ ì¬ìˆœìœ„í™” (í˜„ì¬ êµ¬í˜„)
    const prompt = `ì§ˆë¬¸: ${query}\n\në‹¤ìŒ ë¬¸ì„œë“¤ì„ ê´€ë ¨ì„± ìˆœìœ¼ë¡œ ì •ë ¬...`
    const response = await this.llm.generate(prompt)
    return this.parseRanking(response, candidates, topK)
  }

  getMetadata(): StrategyMetadata {
    return {
      name: 'LLM Reranking',
      latency: '300-600ms',
      accuracy: '+50-100%'
    }
  }
}
```

#### B. Cross-Encoder Reranking (ê³ ì„±ëŠ¥)
```typescript
// lib/rag/strategies/reranking/cross-encoder-reranking.ts
export class CrossEncoderRerankingStrategy implements RerankingStrategy {
  name = 'cross-encoder'

  async rerank(query: string, candidates: SearchResult[], topK: number): Promise<SearchResult[]> {
    // Cross-Encoder ëª¨ë¸ ì‚¬ìš© (ë” ì •í™•, ë” ëŠë¦¼)
    const scores = await Promise.all(
      candidates.map(c => this.model.score(query, c.content))
    )

    return candidates
      .map((c, i) => ({ ...c, score: scores[i] }))
      .sort((a, b) => b.score - a.score)
      .slice(0, topK)
  }

  getMetadata(): StrategyMetadata {
    return {
      name: 'Cross-Encoder Reranking',
      model: 'ms-marco-MiniLM-L-12-v2',
      latency: '500-1000ms',
      accuracy: '+70-120%'
    }
  }
}
```

#### C. Cohere Rerank (API ê¸°ë°˜)
```typescript
// lib/rag/strategies/reranking/cohere-reranking.ts
export class CohereRerankingStrategy implements RerankingStrategy {
  name = 'cohere'

  async rerank(query: string, candidates: SearchResult[], topK: number): Promise<SearchResult[]> {
    // Cohere Rerank API í˜¸ì¶œ
    const response = await fetch('https://api.cohere.ai/v1/rerank', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        query,
        documents: candidates.map(c => c.content),
        top_n: topK,
        model: 'rerank-english-v2.0'
      })
    })

    const data = await response.json()
    return this.mapResults(data.results, candidates)
  }

  getMetadata(): StrategyMetadata {
    return {
      name: 'Cohere Rerank',
      latency: '200-400ms',
      accuracy: '+80-130%',
      cost: '$1/1000 searches'
    }
  }
}
```

---

## ğŸ”§ Strategy Registry íŒ¨í„´

```typescript
// lib/rag/strategies/registry.ts

class StrategyRegistry {
  private strategies = new Map<string, Map<string, any>>()

  // ì „ëµ ë“±ë¡
  register<T>(category: string, name: string, strategy: T): void {
    if (!this.strategies.has(category)) {
      this.strategies.set(category, new Map())
    }
    this.strategies.get(category)!.set(name, strategy)
  }

  // ì „ëµ ì¡°íšŒ
  get<T>(category: string, name: string): T | null {
    return this.strategies.get(category)?.get(name) ?? null
  }

  // ì¹´í…Œê³ ë¦¬ë³„ ì „ì²´ ì „ëµ ì¡°íšŒ
  getAll(category: string): Map<string, any> {
    return this.strategies.get(category) ?? new Map()
  }

  // ì „ëµ ëª©ë¡
  list(category: string): string[] {
    return Array.from(this.strategies.get(category)?.keys() ?? [])
  }
}

export const strategyRegistry = new StrategyRegistry()

// ì „ëµ ë“±ë¡
strategyRegistry.register('chunking', 'semantic', new SemanticChunkingStrategy())
strategyRegistry.register('chunking', 'agentic', new AgenticChunkingStrategy())
strategyRegistry.register('chunking', 'docling', new DoclingChunkingStrategy())

strategyRegistry.register('reranking', 'llm', new LLMRerankingStrategy())
strategyRegistry.register('reranking', 'cross-encoder', new CrossEncoderRerankingStrategy())
strategyRegistry.register('reranking', 'cohere', new CohereRerankingStrategy())
```

---

## ğŸ›ï¸ ì„¤ì • ê¸°ë°˜ ì „í™˜

```typescript
// config/rag-config.ts
export interface RAGConfig {
  chunking: {
    strategy: 'semantic' | 'agentic' | 'docling' | 'fixed'
    params?: Record<string, any>
  }
  embedding: {
    strategy: 'nomic' | 'openai' | 'qwen3'
    model: string
  }
  retrieval: {
    strategy: 'hybrid' | 'vector' | 'bm25'
    topK: number
  }
  reranking: {
    strategy: 'llm' | 'cross-encoder' | 'cohere' | 'none'
    enabled: boolean
  }
}

export const DEFAULT_CONFIG: RAGConfig = {
  chunking: {
    strategy: 'semantic',
    params: { chunkSize: 512, overlap: 100 }
  },
  embedding: {
    strategy: 'nomic',
    model: 'nomic-embed-text'
  },
  retrieval: {
    strategy: 'hybrid',
    topK: 20
  },
  reranking: {
    strategy: 'llm',
    enabled: true
  }
}
```

---

## ğŸ§ª A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬

```typescript
// lib/rag/testing/ab-test.ts

interface TestConfig {
  name: string
  config: RAGConfig
}

export class RAGABTest {
  async compare(
    queries: string[],
    configA: TestConfig,
    configB: TestConfig
  ): Promise<ComparisonResult> {
    const resultsA = await this.runQueries(queries, configA.config)
    const resultsB = await this.runQueries(queries, configB.config)

    return {
      configA: {
        name: configA.name,
        avgLatency: this.avgLatency(resultsA),
        avgRelevance: this.avgRelevance(resultsA),
        results: resultsA
      },
      configB: {
        name: configB.name,
        avgLatency: this.avgLatency(resultsB),
        avgRelevance: this.avgRelevance(resultsB),
        results: resultsB
      },
      winner: this.determineWinner(resultsA, resultsB)
    }
  }

  private async runQueries(queries: string[], config: RAGConfig): Promise<QueryResult[]> {
    const service = new RAGService(config)
    return Promise.all(queries.map(q => service.query({ query: q })))
  }
}

// ì‚¬ìš© ì˜ˆì‹œ
const test = new RAGABTest()

const result = await test.compare(
  ['t-test ì •ê·œì„± ê°€ì •', 'ANOVA ì‚¬í›„ê²€ì •', 'íšŒê·€ë¶„ì„ ê°€ì •'],
  { name: 'Current (LLM Rerank)', config: { ...DEFAULT_CONFIG, reranking: { strategy: 'llm', enabled: true } } },
  { name: 'Cohere Rerank', config: { ...DEFAULT_CONFIG, reranking: { strategy: 'cohere', enabled: true } } }
)

console.log(`Winner: ${result.winner}`)
console.log(`Latency A: ${result.configA.avgLatency}ms vs B: ${result.configB.avgLatency}ms`)
console.log(`Relevance A: ${result.configA.avgRelevance} vs B: ${result.configB.avgRelevance}`)
```

---

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì˜ˆì‹œ

```typescript
// scripts/rag/benchmark-strategies.ts

const strategies = {
  chunking: ['semantic', 'agentic', 'docling'],
  reranking: ['llm', 'cross-encoder', 'cohere', 'none']
}

const results = await benchmarkAll(strategies)

// ê²°ê³¼ ì˜ˆì‹œ:
// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
// â”‚ Strategy    â”‚ Latency  â”‚ Accuracy   â”‚ Cost     â”‚
// â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
// â”‚ LLM         â”‚ 450ms    â”‚ +70%       â”‚ Free     â”‚
// â”‚ Cross-Enc   â”‚ 750ms    â”‚ +95%       â”‚ Free     â”‚
// â”‚ Cohere      â”‚ 300ms    â”‚ +110%      â”‚ $0.001   â”‚
// â”‚ None        â”‚ 0ms      â”‚ Baseline   â”‚ Free     â”‚
// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ êµ¬í˜„ ë¡œë“œë§µ

### Phase 1: ì¸í„°í˜ì´ìŠ¤ ì •ì˜ (1ì¼)
- âœ… ChunkingStrategy, RerankingStrategy ë“± ì¸í„°í˜ì´ìŠ¤
- âœ… StrategyRegistry êµ¬í˜„

### Phase 2: í˜„ì¬ êµ¬í˜„ì„ í”ŒëŸ¬ê·¸ì¸ìœ¼ë¡œ ë³€í™˜ (2ì¼)
- âœ… SemanticChunkingStrategy
- âœ… LLMRerankingStrategy
- âœ… OllamaProviderë¥¼ Strategy ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •

### Phase 3: ìƒˆë¡œìš´ ì „ëµ ì¶”ê°€ (ì„ íƒ)
- ğŸ”œ AgenticChunkingStrategy (Anthropic Cookbook)
- ğŸ”œ DoclingChunkingStrategy (PDF êµ¬ì¡° ë¶„ì„)
- ğŸ”œ CrossEncoderRerankingStrategy
- ğŸ”œ CohereRerankingStrategy

### Phase 4: A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ (1ì¼)
- ğŸ”œ RAGABTest í´ë˜ìŠ¤
- ğŸ”œ ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸
- ğŸ”œ ê²°ê³¼ ì‹œê°í™”

---

## ğŸ¯ íŒŒì¼ íƒ€ì…ë³„ ì „ëµ ë¶„ë¦¬

**í•µì‹¬**: íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ìµœì ì˜ ì²­í‚¹ ì „ëµ ìë™ ì„ íƒ

### ì „ëµ ì„ íƒ ë¡œì§

```typescript
// lib/rag/strategies/chunking/auto-select.ts
export class AutoChunkingStrategy implements ChunkingStrategy {
  name = 'auto'

  async chunk(document: Document): Promise<Chunk[]> {
    const fileType = this.detectFileType(document)

    switch (fileType) {
      case 'pdf':
        // PDF: Doclingìœ¼ë¡œ êµ¬ì¡° ë¶„ì„
        return new DoclingChunkingStrategy().chunk(document)

      case 'md':
      case 'txt':
        // Markdown/í…ìŠ¤íŠ¸: ì‹œë§¨í‹± ì²­í‚¹
        return new SemanticChunkingStrategy().chunk(document)

      case 'docx':
        // Word: Docling (êµ¬ì¡° ë³´ì¡´)
        return new DoclingChunkingStrategy().chunk(document)

      case 'html':
        // HTML: DOM êµ¬ì¡° ê¸°ë°˜
        return new HTMLChunkingStrategy().chunk(document)

      default:
        // ê¸°ë³¸: ì‹œë§¨í‹± ì²­í‚¹
        return new SemanticChunkingStrategy().chunk(document)
    }
  }

  private detectFileType(document: Document): string {
    if (document.pdfPath?.endsWith('.pdf')) return 'pdf'
    if (document.filePath?.endsWith('.md')) return 'md'
    if (document.filePath?.endsWith('.docx')) return 'docx'
    if (document.content?.startsWith('<!DOCTYPE html')) return 'html'
    return 'txt'
  }
}
```

---

## ğŸ“„ íŒŒì¼ íƒ€ì…ë³„ ìµœì  ì „ëµ ë¹„êµ

| íŒŒì¼ íƒ€ì… | ê¶Œì¥ ì „ëµ | ì´ìœ  | ì¥ì  | ë‹¨ì  |
|----------|---------|------|------|------|
| **Markdown (.md)** | Semantic Chunking | ë‹¨ìˆœ êµ¬ì¡° | ë¹ ë¦„, íš¨ê³¼ì  | - |
| **í…ìŠ¤íŠ¸ (.txt)** | Semantic Chunking | êµ¬ì¡° ì—†ìŒ | ë¹ ë¦„ | - |
| **PDF (.pdf)** | Docling Chunking | ë³µì¡í•œ ë ˆì´ì•„ì›ƒ | í‘œ/ê·¸ë¦¼/ìˆ˜ì‹ ë³´ì¡´ | ëŠë¦¼ |
| **Word (.docx)** | Docling Chunking | êµ¬ì¡° ë³´ì¡´ í•„ìš” | ì„œì‹ ìœ ì§€ | ëŠë¦¼ |
| **HTML (.html)** | HTML Chunking | DOM êµ¬ì¡° í™œìš© | ì •í™•í•œ ì„¹ì…˜ ë¶„ë¦¬ | - |
| **Code (.py, .ts)** | Code-Aware Chunking | AST ë¶„ì„ | í•¨ìˆ˜/í´ë˜ìŠ¤ ë‹¨ìœ„ | ì–¸ì–´ë³„ íŒŒì„œ í•„ìš” |

---

## ğŸ“„ íŒŒì¼ íƒ€ì…ë³„ ìµœì  ì „ëµ

### 1. Markdown/í…ìŠ¤íŠ¸ íŒŒì¼ â†’ Semantic Chunking

**ì´ìœ **:
- âœ… êµ¬ì¡°ê°€ ë‹¨ìˆœ (ì œëª©, ë¬¸ë‹¨ë§Œ)
- âœ… RecursiveCharacterTextSplitterê°€ íš¨ê³¼ì 
- âœ… ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„

**í˜„ì¬ êµ¬í˜„**:
```typescript
// ì´ë¯¸ êµ¬í˜„ë¨: scripts/rag/semantic-rechunk.ts
chunkSize: 512
chunkOverlap: 100
separators: ["\n\n\n", "\n\n", "\n", ". ", " ", ""]
```

---

### 2. PDF íŒŒì¼ â†’ Docling Chunking

**ì´ìœ **:
- âœ… ë³µì¡í•œ êµ¬ì¡° (ì œëª©, í‘œ, ê·¸ë¦¼, ìˆ˜ì‹)
- âœ… Doclingì´ êµ¬ì¡° ë¶„ì„ ìµœê³  ì„±ëŠ¥
- âœ… í‘œ/ìˆ˜ì‹ ë³´ì¡´ í•„ìˆ˜

### Docling ì „ëµ êµ¬í˜„ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)

```typescript
// lib/rag/strategies/chunking/docling-chunking.ts
export class DoclingChunkingStrategy implements ChunkingStrategy {
  name = 'docling'

  async chunk(document: Document): Promise<Chunk[]> {
    // PDF íŒŒì¼ ê²½ë¡œ í™•ì¸
    if (!document.pdfPath) {
      throw new Error('PDF path required for Docling strategy')
    }

    // Doclingìœ¼ë¡œ PDF íŒŒì‹±
    const parsed = await this.parseWithDocling(document.pdfPath)

    // êµ¬ì¡° ê¸°ë°˜ ì²­í‚¹
    const chunks: Chunk[] = []

    // 1. ì„¹ì…˜ë³„ ì²­í‚¹
    for (const section of parsed.sections) {
      chunks.push({
        doc_id: `${document.doc_id}_section_${section.id}`,
        content: section.text,
        metadata: {
          type: 'section',
          heading: section.heading,
          level: section.level
        }
      })
    }

    // 2. í‘œ ì²­í‚¹ (í‘œëŠ” ë¶„ë¦¬í•˜ì§€ ì•ŠìŒ)
    for (const table of parsed.tables) {
      chunks.push({
        doc_id: `${document.doc_id}_table_${table.id}`,
        content: this.tableToMarkdown(table),
        metadata: {
          type: 'table',
          caption: table.caption
        }
      })
    }

    // 3. ìˆ˜ì‹ ì²­í‚¹
    for (const equation of parsed.equations) {
      chunks.push({
        doc_id: `${document.doc_id}_eq_${equation.id}`,
        content: equation.latex,
        metadata: {
          type: 'equation'
        }
      })
    }

    return chunks
  }

  private async parseWithDocling(pdfPath: string) {
    // Docling í˜¸ì¶œ (í˜„ì¬ êµ¬í˜„ ì¬ì‚¬ìš©)
    // ...
  }

  private tableToMarkdown(table: Table): string {
    // í‘œ â†’ Markdown ë³€í™˜
    // ...
  }
}
```

---

## ğŸ“– ì°¸ê³  ìë£Œ

### 2025 RAG íŠ¸ë Œë“œ
1. **Agentic Chunking**
   - https://github.com/anthropics/anthropic-cookbook/blob/main/skills/contextual-embeddings/guide.ipynb
   - LLMì´ ë¬¸ì„œ êµ¬ì¡° ì´í•´í•˜ê³  ìµœì  ê²½ê³„ ê²°ì •

2. **Contextual Retrieval**
   - https://www.anthropic.com/news/contextual-retrieval
   - ê° ì²­í¬ì— ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€

3. **Hybrid Search Evolution**
   - BM25 + Dense + Sparse Hybrid
   - https://www.pinecone.io/learn/hybrid-search-intro/

4. **Cross-Encoder Reranking**
   - https://www.sbert.net/examples/applications/cross-encoder/README.html
   - LLMë³´ë‹¤ ë¹ ë¥´ê³  ì •í™•

5. **Docling (IBM Research)**
   - https://github.com/DS4SD/docling
   - PDF êµ¬ì¡° ë¶„ì„ ìµœê³  ì„±ëŠ¥

---

## âœ… ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì‘ì—…

### 1. Docling Strategy êµ¬í˜„ (ìš°ì„ )
```bash
npm install @docling/core
```

### 2. Cross-Encoder Reranking (ë¬´ë£Œ, ê³ ì„±ëŠ¥)
```bash
npm install @xenova/transformers
```

### 3. A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬
- í˜„ì¬ LLM Reranking vs Cross-Encoder ë¹„êµ
- ê²°ê³¼ë¥¼ í‘œë¡œ ì¶œë ¥

---

**ë‹¤ìŒ ë‹¨ê³„**: ì–´ë–¤ ì „ëµë¶€í„° êµ¬í˜„í• ê¹Œìš”?
1. Docling ì²­í‚¹ ì „ëµ (PDF ëŒ€ë¹„)
2. Cross-Encoder Reranking (ì„±ëŠ¥ ê°œì„ )
3. A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ (ë¹„êµ ë„êµ¬)
