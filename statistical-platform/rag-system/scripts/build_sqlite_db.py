"""
SQLite DB ë¹Œë” ìŠ¤í¬ë¦½íŠ¸

í¬ë¡¤ë§ëœ 101ê°œ ë¬¸ì„œë¥¼ SQLite DBë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

ì‹¤í–‰:
    cd statistical-platform/rag-system
    python scripts/build_sqlite_db.py

ì¶œë ¥:
    data/rag.db (SQLite ë°ì´í„°ë² ì´ìŠ¤)
"""

import os
import sys
import sqlite3
import json
import time
from pathlib import Path
from typing import List, Dict, Optional
import hashlib

# Windows ì½˜ì†” UTF-8 ì¶œë ¥ ê°•ì œ
if sys.platform == "win32":
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# ì„¤ì •
SCRIPT_DIR = Path(__file__).parent
RAG_SYSTEM_DIR = SCRIPT_DIR.parent
DATA_DIR = RAG_SYSTEM_DIR / "data"
DB_PATH = DATA_DIR / "rag.db"
SCHEMA_PATH = RAG_SYSTEM_DIR / "schema.sql"

# ë¬¸ì„œ ë””ë ‰í† ë¦¬
DOC_DIRS = {
    "scipy": DATA_DIR / "scipy",
    "numpy": DATA_DIR / "numpy",
    "statsmodels": DATA_DIR / "statsmodels",
    "pingouin": DATA_DIR / "pingouin",
    "project": DATA_DIR / "project",
    "methodology": DATA_DIR / "methodology-guide",
    "openintro": DATA_DIR / "openintro"
}


def create_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ë° ìŠ¤í‚¤ë§ˆ ì ìš©"""
    print(f"[1/4] ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±: {DB_PATH}")

    # ê¸°ì¡´ DB ì‚­ì œ (ì¬êµ¬ì¶•)
    if DB_PATH.exists():
        DB_PATH.unlink()
        print("  - ê¸°ì¡´ DB ì‚­ì œë¨")

    # ìŠ¤í‚¤ë§ˆ ì ìš©
    with open(SCHEMA_PATH, 'r', encoding='utf-8') as f:
        schema_sql = f.read()

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.executescript(schema_sql)
    conn.commit()
    conn.close()

    print("  - ìŠ¤í‚¤ë§ˆ ì ìš© ì™„ë£Œ")


def generate_doc_id(library: str, filename: str) -> str:
    """ë¬¸ì„œ ID ìƒì„± (ì˜ˆ: scipy_ttest_ind)"""
    # íŒŒì¼ëª…ì—ì„œ .md ì œê±°
    name = filename.replace('.md', '')
    # íŠ¹ìˆ˜ ë¬¸ì ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
    name = name.replace('-', '_').replace('.', '_').lower()
    return f"{library}_{name}"


def extract_title_from_content(content: str, filename: str) -> str:
    """Markdownì—ì„œ ì œëª© ì¶”ì¶œ"""
    lines = content.split('\n')

    # ì²« ë²ˆì§¸ # í—¤ë” ì°¾ê¸°
    for line in lines:
        if line.startswith('# '):
            return line.replace('# ', '').strip()

    # ì œëª©ì´ ì—†ìœ¼ë©´ íŒŒì¼ëª… ì‚¬ìš©
    return filename.replace('.md', '').replace('_', ' ').replace('-', ' ').title()


def extract_summary(content: str, max_length: int = 200) -> str:
    """ìš”ì•½ ìƒì„± (ì²« 200ì)"""
    # Markdown í—¤ë” ì œê±°
    lines = [line for line in content.split('\n') if not line.startswith('#')]
    text = ' '.join(lines).strip()

    # ì²« 200ì ì¶”ì¶œ
    if len(text) > max_length:
        return text[:max_length] + '...'
    return text


def categorize_document(library: str, doc_id: str, content: str) -> Optional[str]:
    """ë¬¸ì„œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
    # í”„ë¡œì íŠ¸ ë¬¸ì„œëŠ” íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ
    if library == "project":
        if "worker1" in doc_id:
            return "descriptive"
        elif "worker2" in doc_id:
            return "hypothesis"
        elif "worker3" in doc_id:
            return "nonparametric_anova"
        elif "worker4" in doc_id:
            return "regression_advanced"
        elif "statistical_methods" in doc_id:
            return "overview"

    # ë°©ë²•ë¡  ê°€ì´ë“œ
    if library == "methodology":
        if "decision" in doc_id or "tree" in doc_id:
            return "guide_method_selection"
        elif "assumption" in doc_id:
            return "guide_assumptions"
        elif "interpretation" in doc_id:
            return "guide_interpretation"
        elif "comparison" in doc_id:
            return "guide_comparison"

    # SciPy/NumPy: í•¨ìˆ˜ëª…ìœ¼ë¡œ ì¶”ì •
    content_lower = content.lower()
    if any(word in content_lower for word in ["test", "ê²€ì •", "hypothesis"]):
        return "hypothesis"
    elif any(word in content_lower for word in ["regression", "íšŒê·€"]):
        return "regression"
    elif any(word in content_lower for word in ["correlation", "ìƒê´€"]):
        return "correlation"
    elif any(word in content_lower for word in ["anova", "ë¶„ì‚°"]):
        return "anova"
    elif any(word in content_lower for word in ["mean", "median", "std", "var"]):
        return "descriptive"

    return None


def count_words(text: str) -> int:
    """ë‹¨ì–´ ìˆ˜ ê³„ì‚°"""
    # ê³µë°± ê¸°ì¤€ ë¶„ë¦¬ (ê°„ë‹¨í•œ ë°©ë²•)
    return len(text.split())


def load_documents() -> List[Dict]:
    """ëª¨ë“  ë¬¸ì„œ ë¡œë“œ"""
    print(f"[2/4] ë¬¸ì„œ ë¡œë“œ ì¤‘...")

    documents = []
    current_time = int(time.time())

    for library, doc_dir in DOC_DIRS.items():
        if not doc_dir.exists():
            print(f"  - {library}: ë””ë ‰í† ë¦¬ ì—†ìŒ (ìŠ¤í‚µ)")
            continue

        md_files = list(doc_dir.glob("*.md"))
        print(f"  - {library}: {len(md_files)}ê°œ íŒŒì¼")

        for md_file in md_files:
            try:
                # íŒŒì¼ ì½ê¸°
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # ë¬¸ì„œ ID ìƒì„±
                doc_id = generate_doc_id(library, md_file.name)

                # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                title = extract_title_from_content(content, md_file.name)
                summary = extract_summary(content)
                category = categorize_document(library, doc_id, content)
                word_count = count_words(content)

                # ë¬¸ì„œ ê°ì²´ ìƒì„±
                doc = {
                    "doc_id": doc_id,
                    "title": title,
                    "library": library,
                    "category": category,
                    "content": content,
                    "summary": summary,
                    "source_url": None,  # í¬ë¡¤ë§ ë¡œê·¸ì—ì„œ ì¶”ì¶œ ê°€ëŠ¥
                    "source_file": str(md_file.relative_to(RAG_SYSTEM_DIR)),
                    "created_at": current_time,
                    "updated_at": current_time,
                    "word_count": word_count
                }

                documents.append(doc)

            except Exception as e:
                print(f"  âš ï¸ ì—ëŸ¬ ({md_file.name}): {e}")

    print(f"  âœ“ ì´ {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
    return documents


def insert_documents(documents: List[Dict]):
    """ë¬¸ì„œë¥¼ DBì— ì‚½ì…"""
    print(f"[3/4] ë¬¸ì„œ DB ì‚½ì… ì¤‘...")

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    for doc in documents:
        cursor.execute("""
            INSERT INTO documents (
                doc_id, title, library, category,
                content, summary,
                source_url, source_file,
                created_at, updated_at, word_count
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            doc["doc_id"],
            doc["title"],
            doc["library"],
            doc["category"],
            doc["content"],
            doc["summary"],
            doc["source_url"],
            doc["source_file"],
            doc["created_at"],
            doc["updated_at"],
            doc["word_count"]
        ))

    conn.commit()
    conn.close()

    print(f"  âœ“ {len(documents)}ê°œ ë¬¸ì„œ ì‚½ì… ì™„ë£Œ")


def generate_statistics():
    """DB í†µê³„ ìƒì„±"""
    print(f"[4/4] DB í†µê³„ ìƒì„± ì¤‘...")

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # ë¼ì´ë¸ŒëŸ¬ë¦¬ë³„ í†µê³„
    cursor.execute("""
        SELECT library, COUNT(*) as count, SUM(word_count) as total_words
        FROM documents
        GROUP BY library
    """)

    print("\nğŸ“Š ë¬¸ì„œ í†µê³„:")
    print("-" * 50)
    for row in cursor.fetchall():
        library, count, total_words = row
        print(f"  {library:15} | {count:3}ê°œ | {total_words:,}ì")

    # ì „ì²´ í†µê³„
    cursor.execute("SELECT COUNT(*), SUM(word_count) FROM documents")
    total_docs, total_words = cursor.fetchone()
    print("-" * 50)
    print(f"  {'TOTAL':15} | {total_docs:3}ê°œ | {total_words:,}ì")

    # FTS í…Œì´ë¸” í™•ì¸
    cursor.execute("SELECT COUNT(*) FROM documents_fts")
    fts_count = cursor.fetchone()[0]
    print(f"\nâœ“ FTS ì¸ë±ìŠ¤: {fts_count}ê°œ ë¬¸ì„œ")

    # DB íŒŒì¼ í¬ê¸°
    db_size = DB_PATH.stat().st_size / (1024 * 1024)  # MB
    print(f"âœ“ DB í¬ê¸°: {db_size:.2f} MB")

    conn.close()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 50)
    print("RAG System - SQLite DB Builder")
    print("=" * 50)
    print()

    try:
        # 1. DB ìƒì„±
        create_database()

        # 2. ë¬¸ì„œ ë¡œë“œ
        documents = load_documents()

        # 3. DB ì‚½ì…
        insert_documents(documents)

        # 4. í†µê³„ ìƒì„±
        generate_statistics()

        print()
        print("=" * 50)
        print("âœ… DB ë¹Œë“œ ì™„ë£Œ!")
        print(f"   ìœ„ì¹˜: {DB_PATH}")
        print("=" * 50)

    except Exception as e:
        print(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        exit(1)


if __name__ == "__main__":
    main()
