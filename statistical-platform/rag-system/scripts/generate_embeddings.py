#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ë²¡í„° ì„ë² ë”© ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (Ollama)

SQLite DBì˜ ë¬¸ì„œë“¤ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ê³  Ollamaë¡œ ì„ë² ë”© ìƒì„±
embeddings í…Œì´ë¸”ì— ì €ì¥

ì‹¤í–‰:
    cd statistical-platform/rag-system
    python scripts/generate_embeddings.py
"""

import sys
import io
import sqlite3
import json
import time
from pathlib import Path
from typing import List, Dict
import requests

# Windows UTF-8 encoding fix
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ì„¤ì •
SCRIPT_DIR = Path(__file__).parent
RAG_SYSTEM_DIR = SCRIPT_DIR.parent
DATA_DIR = RAG_SYSTEM_DIR / "data"
DB_PATH = DATA_DIR / "rag.db"

OLLAMA_ENDPOINT = "http://localhost:11434"
EMBEDDING_MODEL = "nomic-embed-text"  # ê¸°ë³¸ ì„ë² ë”© ëª¨ë¸
CHUNK_SIZE = 500  # í† í° ìˆ˜ (ëŒ€ëµ 500 ë‹¨ì–´)
CHUNK_OVERLAP = 50  # ê²¹ì¹¨ í† í° ìˆ˜


def check_ollama_server():
    """Ollama ì„œë²„ ì—°ê²° í™•ì¸"""
    try:
        response = requests.get(f"{OLLAMA_ENDPOINT}/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            model_names = [m['name'] for m in models]
            print(f"âœ“ Ollama ì„œë²„ ì—°ê²° ì„±ê³µ ({len(models)}ê°œ ëª¨ë¸)")

            # ì„ë² ë”© ëª¨ë¸ í™•ì¸
            if EMBEDDING_MODEL in model_names:
                print(f"âœ“ ì„ë² ë”© ëª¨ë¸ '{EMBEDDING_MODEL}' ì‚¬ìš© ê°€ëŠ¥")
                return True
            else:
                print(f"âš ï¸ ì„ë² ë”© ëª¨ë¸ '{EMBEDDING_MODEL}' ì—†ìŒ")
                print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {', '.join(model_names)}")
                print(f"\n   ë‹¤ìš´ë¡œë“œ: ollama pull {EMBEDDING_MODEL}")
                return False
        else:
            print(f"âŒ Ollama ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print(f"âŒ Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {OLLAMA_ENDPOINT}")
        print("   ì„œë²„ ì‹œì‘: ollama serve")
        return False
    except Exception as e:
        print(f"âŒ Ollama ì„œë²„ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


def chunk_text(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP) -> List[str]:
    """
    í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸° (ë‹¨ì–´ ê¸°ì¤€)

    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        chunk_size: ì²­í¬ í¬ê¸° (ë‹¨ì–´ ìˆ˜)
        overlap: ê²¹ì¹¨ í¬ê¸° (ë‹¨ì–´ ìˆ˜)

    Returns:
        List[str]: ì²­í¬ ë¦¬ìŠ¤íŠ¸
    """
    words = text.split()
    chunks = []

    start = 0
    while start < len(words):
        end = start + chunk_size
        chunk = ' '.join(words[start:end])
        chunks.append(chunk)

        # ë‹¤ìŒ ì²­í¬ ì‹œì‘ ìœ„ì¹˜ (ê²¹ì¹¨ ê³ ë ¤)
        start += chunk_size - overlap

        # ë§ˆì§€ë§‰ ì²­í¬ ì²˜ë¦¬
        if end >= len(words):
            break

    return chunks


def generate_embedding(text: str) -> List[float]:
    """
    Ollama APIë¡œ ì„ë² ë”© ìƒì„±

    Args:
        text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸

    Returns:
        List[float]: ì„ë² ë”© ë²¡í„° (768 dimensions for nomic-embed-text)
    """
    try:
        response = requests.post(
            f"{OLLAMA_ENDPOINT}/api/embeddings",
            json={
                "model": EMBEDDING_MODEL,
                "prompt": text
            },
            timeout=30
        )

        if response.status_code == 200:
            embedding = response.json()['embedding']
            return embedding
        else:
            print(f"  âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {response.status_code}")
            return []
    except Exception as e:
        print(f"  âš ï¸ ì„ë² ë”© API ì˜¤ë¥˜: {e}")
        return []


def serialize_embedding(embedding: List[float]) -> bytes:
    """
    ì„ë² ë”© ë²¡í„°ë¥¼ BLOBë¡œ ì§ë ¬í™” (JSON)

    Args:
        embedding: ì„ë² ë”© ë²¡í„°

    Returns:
        bytes: JSON ì§ë ¬í™”ëœ ë°”ì´íŠ¸
    """
    return json.dumps(embedding).encode('utf-8')


def load_documents(db_path: Path) -> List[Dict]:
    """
    SQLite DBì—ì„œ ëª¨ë“  ë¬¸ì„œ ë¡œë“œ

    Returns:
        List[Dict]: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    cursor.execute("""
        SELECT doc_id, title, content, library
        FROM documents
        ORDER BY id
    """)

    documents = []
    for row in cursor.fetchall():
        documents.append({
            'doc_id': row[0],
            'title': row[1],
            'content': row[2],
            'library': row[3]
        })

    conn.close()
    return documents


def insert_embeddings(db_path: Path, embeddings_data: List[Dict]):
    """
    ì„ë² ë”© ë°ì´í„°ë¥¼ DBì— ì‚½ì…

    Args:
        db_path: DB ê²½ë¡œ
        embeddings_data: ì„ë² ë”© ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # ê¸°ì¡´ ì„ë² ë”© ì‚­ì œ (ì¬ìƒì„±)
    cursor.execute("DELETE FROM embeddings")

    # ìƒˆ ì„ë² ë”© ì‚½ì…
    for item in embeddings_data:
        cursor.execute("""
            INSERT INTO embeddings (
                doc_id, chunk_index, chunk_text, chunk_tokens,
                embedding, embedding_model, created_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            item['doc_id'],
            item['chunk_index'],
            item['chunk_text'],
            item['chunk_tokens'],
            item['embedding'],
            item['embedding_model'],
            item['created_at']
        ))

    conn.commit()
    conn.close()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 50)
    print("RAG System - ë²¡í„° ì„ë² ë”© ìƒì„± (Ollama)")
    print("=" * 50)
    print()

    # 1. Ollama ì„œë²„ í™•ì¸
    print("[1/5] Ollama ì„œë²„ í™•ì¸ ì¤‘...")
    if not check_ollama_server():
        print("\nâŒ Ollama ì„œë²„ë¥¼ ë¨¼ì € ì‹œì‘í•˜ì„¸ìš”:")
        print("   1. í„°ë¯¸ë„ì—ì„œ 'ollama serve' ì‹¤í–‰")
        print(f"   2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: ollama pull {EMBEDDING_MODEL}")
        return 1
    print()

    # 2. ë¬¸ì„œ ë¡œë“œ
    print("[2/5] ë¬¸ì„œ ë¡œë“œ ì¤‘...")
    documents = load_documents(DB_PATH)
    print(f"  â†’ {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\n")

    # 3. ì²­í¬ ìƒì„± ë° ì„ë² ë”©
    print(f"[3/5] ì²­í¬ ìƒì„± ë° ì„ë² ë”© ì¤‘ (ëª¨ë¸: {EMBEDDING_MODEL})...")
    embeddings_data = []
    current_time = int(time.time())

    total_chunks = 0
    for doc_idx, doc in enumerate(documents, 1):
        doc_id = doc['doc_id']
        content = doc['content']

        # ì²­í¬ ìƒì„±
        chunks = chunk_text(content, CHUNK_SIZE, CHUNK_OVERLAP)
        total_chunks += len(chunks)

        print(f"  [{doc_idx}/{len(documents)}] {doc_id} ({len(chunks)}ê°œ ì²­í¬)")

        # ê° ì²­í¬ì— ëŒ€í•´ ì„ë² ë”© ìƒì„±
        for chunk_idx, chunk in enumerate(chunks):
            # ì„ë² ë”© ìƒì„±
            embedding = generate_embedding(chunk)

            if not embedding:
                print(f"    âš ï¸ ì²­í¬ {chunk_idx} ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ (ìŠ¤í‚µ)")
                continue

            # ì„ë² ë”© ë°ì´í„° ì €ì¥
            embeddings_data.append({
                'doc_id': doc_id,
                'chunk_index': chunk_idx,
                'chunk_text': chunk,
                'chunk_tokens': len(chunk.split()),  # ë‹¨ì–´ ìˆ˜
                'embedding': serialize_embedding(embedding),
                'embedding_model': EMBEDDING_MODEL,
                'created_at': current_time
            })

            # Rate limiting (Ollama ì„œë²„ ë¶€í•˜ ë°©ì§€)
            time.sleep(0.1)

    print(f"\n  âœ“ ì´ {total_chunks}ê°œ ì²­í¬ ì„ë² ë”© ì™„ë£Œ\n")

    # 4. DB ì‚½ì…
    print(f"[4/5] ì„ë² ë”© DB ì‚½ì… ì¤‘...")
    insert_embeddings(DB_PATH, embeddings_data)
    print(f"  âœ“ {len(embeddings_data)}ê°œ ì„ë² ë”© ì‚½ì… ì™„ë£Œ\n")

    # 5. í†µê³„ ì¶œë ¥
    print("[5/5] í†µê³„ ìƒì„± ì¤‘...")
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # ë¼ì´ë¸ŒëŸ¬ë¦¬ë³„ ì„ë² ë”© í†µê³„
    cursor.execute("""
        SELECT d.library, COUNT(e.id) as chunk_count
        FROM documents d
        LEFT JOIN embeddings e ON d.doc_id = e.doc_id
        GROUP BY d.library
    """)

    print("\nğŸ“Š ì„ë² ë”© í†µê³„:")
    print("-" * 50)
    for row in cursor.fetchall():
        library, chunk_count = row
        print(f"  {library:15} | {chunk_count:4}ê°œ ì²­í¬")

    # ì „ì²´ í†µê³„
    cursor.execute("SELECT COUNT(*) FROM embeddings")
    total_embeddings = cursor.fetchone()[0]

    cursor.execute("SELECT COUNT(DISTINCT doc_id) FROM embeddings")
    total_docs = cursor.fetchone()[0]

    print("-" * 50)
    print(f"  {'TOTAL':15} | {total_embeddings:4}ê°œ ì²­í¬")
    print(f"\nâœ“ ë¬¸ì„œ: {total_docs}ê°œ")
    print(f"âœ“ í‰ê·  ì²­í¬/ë¬¸ì„œ: {total_embeddings / total_docs:.1f}ê°œ")

    # DB íŒŒì¼ í¬ê¸°
    db_size = DB_PATH.stat().st_size / (1024 * 1024)  # MB
    print(f"âœ“ DB í¬ê¸°: {db_size:.2f} MB")

    conn.close()

    print()
    print("=" * 50)
    print("âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
    print(f"   ìœ„ì¹˜: {DB_PATH}")
    print("=" * 50)

    return 0


if __name__ == "__main__":
    sys.exit(main())