# RAG ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ (Hybrid RAG + Semantic Chunking)

**ëª©í‘œ**: ìµœê³  ì •í™•ë„ì˜ í†µê³„ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ

**í•µì‹¬ ê¸°ìˆ **:
- âœ… **Docling**: PDF/HTML â†’ Markdown (ìˆ˜ì‹/í‘œ ë³´ì¡´) - IBM Research, 2025ë…„ ê³µì‹ ì¶œì‹œ
- âœ… **Semantic Chunking**: ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹ (ë¬¸ë§¥ ë³´ì¡´) - LangChain Experimental
- âœ… **Hybrid Retrieval**: BM25 (ì •í™• ë§¤ì¹­) + Vector (ì˜ë¯¸ ìœ ì‚¬ë„)
- âœ… **Reranker**: Cross-encoderë¡œ Top-K ì¬ì •ë ¬

**âš ï¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ê²€ì¦ í•„ìˆ˜**:
- ì´ ë¬¸ì„œëŠ” 2025ë…„ 10ì›” ê¸°ì¤€ ê³µì‹ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë¨
- ì‹¤ì œ êµ¬í˜„ ì „ ìµœì‹  ê³µì‹ ë¬¸ì„œ í™•ì¸ ê¶Œì¥ (Breaking changes ê°€ëŠ¥ì„±)

---

## ğŸ“š ë¬¸ì„œ ì†ŒìŠ¤ ì „ëµ (ì •í™•ì„± ìµœìš°ì„ )

### Tier 2: ê³µì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œ (ì°¸ê³ ìš© â­â­â­)

#### 6. SciPy Documentation
```
URL: https://docs.scipy.org/doc/scipy/reference/stats.html
ë²„ì „: SciPy 1.14.x (Pyodide ë²„ì „ê³¼ ì¼ì¹˜)
ë²”ìœ„: scipy.stats ëª¨ë“ˆ (~300 í•¨ìˆ˜)
ìƒíƒœ: í”„ë¡œì íŠ¸ì—ì„œ ì‹¤ì œ ì‚¬ìš© ì¤‘ (Worker 1-4 ì „ì²´)
```

**í¬ë¡¤ë§ ëŒ€ìƒ**:
- âœ… **API Reference**: í•¨ìˆ˜ë³„ ìƒì„¸ ë¬¸ì„œ
  - ì˜ˆ: `scipy.stats.ttest_ind`, `mannwhitneyu`, `kruskal`
- âœ… **Parameters**: íŒŒë¼ë¯¸í„° ì„¤ëª…, íƒ€ì…, ê¸°ë³¸ê°’
- âœ… **Returns**: ë¦¬í„´ê°’ êµ¬ì¡° (statistic, pvalue)
- âœ… **Mathematical Formulas**: LaTeX ìˆ˜ì‹ (ê²€ì • í†µê³„ëŸ‰ ê³„ì‚°)
- âœ… **Examples**: ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ (ì½”ë“œ + í•´ì„)
- âœ… **Notes**: ê°€ì •, ì œí•œì‚¬í•­, ì£¼ì˜ì‚¬í•­

**URL íŒ¨í„´**:
```
https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.{function}.html
```

---

#### 7. NumPy Documentation
```
URL: https://numpy.org/doc/stable/reference/routines.statistics.html
ë²„ì „: NumPy 1.26.x
ë²”ìœ„: ê¸°ìˆ í†µê³„ í•¨ìˆ˜ (~50 í•¨ìˆ˜)
ìƒíƒœ: í”„ë¡œì íŠ¸ì—ì„œ ì‹¤ì œ ì‚¬ìš© ì¤‘ (Worker 1 ì£¼ë¡œ)
```

**í¬ë¡¤ë§ ëŒ€ìƒ**:
- âœ… **Basic Statistics**: `mean`, `median`, `std`, `var`
- âœ… **Percentiles**: `percentile`, `quantile` (Kruskal-Wallis, Friedmanì—ì„œ ì‚¬ìš©)
- âœ… **Correlation**: `corrcoef`, `cov`
- âŒ **ë°°ì—´ ì—°ì‚° ì œì™¸**: reshape, indexing ë“± (RAG ë¶ˆí•„ìš”)

---

### Tier 0: í†µê³„ ë°©ë²•ë¡  ê°€ì´ë“œ (ì„ë°•ì‚¬ ëŒ€ìƒ â­â­â­â­â­)

#### 1. í†µê³„ ë°©ë²• ì„ íƒ ë° í•´ì„ ê°€ì´ë“œ (ì‹ ê·œ ì‘ì„± í•„ìš”)
```
ê²½ë¡œ: rag-system/data/methodology-guide/
ë‚´ìš©: í†µê³„ ë°©ë²•ë¡  ì¤‘ì‹¬ ê°€ì´ë“œ (ì•± UI ë¬´ê´€)
- statistical-decision-tree.md: ì—°êµ¬ ì§ˆë¬¸ â†’ í†µê³„ ë°©ë²• ì„ íƒ
- assumption-guide.md: ê°€ì • ê²€ì¦ ë° ìœ„ë°˜ ì‹œ ëŒ€ì•ˆ
- interpretation-guide.md: ê²°ê³¼ í•´ì„ (p-value, effect size)
- method-comparison.md: ìœ ì‚¬ ë°©ë²• ë¹„êµ (t-test vs Mann-Whitney)
```

**RAG í™œìš©** (í†µê³„ ë°©ë²•ë¡  ì¤‘ì‹¬):
- âœ… **ë°©ë²• ì„ íƒ**: "ì •ê·œì„± ê°€ì • ìœ„ë°˜ ì‹œ â†’ Mann-Whitney U ê²€ì •"
- âœ… **ê°€ì • ê²€ì¦**: "Shapiro-Wilk p < 0.05 â†’ ì •ê·œì„± ê¹¨ì§ â†’ ë¹„ëª¨ìˆ˜ ê²€ì •"
- âœ… **ê²°ê³¼ í•´ì„**: "Cohen's d = 0.8 â†’ í° íš¨ê³¼í¬ê¸° (ì‹¤ì§ˆì  ì˜ë¯¸ ìˆìŒ)"
- âœ… **ëŒ€ì•ˆ ì œì‹œ**: "ë“±ë¶„ì‚° ê°€ì • ìœ„ë°˜ â†’ Welch's t-test ì‚¬ìš©"

**ë©”ì„œë“œ ìœ„ì¹˜** (method-metadata.tsì—ì„œ ìë™ ì¶”ì¶œ):
- âœ… **ì¹´í…Œê³ ë¦¬ë§Œ ì œê³µ**: "ì´ ë°©ë²•ì€ 'ê°€ì„¤ê²€ì •' ì¹´í…Œê³ ë¦¬ì…ë‹ˆë‹¤"
- âœ… **ê²€ìƒ‰ í‚¤ì›Œë“œ**: "ì•± ê²€ìƒ‰ì°½ì— 't-test' ë˜ëŠ” 'mann-whitney' ì…ë ¥"
- âŒ **ìƒì„¸ ë©”ë‰´ ê²½ë¡œ ì œì™¸**: UI ë³€ê²½ ì‹œ ë¬¸ì„œ ìˆ˜ì • ë¶ˆí•„ìš”

**ìš°ì„ ìˆœìœ„**: **ê°€ì¥ ë†’ìŒ** (ì„ë°•ì‚¬ ì—°êµ¬ìì˜ ì‹¤ì œ ë‹ˆì¦ˆ)

---

### Tier 1: í”„ë¡œì íŠ¸ ë‚´ë¶€ ë¬¸ì„œ (í•µì‹¬! â­â­â­â­â­)

#### 2. Method Metadata (60ê°œ ë©”ì„œë“œ)
```
ê²½ë¡œ: statistical-platform/lib/statistics/registry/method-metadata.ts
ë‚´ìš©: ê° í†µê³„ ë©”ì„œë“œì˜ ë©”íƒ€ë°ì´í„°
- ë©”ì„œë“œ ID, ê·¸ë£¹ (descriptive/hypothesis/etc.)
- ì˜ì¡´ì„± íŒ¨í‚¤ì§€ (numpy, scipy)
- ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„
```

**RAG í™œìš©**:
- âœ… ë©”ì„œë“œ ì¶”ì²œ: "ë‘ ê·¸ë£¹ ë¹„êµ" â†’ t-test, mann-whitney
- âœ… ì˜ì¡´ì„± í™•ì¸: "ì´ ë©”ì„œë“œëŠ” scipyê°€ í•„ìš”í•©ë‹ˆë‹¤"
- âœ… ì‹¤í–‰ ì‹œê°„ ì˜ˆì¸¡: "ì•½ 0.3ì´ˆ ì†Œìš”ë©ë‹ˆë‹¤"

---

#### 3. Implementation Summary
```
ê²½ë¡œ: statistical-platform/docs/implementation-summary.md
ë‚´ìš©: êµ¬í˜„ í˜„í™© ë° ìš°ì„ ìˆœìœ„
- êµ¬í˜„ ì™„ë£Œ (41ê°œ)
- êµ¬í˜„ í•„ìš” (24ê°œ)
- ë©”íƒ€ë°ì´í„°ë§Œ ë“±ë¡ (ìš°ì„ ìˆœìœ„ 3)
```

**RAG í™œìš©**:
- âœ… ë©”ì„œë“œ ì§€ì› ì—¬ë¶€: "ì´ ë©”ì„œë“œëŠ” í˜„ì¬ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤"
- âœ… ëŒ€ì•ˆ ì œì‹œ: "AëŠ” ë¯¸êµ¬í˜„, Bë¥¼ ëŒ€ì‹  ì‚¬ìš©í•˜ì„¸ìš”"

---

#### 4. Python Worker ì½”ë“œ ì£¼ì„
```
ê²½ë¡œ: statistical-platform/public/workers/python/worker*.py
ë‚´ìš©: ì‹¤ì œ êµ¬í˜„ ì½”ë“œ + ì£¼ì„
- Worker 1: ê¸°ìˆ í†µê³„ (214 lines)
- Worker 2: ê°€ì„¤ê²€ì • (338 lines)
- Worker 3: ë¹„ëª¨ìˆ˜/ANOVA (614 lines)
- Worker 4: íšŒê·€/ê³ ê¸‰ (656 lines)
```

**RAG í™œìš©**:
- âœ… êµ¬í˜„ ì„¸ë¶€ì‚¬í•­: "ì´ ë©”ì„œë“œëŠ” scipy.stats.mannwhitneyuë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤"
- âœ… ì—ëŸ¬ ì²˜ë¦¬: "ìƒ˜í”Œ í¬ê¸°ê°€ 3 ë¯¸ë§Œì´ë©´ ì—ëŸ¬ ë°œìƒ"
- âœ… ë°ì´í„° ì „ì²˜ë¦¬: "None ê°’ì€ ìë™ìœ¼ë¡œ ì œê±°ë©ë‹ˆë‹¤"

---

### Tier 3: í–¥í›„ í™•ì¥ (í˜„ì¬ ë¯¸ì‚¬ìš©)

#### 5. statsmodels (Phase 7 ì´í›„)
```
URL: https://www.statsmodels.org/stable/index.html
í˜„ì¬ ìƒíƒœ: ì½”ë“œë² ì´ìŠ¤ì—ì„œ import ì—†ìŒ
ê³„íš: íšŒê·€ë¶„ì„ ê³ ë„í™” ì‹œ ë„ì… ê°€ëŠ¥
ë³´ë¥˜ ì´ìœ : í˜„ì¬ scipyë¡œ ì¶©ë¶„
```

#### 7. pingouin (Phase 8 ì´í›„)
```
URL: https://pingouin-stats.org/api.html
í˜„ì¬ ìƒíƒœ: ì½”ë“œë² ì´ìŠ¤ì—ì„œ import ì—†ìŒ
ê³„íš: Effect size ê³ ë„í™” ì‹œ ë„ì… ê°€ëŠ¥
ë³´ë¥˜ ì´ìœ : í˜„ì¬ ìˆ˜ë™ ê³„ì‚°ìœ¼ë¡œ ì¶©ë¶„
```

---

### ë¬¸ì„œ ìˆ˜ì§‘ ìš°ì„ ìˆœìœ„ (Week 1 Day-by-Day)

**Day 1**: í†µê³„ ë°©ë²•ë¡  ê°€ì´ë“œ ì‘ì„± (Tier 0, ìµœìš°ì„ !)
- [ ] statistical-decision-tree.md: ì—°êµ¬ ì§ˆë¬¸ â†’ í†µê³„ ë°©ë²• ì„ íƒ
- [ ] assumption-guide.md: ê°€ì • ê²€ì¦ ë° ìœ„ë°˜ ì‹œ ëŒ€ì•ˆ
- [ ] interpretation-guide.md: ê²°ê³¼ í•´ì„ (p-value, effect size, ì‹ ë¢°êµ¬ê°„)
- [ ] method-comparison.md: ìœ ì‚¬ ë°©ë²• ë¹„êµ (ëª¨ìˆ˜ vs ë¹„ëª¨ìˆ˜)

**Day 2**: Crawl4AI ì…‹ì—… + ìƒ˜í”Œ í…ŒìŠ¤íŠ¸
- [ ] Crawl4AI ì„¤ì¹˜ ë° í™˜ê²½ êµ¬ì„±
- [ ] SciPy t-test ìƒ˜í”Œ í¬ë¡¤ë§
- [ ] LaTeX, í‘œ, ì½”ë“œ ë¸”ë¡ í’ˆì§ˆ í™•ì¸

**Day 3**: SciPy í•µì‹¬ í•¨ìˆ˜ í¬ë¡¤ë§ (41ê°œ)
```python
# Worker ì½”ë“œì—ì„œ ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ í•¨ìˆ˜ë§Œ
scipy_functions = [
    'ttest_ind', 'mannwhitneyu', 'kruskal',
    'shapiro', 'levene', 'chi2_contingency',
    'pearsonr', 'spearmanr', # ... ì´ 41ê°œ
]
```

**Day 4**: NumPy ê¸°ì´ˆ í†µê³„ + í”„ë¡œì íŠ¸ ë¬¸ì„œ
- [ ] NumPy ê¸°ì´ˆ í†µê³„ í¬ë¡¤ë§ (~20ê°œ)
- [ ] method-metadata.ts íŒŒì‹± (60ê°œ)
- [ ] implementation-summary.md ë³µì‚¬
- [ ] Python Worker ì£¼ì„ ì¶”ì¶œ

**Day 5-7**: í’ˆì§ˆ ê²€ì¦ + LLM Prompt ì„¤ê³„
- [ ] ë¬¸ì„œ ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
- [ ] RAG Prompt Template ì‘ì„± (ì‚¬ìš©ì ì¹œí™”ì )
- [ ] ìƒ˜í”Œ ì§ˆë¬¸-ë‹µë³€ í…ŒìŠ¤íŠ¸
- [ ] ìµœì¢… ë¬¸ì„œ ê°œìˆ˜: ~130ê°œ (app-guide 4 + scipy 41 + numpy 20 + project 65)

---

## ğŸ—ï¸ ì „ì²´ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 1: Document Processing (Week 1)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Crawl4AI (Web Crawler)         â”‚
    â”‚  - ì›¹ì—ì„œ HTML ë‹¤ìš´ë¡œë“œ          â”‚
    â”‚  - ë¹„ë™ê¸° ë³‘ë ¬ í¬ë¡¤ë§ (6x fast) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Docling (Parser, Optional)     â”‚
    â”‚  - HTML/PDF â†’ ì •êµí•œ Markdown   â”‚
    â”‚  - AI ë ˆì´ì•„ì›ƒ ë¶„ì„              â”‚
    â”‚  - ìˆ˜ì‹/í‘œ ì •ë°€ ì¶”ì¶œ             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Semantic Chunker               â”‚
    â”‚  - ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹                â”‚
    â”‚  - ë¬¸ë§¥ ë³´ì¡´ (ë¬¸ì¥ ì¤‘ê°„ ì•ˆ ì˜ë¦¼) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 2: Vector Database (Week 2)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Dual Indexing                  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  1. BM25 Index (Sparse)         â”‚
    â”‚     - í†µê³„ ìš©ì–´ ì •í™• ë§¤ì¹­        â”‚
    â”‚  2. Chroma Vector DB (Dense)    â”‚
    â”‚     - HuggingFace Embeddings    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 3: Query Pipeline (Week 3-4)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         ì‚¬ìš©ì ì§ˆë¬¸: "ë‘ ê·¸ë£¹ í‰ê·  ë¹„êµ?"
                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Hybrid Retriever               â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  BM25 (k=10) + Vector (k=10)    â”‚
    â”‚  â†’ 20ê°œ í›„ë³´ ë¬¸ì„œ               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Cohere Reranker                â”‚
    â”‚  - Cross-encoderë¡œ ì¬ì •ë ¬        â”‚
    â”‚  â†’ Top 5 ë¬¸ì„œ ì„ ì •              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Context Builder                â”‚
    â”‚  - ì„ íƒëœ ë¬¸ì„œ í¬ë§·íŒ…            â”‚
    â”‚  - í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Ollama LLM (Llama 3)           â”‚
    â”‚  - ìµœì¢… ë‹µë³€ ìƒì„±               â”‚
    â”‚  - Streaming ì‘ë‹µ               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 4: Frontend (Week 5)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Vercel AI SDK (Next.js)        â”‚
    â”‚  - ChatGPT ìŠ¤íƒ€ì¼ UI            â”‚
    â”‚  - Streaming ì‹¤ì‹œê°„ í‘œì‹œ        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ ìƒì„¸

### 1. Document Crawling & Parsing

#### 1-1. Crawl4AI (Web Crawler)

**ì„¤ì¹˜**:
```bash
pip install crawl4ai  # v0.7.6 (2025)
```

**ì—­í• **: ì›¹ì—ì„œ HTML ë‹¤ìš´ë¡œë“œ + ê¸°ë³¸ Markdown ë³€í™˜
**ê¸°ëŠ¥**:
- âœ… ë¹„ë™ê¸° ë³‘ë ¬ í¬ë¡¤ë§ (6x faster)
- âœ… JavaScript ë Œë”ë§ ì§€ì›
- âœ… LLM-friendly Markdown ìƒì„±
- âœ… ë…¸ì´ì¦ˆ ìë™ ì œê±° (fit_markdown)

**ì˜ˆì‹œ**:
```python
from crawl4ai import AsyncWebCrawler
from crawl4ai.markdown_generation import DefaultMarkdownGenerator

async with AsyncWebCrawler() as crawler:
    result = await crawler.arun(
        url="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html",
        markdown_generator=DefaultMarkdownGenerator()
    )

    # LLM-friendly Markdown (ë…¸ì´ì¦ˆ ì œê±°ë¨)
    markdown = result.markdown_v2.fit_markdown
```

---

#### 1-2. Docling (Advanced Parser, Optional)

**ì„¤ì¹˜**:
```bash
pip install docling  # IBM Research (2025)
```

**ì—­í• **: PDF/HTML â†’ **ì •êµí•œ** Markdown íŒŒì‹± (AI ë ˆì´ì•„ì›ƒ ë¶„ì„)
**ê¸°ëŠ¥**:
- âœ… LaTeX ìˆ˜ì‹ ì™„ë²½ ë³µì› (`$$...$$`)
- âœ… ë³µì¡í•œ í‘œ êµ¬ì¡° ë³´ì¡´ (94%+ ì •í™•ë„)
- âœ… ë ˆì´ì•„ì›ƒ ë¶„ì„ (ì œëª©, ë³¸ë¬¸, ê°ì£¼, 2ë‹¨ ë ˆì´ì•„ì›ƒ)
- âœ… ì´ë¯¸ì§€ ë¶„ë¥˜ ë° ìº¡ì…˜ ì—°ê²°

**PyPDF2 vs Docling ë¹„êµ**:
```python
# âŒ PyPDF2 (ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì¶”ì¶œ)
from PyPDF2 import PdfReader
text = PdfReader("paper.pdf").pages[0].extract_text()
# ê²°ê³¼: "t = (x 1 - x 2) / (s / n 1 + s / n 2)"  â† ìˆ˜ì‹ ê¹¨ì§!

# âœ… Docling (AI íŒŒì‹±)
from docling.document_converter import DocumentConverter
result = DocumentConverter().convert("paper.pdf")
markdown = result.document.export_to_markdown()
# ê²°ê³¼: "$$t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s^2}{n_1} + \frac{s^2}{n_2}}}$$"  â† ì™„ë²½!
```

**ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤**:
- âœ… PDF ë…¼ë¬¸ íŒŒì‹± (í†µê³„ ì´ë¡  ì°¸ê³  ë¬¸í—Œ)
- âœ… ë³µì¡í•œ HTML (ìˆ˜ì‹/í‘œê°€ ë§ì€ ê²½ìš°)
- âŒ ë‹¨ìˆœ HTML (Crawl4AIë§Œìœ¼ë¡œ ì¶©ë¶„)

---

#### 1-3. íŒŒì´í”„ë¼ì¸ ì„ íƒ ê°€ì´ë“œ

| ë¬¸ì„œ ì†ŒìŠ¤ | ë³µì¡ë„ | ì¶”ì²œ ë„êµ¬ | ì´ìœ  |
|-----------|--------|-----------|------|
| SciPy HTML | ë‚®ìŒ | **Crawl4AIë§Œ** | Sphinx í…œí”Œë¦¿ (êµ¬ì¡° ë‹¨ìˆœ) |
| statsmodels HTML | ì¤‘ê°„ | Crawl4AI â†’ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ | í’ˆì§ˆ í™•ì¸ í›„ ê²°ì • |
| í†µê³„ ë…¼ë¬¸ PDF | ë†’ìŒ | **Docling í•„ìˆ˜** | LaTeX ìˆ˜ì‹ ë³µì› í•„ìš” |
| í”„ë¡œì íŠ¸ ë¬¸ì„œ | ë‚®ìŒ | ì§ì ‘ ë³µì‚¬ | ë¡œì»¬ íŒŒì¼ |

**ìµœì¢… ì „ëµ**:
```python
# Step 1: Crawl4AIë¡œ ìƒ˜í”Œ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸
sample = await crawl_with_crawl4ai("https://docs.scipy.org/.../ttest_ind.html")

# Step 2: í’ˆì§ˆ ê²€ì‚¬
if has_latex_formulas(sample) and formulas_look_good(sample):
    # Crawl4AIë§Œ ì‚¬ìš© (ë¹ ë¦„)
    use_crawl4ai_only()
else:
    # Crawl4AI + Docling ì¡°í•© (ì •êµí•¨)
    use_crawl4ai_then_docling()
```

---

### 2. Semantic Chunking (LangChain Experimental)

**ì„¤ì¹˜**:
```bash
pip install langchain>=1.0 langchain-experimental
```

**3ê°€ì§€ Chunking ì „ëµ ë¹„êµ**:

| ì „ëµ | ë°©ì‹ | ì¥ì  | ë‹¨ì  | í†µê³„ ë¬¸ì„œ ì í•©ë„ |
|------|------|------|------|------------------|
| **Fixed Size** | ê³ ì • í¬ê¸° (512 tokens) | ë¹ ë¦„ | ë¬¸ë§¥ ì†ì‹¤ | â­â­ (ë¹„ì¶”ì²œ) |
| **Recursive** | ë¬¸ë‹¨/ë¬¸ì¥ ê²½ê³„ | ê· í˜• | ì—¬ì „íˆ ìë¦„ | â­â­â­ (ê´œì°®ìŒ) |
| **Semantic** | ì„ë² ë”© ìœ ì‚¬ë„ | ë¬¸ë§¥ ì™„ë²½ ë³´ì¡´ | ëŠë¦¼ | â­â­â­â­â­ (ìµœê³ ) |

**Semantic Chunking êµ¬í˜„**:
```python
from langchain_experimental.text_splitter import SemanticChunker
from langchain_community.embeddings import HuggingFaceEmbeddings

# Embedding ëª¨ë¸
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# Semantic Chunker (3ê°€ì§€ ëª¨ë“œ)
text_splitter = SemanticChunker(
    embeddings,
    breakpoint_threshold_type="percentile",  # 'percentile', 'standard_deviation', 'interquartile'
    breakpoint_threshold_amount=95  # ìƒìœ„ 5%ë§Œ ê²½ê³„ë¡œ ì¸ì‹ (ë” í° ì²­í¬)
)

# ì²­í‚¹ ì‹¤í–‰
chunks = text_splitter.create_documents([markdown_text])

# ê²°ê³¼: ì˜ë¯¸ì ìœ¼ë¡œ ì™„ê²°ëœ ì²­í¬
# Chunk 1: "scipy.stats.ttest_ind ... Formula: ... Parameters: ..."
# Chunk 2: "Returns: ... Examples: ..."
```

**ì™œ Semantic Chunkingì¸ê°€?**:
```python
# âŒ Fixed Size (512 tokens)
chunk1 = """
scipy.stats.ttest_ind calculates T-test for means.
Formula: t = (x1 - x2) / sqrt(s1^2/n1 + s2^"""  # â† ìˆ˜ì‹ ì¤‘ê°„ ì˜ë¦¼!

# âœ… Semantic Chunking
chunk1 = """
scipy.stats.ttest_ind calculates T-test for means.
Formula: t = (x1 - x2) / sqrt(s1^2/n1 + s2^2/n2)
"""  # â† ìˆ˜ì‹ ì™„ì „íˆ í¬í•¨
chunk2 = """
Parameters:
- a: First sample
- b: Second sample
"""  # â† íŒŒë¼ë¯¸í„° ì„¹ì…˜ ì™„ì „íˆ ë¶„ë¦¬
```

---

### 3. Hybrid Retrieval (BM25 + Vector)

**ì„¤ì¹˜**:
```bash
pip install rank-bm25 langchain-cohere
```

**êµ¬í˜„**:
```python
from langchain.retrievers import BM25Retriever, EnsembleRetriever
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_cohere import CohereRerank

# 1. BM25 Retriever (í‚¤ì›Œë“œ ë§¤ì¹­)
bm25_retriever = BM25Retriever.from_documents(chunks)
bm25_retriever.k = 10  # Top 10

# 2. Vector Retriever (ì˜ë¯¸ ìœ ì‚¬ë„)
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
vectorstore = Chroma.from_documents(chunks, embeddings, persist_directory="./chroma_db")
vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})

# 3. Ensemble (Hybrid)
hybrid_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, vector_retriever],
    weights=[0.5, 0.5]  # ë™ë“± ë¹„ì¤‘ (ì¡°ì • ê°€ëŠ¥)
)

# 4. Reranker (Top 5ë¡œ ì••ì¶•)
reranker = CohereRerank(
    model="rerank-english-v2.0",  # ë˜ëŠ” "rerank-multilingual-v2.0"
    top_n=5,
    cohere_api_key="YOUR_API_KEY"  # ë¬´ë£Œ 1000 requests/ì›”
)

# 5. ìµœì¢… ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸
def search(query: str):
    # Step 1: Hybrid ê²€ìƒ‰ (20ê°œ í›„ë³´)
    docs = hybrid_retriever.get_relevant_documents(query)

    # Step 2: Rerank (Top 5 ì„ ì •)
    reranked = reranker.rerank(docs, query)

    return reranked[:5]
```

**ì„±ëŠ¥ ë¹„êµ** (í†µê³„ ë¬¸ì„œ ê²€ìƒ‰):
| ë°©ì‹ | Recall@5 | Precision@5 | ì˜ˆì‹œ |
|------|----------|-------------|------|
| Vectorë§Œ | 65% | 70% | "ë‘ ê·¸ë£¹ ë¹„êµ" â†’ mann-whitney (ì˜ëª»ëœ ê²°ê³¼) |
| BM25ë§Œ | 70% | 60% | "t-test" â†’ ì •í™• ë§¤ì¹­ë§Œ |
| **Hybrid + Rerank** | **85%** | **90%** | "ë‘ ê·¸ë£¹ í‰ê·  ë¹„êµ" â†’ t-test âœ“ |

---

### 4. Cohere Reranker (ë¬´ë£Œ API)

**ì™œ Rerankerê°€ í•„ìš”í•œê°€?**:
```python
# Hybrid ê²€ìƒ‰ í›„ (20ê°œ ë¬¸ì„œ)
[
  {"score": 0.85, "doc": "t-test for independent samples..."},
  {"score": 0.84, "doc": "mann-whitney U test..."},  # â† ë¹„ìŠ·í•œ ì ìˆ˜
  {"score": 0.83, "doc": "ANOVA for multiple groups..."},
]

# Reranker ì ìš© í›„ (Cross-encoderë¡œ ì¬ì ìˆ˜í™”)
[
  {"score": 0.95, "doc": "t-test for independent samples..."},  # â† í™•ì‹¤í•œ 1ìœ„
  {"score": 0.62, "doc": "ANOVA for multiple groups..."},
  {"score": 0.58, "doc": "mann-whitney U test..."},
]
```

**Cohere Rerank API** (ë¬´ë£Œ í‹°ì–´):
- âœ… ì›” 1000 requests (ì¶©ë¶„í•¨)
- âœ… ë¬´ë£Œ API Key: https://dashboard.cohere.com/
- âœ… Multilingual ì§€ì› (í•œêµ­ì–´ ì§ˆë¬¸ ê°€ëŠ¥)

**ëŒ€ì•ˆ** (ì™„ì „ ë¬´ë£Œ):
```python
from sentence_transformers import CrossEncoder

# Hugging Face Cross-encoder (ë¡œì»¬ ì‹¤í–‰)
reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

def rerank(query, docs):
    pairs = [(query, doc.page_content) for doc in docs]
    scores = reranker.predict(pairs)
    ranked = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)
    return [doc for doc, score in ranked[:5]]
```

---

### 5. Frontend (Vercel AI SDK)

**ì„¤ì¹˜**:
```bash
npm install ai @langchain/community
```

**API Route** (`app/api/rag/route.ts`):
```typescript
import { StreamingTextResponse } from 'ai'
import { Ollama } from '@langchain/community/llms/ollama'

export async function POST(req: Request) {
  const { messages } = await req.json()
  const userQuery = messages[messages.length - 1].content

  // Python FastAPI í˜¸ì¶œ (Hybrid Retrieval)
  const response = await fetch('http://localhost:8000/search', {
    method: 'POST',
    body: JSON.stringify({ query: userQuery })
  })
  const { docs } = await response.json()

  // LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
  const context = docs.map((d: any) => d.page_content).join('\n\n')
  const prompt = `Based on the following documentation:

${context}

Answer the user's question: ${userQuery}`

  // Ollama LLM (Streaming)
  const llm = new Ollama({ model: 'llama3', baseUrl: 'http://localhost:11434' })
  const stream = await llm.stream(prompt)

  return new StreamingTextResponse(stream)
}
```

**Chat UI** (`app/components/chat/ChatPanel.tsx`):
```typescript
'use client'
import { useChat } from 'ai/react'

export function ChatPanel() {
  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({
    api: '/api/rag'
  })

  return (
    <div className="flex flex-col h-full">
      {/* ë©”ì‹œì§€ í‘œì‹œ */}
      <div className="flex-1 overflow-y-auto p-4">
        {messages.map(m => (
          <div key={m.id} className={m.role === 'user' ? 'text-right' : 'text-left'}>
            <div className="inline-block p-3 rounded-lg bg-muted">
              {m.content}
            </div>
          </div>
        ))}
      </div>

      {/* ì…ë ¥ í¼ */}
      <form onSubmit={handleSubmit} className="p-4 border-t">
        <input
          value={input}
          onChange={handleInputChange}
          placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."
          className="w-full p-2 border rounded"
          disabled={isLoading}
        />
      </form>
    </div>
  )
}
```

---

## ğŸ“Š ì˜ˆìƒ ì •í™•ë„ ë¹„êµ

| êµ¬ì„± | Recall@5 | Precision@5 | ì‚¬ìš©ì ë§Œì¡±ë„ |
|------|----------|-------------|--------------|
| Vectorë§Œ | 65% | 70% | â­â­â­ |
| BM25ë§Œ | 70% | 60% | â­â­ |
| Hybrid (no rerank) | 75% | 75% | â­â­â­â­ |
| **Hybrid + Rerank** | **85%** | **90%** | â­â­â­â­â­ |
| + Semantic Chunking | **90%** | **92%** | â­â­â­â­â­ |

**ì˜ˆìƒ ê°œë°œ ì‹œê°„**: 3ì£¼ (5ì£¼ â†’ 3ì£¼)

---

## ğŸš€ êµ¬í˜„ ìˆœì„œ (3ì£¼)

### Week 1: Document Processing + Chunking
- [ ] Doclingìœ¼ë¡œ SciPy/statsmodels ë¬¸ì„œ íŒŒì‹±
- [ ] Semantic Chunking ì ìš©
- [ ] 600+ ì²­í¬ ìƒì„±

### Week 2: Hybrid Indexing
- [ ] BM25 ì¸ë±ìŠ¤ êµ¬ì¶•
- [ ] Chroma Vector DB êµ¬ì¶•
- [ ] Hybrid Retriever êµ¬í˜„

### Week 3: Reranker + Frontend
- [ ] Cohere Reranker í†µí•© (ë˜ëŠ” ë¡œì»¬ Cross-encoder)
- [ ] FastAPI ì—”ë“œí¬ì¸íŠ¸ (`/search`)
- [ ] Vercel AI SDK + Streaming UI

---

**ì‘ì„±ì¼**: 2025-10-31
**ë‹¤ìŒ ë‹¨ê³„**: Week 1 ì‹œì‘ (Docling ì„¤ì¹˜ + ë¬¸ì„œ íŒŒì‹±)