"""
Worker 3: Nonparametric & ANOVA Python Module

비모수검정 + 분산분석 그룹 (18개 메서드)
- 패키지: SciPy, Statsmodels
- 예상 메모리: 140MB
- 예상 로딩: 2.3초
"""

import numpy as np
from scipy import stats


# Nonparametric Tests (9개)

def mann_whitney_test(group1, group2):
    """Mann-Whitney U 검정"""
    group1 = np.array([x for x in group1 if x is not None and not np.isnan(x)])
    group2 = np.array([x for x in group2 if x is not None and not np.isnan(x)])
    
    if len(group1) < 2 or len(group2) < 2:
        raise ValueError("Each group must have at least 2 observations")
    
    statistic, p_value = stats.mannwhitneyu(group1, group2, alternative='two-sided')
    
    return {
        'statistic': float(statistic),
        'pValue': float(p_value)
    }


def wilcoxon_test(values1, values2):
    """
    Wilcoxon 부호순위 검정
    
    쌍(pair) 단위로 데이터 정제하여 통계적 정확성 보장
    """
    # 쌍 단위로 정제 (양쪽 모두 유효한 값만 선택)
    pairs = [(v1, v2) for v1, v2 in zip(values1, values2) 
             if v1 is not None and v2 is not None 
             and not np.isnan(v1) and not np.isnan(v2)]
    
    if len(pairs) < 2:
        raise ValueError("Wilcoxon test requires at least 2 valid pairs")
    
    values1 = np.array([p[0] for p in pairs])
    values2 = np.array([p[1] for p in pairs])
    
    statistic, p_value = stats.wilcoxon(values1, values2)
    
    return {
        'statistic': float(statistic),
        'pValue': float(p_value),
        'nPairs': int(len(pairs))
    }


def kruskal_wallis_test(groups):
    """Kruskal-Wallis H 검정"""
    clean_groups = [np.array([x for x in group if x is not None and not np.isnan(x)]) for group in groups]
    
    # 각 그룹이 최소 1개 이상의 관측치를 가져야 함
    for i, group in enumerate(clean_groups):
        if len(group) == 0:
            raise ValueError(f"Group {i} has no valid observations")
    
    statistic, p_value = stats.kruskal(*clean_groups)
    
    return {
        'statistic': float(statistic),
        'pValue': float(p_value),
        'df': int(len(clean_groups) - 1)
    }


def friedman_test(groups):
    """Friedman 검정"""
    clean_groups = [np.array([x for x in group if x is not None and not np.isnan(x)]) for group in groups]
    
    # 모든 그룹이 같은 길이를 가져야 함 (repeated measures)
    lengths = [len(g) for g in clean_groups]
    if len(set(lengths)) > 1:
        raise ValueError(f"Friedman test requires equal group sizes, got: {lengths}")
    
    statistic, p_value = stats.friedmanchisquare(*clean_groups)
    
    return {
        'statistic': float(statistic),
        'pValue': float(p_value)
    }


# ANOVA Tests (9개)

def one_way_anova(groups):
    """일원 분산분석 (One-Way ANOVA)"""
    clean_groups = [np.array([x for x in group if x is not None and not np.isnan(x)]) for group in groups]
    
    # 각 그룹이 최소 2개 이상의 관측치를 가져야 함
    for i, group in enumerate(clean_groups):
        if len(group) < 2:
            raise ValueError(f"Group {i} must have at least 2 observations")
    
    f_statistic, p_value = stats.f_oneway(*clean_groups)
    
    return {
        'fStatistic': float(f_statistic),
        'pValue': float(p_value),
        'df1': int(len(clean_groups) - 1),
        'df2': int(sum(len(g) for g in clean_groups) - len(clean_groups))
    }


def two_way_anova(data_matrix, factor1_levels, factor2_levels):
    """
    이원 분산분석 (Two-Way ANOVA)
    
    주의: 완전한 구현을 위해서는 statsmodels 사용 권장
    현재는 기본적인 제곱합만 계산
    """
    data_matrix = np.array(data_matrix)
    
    if data_matrix.size == 0:
        raise ValueError("Empty data matrix")
    
    grand_mean = np.mean(data_matrix)
    ss_total = np.sum((data_matrix - grand_mean) ** 2)
    
    # 실제 Two-Way ANOVA는 statsmodels 권장
    return {
        'ssTotal': float(ss_total),
        'grandMean': float(grand_mean),
        'warning': 'Use statsmodels for complete two-way ANOVA implementation'
    }


def tukey_hsd(groups):
    """
    Tukey HSD 사후검정

    SciPy 1.10+ 필요
    """
    from scipy.stats import tukey_hsd as scipy_tukey

    clean_groups = [np.array([x for x in group if x is not None and not np.isnan(x)]) for group in groups]

    # 각 그룹이 최소 1개 이상의 관측치를 가져야 함
    for i, group in enumerate(clean_groups):
        if len(group) == 0:
            raise ValueError(f"Group {i} has no valid observations")

    try:
        result = scipy_tukey(*clean_groups)

        # SciPy 버전에 따라 pvalue 속성이 다를 수 있음
        if hasattr(result, 'pvalue'):
            p_value = float(result.pvalue)
        else:
            p_value = None

        return {
            'statistic': float(result.statistic),
            'pValue': p_value,
            'confidenceInterval': result.confidence_interval().tolist() if hasattr(result, 'confidence_interval') else None
        }
    except AttributeError as e:
        raise ValueError(f"SciPy version may not support tukey_hsd: {e}")


# Priority 1 Methods (5 additional)

def sign_test(before, after):
    """
    부호검정 (Sign Test)

    대응표본 비모수 검정
    """
    from scipy.stats import binomtest

    before = np.array(before)
    after = np.array(after)

    if len(before) != len(after):
        raise ValueError("Before and after must have same length")

    diff = after - before

    n_positive = np.sum(diff > 0)
    n_negative = np.sum(diff < 0)
    n_ties = np.sum(diff == 0)
    n_total = n_positive + n_negative

    if n_total == 0:
        raise ValueError("All differences are zero (ties)")

    # 이항검정 (p=0.5)
    result = binomtest(n_positive, n_total, 0.5)

    return {
        'nPositive': int(n_positive),
        'nNegative': int(n_negative),
        'nTies': int(n_ties),
        'pValue': float(result.pvalue)
    }


def runs_test(sequence):
    """
    Runs 검정 (Runs Test for Randomness)

    무작위성 검정
    """
    # None/NaN 정제
    sequence = np.array([x for x in sequence if x is not None and not np.isnan(x)])

    if len(sequence) < 10:
        raise ValueError("Runs test requires at least 10 observations")

    # 중앙값 기준으로 이분화
    median = np.median(sequence)
    binary = (sequence > median).astype(int)

    # Runs 개수 계산
    runs = 1 + np.sum(binary[1:] != binary[:-1])

    # 각 값의 개수
    n1 = np.sum(binary == 0)
    n2 = np.sum(binary == 1)
    n = n1 + n2

    if n1 == 0 or n2 == 0:
        raise ValueError("All values are on one side of median")

    # 기대 runs 및 분산
    expected_runs = (2 * n1 * n2) / n + 1
    var_runs = (2 * n1 * n2 * (2 * n1 * n2 - n)) / (n**2 * (n - 1))

    # Z-통계량
    z_statistic = (runs - expected_runs) / np.sqrt(var_runs)

    # p-value (양측검정)
    p_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))

    return {
        'nRuns': int(runs),
        'expectedRuns': float(expected_runs),
        'n1': int(n1),
        'n2': int(n2),
        'zStatistic': float(z_statistic),
        'pValue': float(p_value)
    }


def mcnemar_test(contingency_table):
    """
    McNemar 검정

    대응표본 범주형 검정
    """
    table = np.array(contingency_table)

    if table.shape != (2, 2):
        raise ValueError("McNemar test requires 2x2 contingency table")

    # b와 c (불일치 셀)
    b = table[0, 1]
    c = table[1, 0]

    # 연속성 보정 여부
    use_correction = (b + c) < 25

    if use_correction:
        # 연속성 보정
        statistic = (abs(b - c) - 1)**2 / (b + c) if (b + c) > 0 else 0
    else:
        statistic = (b - c)**2 / (b + c) if (b + c) > 0 else 0

    # p-value (카이제곱 분포, df=1)
    p_value = 1 - stats.chi2.cdf(statistic, df=1)

    return {
        'statistic': float(statistic),
        'pValue': float(p_value),
        'continuityCorrection': bool(use_correction),
        'discordantPairs': {'b': int(b), 'c': int(c)}
    }


def cochran_q_test(data_matrix):
    """
    Cochran Q 검정

    다중 대응표본 범주형 검정
    """
    data_matrix = np.array(data_matrix)
    n, k = data_matrix.shape  # n subjects, k conditions

    if k < 3:
        raise ValueError("Cochran Q requires at least 3 conditions")

    # 각 행과 열의 합
    row_sums = data_matrix.sum(axis=1)
    col_sums = data_matrix.sum(axis=0)

    # Q 통계량 계산 (0으로 나누기 방지)
    G = col_sums.sum()
    denominator = k * G - np.sum(row_sums**2)

    if denominator == 0:
        raise ValueError("Invalid data: denominator is zero in Cochran Q calculation")

    Q = (k - 1) * (k * np.sum(col_sums**2) - G**2) / denominator

    # p-value (카이제곱 분포, df=k-1)
    df = k - 1
    p_value = 1 - stats.chi2.cdf(Q, df)

    return {
        'qStatistic': float(Q),
        'pValue': float(p_value),
        'df': int(df)
    }


def mood_median_test(groups):
    """
    Mood Median 검정

    비모수 중앙값 검정
    """
    if len(groups) < 2:
        raise ValueError("Mood median test requires at least 2 groups")

    # scipy.stats.median_test 사용
    statistic, p_value, grand_median, contingency_table = stats.median_test(*groups)

    return {
        'statistic': float(statistic),
        'pValue': float(p_value),
        'grandMedian': float(grand_median),
        'contingencyTable': contingency_table.tolist()
    }


# Priority 2 Methods - ANOVA (4 methods)

def repeated_measures_anova(data_matrix, subject_ids, time_labels):
    """
    반복측정 분산분석 (Repeated Measures ANOVA)

    data_matrix: n subjects × k timepoints
    """
    from statsmodels.stats.anova import AnovaRM
    import pandas as pd

    n_subjects, n_timepoints = np.array(data_matrix).shape

    # 데이터프레임 생성 (long format)
    data_long = []
    for i, subject_id in enumerate(subject_ids):
        for j, time_label in enumerate(time_labels):
            data_long.append({
                'subject': subject_id,
                'time': time_label,
                'value': data_matrix[i][j]
            })

    df = pd.DataFrame(data_long)

    # Repeated Measures ANOVA
    aovrm = AnovaRM(df, 'value', 'subject', within=['time'])
    res = aovrm.fit()

    return {
        'fStatistic': float(res.anova_table['F Value'][0]),
        'pValue': float(res.anova_table['Pr > F'][0]),
        'df': {
            'numerator': float(res.anova_table['Num DF'][0]),
            'denominator': float(res.anova_table['Den DF'][0])
        },
        'sphericityEpsilon': 1.0,
        'anovaTable': res.anova_table.to_dict()
    }


def ancova(y_values, group_values, covariates):
    """
    공분산분석 (ANCOVA)

    covariates: list of covariate arrays
    """
    import statsmodels.formula.api as smf
    import statsmodels.api as sm
    import pandas as pd

    # 데이터프레임 생성
    data = {
        'y': y_values,
        'group': group_values
    }

    for i, cov in enumerate(covariates):
        data[f'cov{i}'] = cov

    df = pd.DataFrame(data)

    # 공변량 추가한 모델
    cov_formula = ' + '.join([f'cov{i}' for i in range(len(covariates))])
    formula = f'y ~ C(group) + {cov_formula}'

    model = smf.ols(formula, data=df).fit()
    anova_table = sm.stats.anova_lm(model, typ=2)

    # 조정된 평균 계산
    group_means = df.groupby('group')['y'].mean()

    return {
        'fStatisticGroup': float(anova_table.loc['C(group)', 'F']),
        'pValueGroup': float(anova_table.loc['C(group)', 'PR(>F)']),
        'fStatisticCovariate': [float(anova_table.loc[f'cov{i}', 'F']) for i in range(len(covariates))],
        'pValueCovariate': [float(anova_table.loc[f'cov{i}', 'PR(>F)']) for i in range(len(covariates))],
        'adjustedMeans': [{'group': g, 'mean': float(m)} for g, m in group_means.items()],
        'anovaTable': anova_table.to_dict()
    }


def manova(data_matrix, group_values, var_names):
    """
    다변량 분산분석 (MANOVA)

    data_matrix: n observations × p variables
    """
    from statsmodels.multivariate.manova import MANOVA
    import pandas as pd

    # 데이터프레임 생성
    df_dict = {'group': group_values}
    for i, var_name in enumerate(var_names):
        df_dict[var_name] = [row[i] for row in data_matrix]

    df = pd.DataFrame(df_dict)

    # MANOVA
    formula = ' + '.join(var_names) + ' ~ group'
    maov = MANOVA.from_formula(formula, data=df)
    result = maov.mv_test()

    # Wilks' Lambda 추출
    test_results = result.results['group']['stat']

    return {
        'wilksLambda': float(test_results.loc["Wilks' lambda", 'Value']),
        'pillaiTrace': float(test_results.loc["Pillai's trace", 'Value']),
        'hotellingLawley': float(test_results.loc["Hotelling-Lawley trace", 'Value']),
        'royMaxRoot': float(test_results.loc["Roy's greatest root", 'Value']),
        'fStatistic': float(test_results.loc["Wilks' lambda", 'F Value']),
        'pValue': float(test_results.loc["Wilks' lambda", 'Pr > F']),
        'df': {
            'hypothesis': float(test_results.loc["Wilks' lambda", 'Num DF']),
            'error': float(test_results.loc["Wilks' lambda", 'Den DF'])
        }
    }


def scheffe_test(groups):
    """
    Scheffe 사후검정 (Scheffe Test)

    groups: list of arrays (각 그룹의 데이터)
    """
    k = len(groups)
    n_total = sum(len(g) for g in groups)
    group_means = [np.mean(g) for g in groups]
    group_ns = [len(g) for g in groups]

    # 전체 평균
    grand_mean = np.mean(np.concatenate(groups))

    # MSE (Mean Square Error) 계산
    ss_within = sum(np.sum((g - np.mean(g))**2) for g in groups)
    df_within = n_total - k
    mse = ss_within / df_within

    # 모든 쌍 비교
    comparisons = []
    for i in range(k):
        for j in range(i+1, k):
            mean_diff = group_means[i] - group_means[j]

            # Scheffe 통계량
            se = np.sqrt(mse * (1/group_ns[i] + 1/group_ns[j]))
            f_stat = (mean_diff ** 2) / ((k - 1) * se ** 2)

            # p-value
            p_value = 1 - stats.f.cdf(f_stat, k - 1, df_within)

            # 임계값
            critical_f = stats.f.ppf(0.95, k - 1, df_within)
            critical_value = np.sqrt((k - 1) * critical_f) * se

            comparisons.append({
                'group1': i,
                'group2': j,
                'meanDiff': float(mean_diff),
                'fStatistic': float(f_stat),
                'pValue': float(p_value),
                'criticalValue': float(critical_value),
                'significant': p_value < 0.05
            })

    return {
        'comparisons': comparisons,
        'mse': float(mse),
        'dfWithin': int(df_within)
    }
