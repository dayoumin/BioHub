"""
Worker 4: Regression & Advanced Analysis Python Module

회귀분석 + 고급분석 그룹 (24개 메서드)
- 패키지: SciPy, Statsmodels, Sklearn
- 예상 메모리: 200MB  
- 예상 로딩: 3.8초
"""

import numpy as np
from scipy import stats


def linear_regression(x, y):
    """
    선형 회귀분석
    
    쌍(pair) 단위로 데이터 정제하여 통계적 정확성 보장
    """
    # 쌍 단위로 정제 (양쪽 모두 유효한 값만 선택)
    pairs = [(x_val, y_val) for x_val, y_val in zip(x, y) 
             if x_val is not None and y_val is not None 
             and not np.isnan(x_val) and not np.isnan(y_val)]
    
    if len(pairs) < 3:
        raise ValueError("Linear regression requires at least 3 valid pairs")
    
    x = np.array([p[0] for p in pairs])
    y = np.array([p[1] for p in pairs])
    
    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
    
    return {
        'slope': float(slope),
        'intercept': float(intercept),
        'rSquared': float(r_value ** 2),
        'pValue': float(p_value),
        'stdErr': float(std_err),
        'nPairs': int(len(pairs))
    }


def multiple_regression(X, y):
    """
    다중 회귀분석
    
    주의: 완전한 구현을 위해서는 statsmodels 사용 권장
    """
    X = np.array(X)
    y = np.array(y)
    
    if X.shape[0] < X.shape[1] + 1:
        raise ValueError(f"Insufficient observations: need at least {X.shape[1] + 1}, got {X.shape[0]}")
    
    # 최소제곱법으로 회귀계수 계산
    try:
        coefficients = np.linalg.lstsq(X, y, rcond=None)[0]
        
        y_pred = X @ coefficients
        ss_res = np.sum((y - y_pred) ** 2)
        ss_tot = np.sum((y - np.mean(y)) ** 2)
        r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0.0
        
        return {
            'coefficients': coefficients.tolist(),
            'rSquared': float(r_squared),
            'nObservations': int(X.shape[0]),
            'nPredictors': int(X.shape[1])
        }
    except np.linalg.LinAlgError as e:
        raise ValueError(f"Singular matrix in multiple regression: {e}")


def logistic_regression(X, y):
    """
    로지스틱 회귀분석
    
    주의: 완전한 구현을 위해서는 statsmodels 사용 권장
    """
    # 실제 구현은 statsmodels.GLM 권장
    return {
        'message': 'Use statsmodels.api.GLM with family=sm.families.Binomial() for logistic regression',
        'warning': 'Placeholder implementation - needs statsmodels'
    }


def pca_analysis(data_matrix, n_components=2):
    """
    주성분 분석 (PCA)
    
    NumPy SVD로 직접 구현 (sklearn보다 빠름)
    """
    data_matrix = np.array(data_matrix)
    
    if data_matrix.shape[0] < 2:
        raise ValueError("PCA requires at least 2 observations")
    
    if data_matrix.shape[1] < n_components:
        raise ValueError(f"Cannot extract {n_components} components from {data_matrix.shape[1]} features")
    
    # 데이터 중심화
    mean = np.mean(data_matrix, axis=0)
    centered_data = data_matrix - mean
    
    # SVD 계산
    U, S, Vt = np.linalg.svd(centered_data, full_matrices=False)
    
    # 주성분 점수 계산
    components = U[:, :n_components] * S[:n_components]
    
    # 설명된 분산 비율
    explained_variance = (S ** 2) / (data_matrix.shape[0] - 1)
    total_variance = np.sum(explained_variance)
    explained_variance_ratio = explained_variance[:n_components] / total_variance
    
    return {
        'components': components.tolist(),
        'explainedVariance': explained_variance[:n_components].tolist(),
        'explainedVarianceRatio': explained_variance_ratio.tolist(),
        'cumulativeVariance': np.cumsum(explained_variance_ratio).tolist(),
        'loadings': Vt[:n_components].T.tolist()  # 주성분 적재값
    }


# Priority 2 Methods - Regression (9 methods)

def curve_estimation(x_values, y_values, model_type='linear'):
    """
    곡선추정 (Curve Estimation)

    Models: linear, quadratic, cubic, exponential, logarithmic, power
    """
    # None/NaN 쌍 단위 정제
    pairs = [(x_val, y_val) for x_val, y_val in zip(x_values, y_values)
             if x_val is not None and y_val is not None
             and not np.isnan(x_val) and not np.isnan(y_val)]

    if len(pairs) < 3:
        raise ValueError(f"Curve estimation requires at least 3 valid pairs, got {len(pairs)}")

    x = np.array([p[0] for p in pairs])
    y = np.array([p[1] for p in pairs])

    if model_type == 'linear':
        coeffs = np.polyfit(x, y, 1)
        predictions = np.polyval(coeffs, x)
    elif model_type == 'quadratic':
        coeffs = np.polyfit(x, y, 2)
        predictions = np.polyval(coeffs, x)
    elif model_type == 'cubic':
        coeffs = np.polyfit(x, y, 3)
        predictions = np.polyval(coeffs, x)
    elif model_type == 'exponential':
        # y = a * exp(bx)
        if np.any(y <= 0):
            raise ValueError("Exponential model requires all y > 0")
        log_y = np.log(y)
        coeffs_linear = np.polyfit(x, log_y, 1)
        a = np.exp(coeffs_linear[1])
        b = coeffs_linear[0]
        coeffs = [a, b]
        predictions = a * np.exp(b * x)
    elif model_type == 'logarithmic':
        # y = a + b*ln(x)
        if np.any(x <= 0):
            raise ValueError("Logarithmic model requires all x > 0")
        log_x = np.log(x)
        coeffs = np.polyfit(log_x, y, 1)
        predictions = coeffs[0] * np.log(x) + coeffs[1]
    elif model_type == 'power':
        # y = a * x^b
        if np.any(x <= 0) or np.any(y <= 0):
            raise ValueError("Power model requires all x > 0 and y > 0")
        log_x = np.log(x)
        log_y = np.log(y)
        coeffs_linear = np.polyfit(log_x, log_y, 1)
        a = np.exp(coeffs_linear[1])
        b = coeffs_linear[0]
        coeffs = [a, b]
        predictions = a * (x ** b)
    else:
        raise ValueError(f"Unknown model type: {model_type}")

    # R-squared
    ss_res = np.sum((y - predictions) ** 2)
    ss_tot = np.sum((y - np.mean(y)) ** 2)
    r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0

    return {
        'modelType': model_type,
        'coefficients': [float(c) for c in coeffs],
        'rSquared': float(r_squared),
        'predictions': [float(p) for p in predictions],
        'residuals': [float(r) for r in (y - predictions)],
        'nPairs': int(len(pairs))
    }


def nonlinear_regression(x_values, y_values, model_type='exponential', initial_guess=None):
    """
    비선형 회귀 (Nonlinear Regression) - 사전 정의된 모델만 지원

    Models:
    - exponential: y = a * exp(b * x)
    - logistic: y = L / (1 + exp(-k * (x - x0)))
    - gompertz: y = a * exp(-b * exp(-c * x))
    - power: y = a * x^b
    - hyperbolic: y = (a * x) / (b + x)
    """
    from scipy.optimize import curve_fit

    # None/NaN 쌍 단위 정제
    pairs = [(x_val, y_val) for x_val, y_val in zip(x_values, y_values)
             if x_val is not None and y_val is not None
             and not np.isnan(x_val) and not np.isnan(y_val)]

    if len(pairs) < 3:
        raise ValueError(f"Nonlinear regression requires at least 3 valid pairs, got {len(pairs)}")

    x = np.array([p[0] for p in pairs])
    y = np.array([p[1] for p in pairs])

    # 모델 함수 정의
    if model_type == 'exponential':
        def model_func(x, a, b):
            return a * np.exp(b * x)
        if initial_guess is None:
            initial_guess = [1.0, 0.1]
    elif model_type == 'logistic':
        def model_func(x, L, k, x0):
            return L / (1 + np.exp(-k * (x - x0)))
        if initial_guess is None:
            initial_guess = [max(y), 1.0, np.mean(x)]
    elif model_type == 'gompertz':
        def model_func(x, a, b, c):
            return a * np.exp(-b * np.exp(-c * x))
        if initial_guess is None:
            initial_guess = [max(y), 1.0, 0.1]
    elif model_type == 'power':
        def model_func(x, a, b):
            return a * np.power(x, b)
        if initial_guess is None:
            initial_guess = [1.0, 1.0]
    elif model_type == 'hyperbolic':
        def model_func(x, a, b):
            return (a * x) / (b + x)
        if initial_guess is None:
            initial_guess = [max(y), 1.0]
    else:
        raise ValueError(f"Unknown model type: {model_type}")

    # curve_fit으로 파라미터 추정
    try:
        popt, pcov = curve_fit(model_func, x, y, p0=initial_guess)
    except RuntimeError as e:
        raise ValueError(f"Curve fitting failed: {str(e)}")

    predictions = model_func(x, *popt)
    residuals = y - predictions

    # R-squared
    ss_res = np.sum(residuals ** 2)
    ss_tot = np.sum((y - np.mean(y)) ** 2)
    r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0

    # 파라미터 표준오차
    param_errors = np.sqrt(np.diag(pcov))

    return {
        'modelType': model_type,
        'parameters': [float(p) for p in popt],
        'parameterErrors': [float(e) for e in param_errors],
        'rSquared': float(r_squared),
        'predictions': [float(p) for p in predictions],
        'residuals': [float(r) for r in residuals],
        'nPairs': int(len(pairs))
    }


def stepwise_regression(y_values, x_matrix, variable_names=None,
                       method='forward', entry_threshold=0.05, stay_threshold=0.10):
    """
    단계적 회귀분석 (Stepwise Regression)

    method: 'forward', 'backward'
    """
    import statsmodels.api as sm

    y = np.array(y_values)
    X = np.array(x_matrix)
    n_vars = X.shape[1]

    if variable_names is None:
        variable_names = [f'X{i}' for i in range(n_vars)]

    if method == 'forward':
        selected = []
        remaining = list(range(n_vars))
        r_squared_history = []

        while remaining:
            best_pval = 1.0
            best_var = None

            for var in remaining:
                test_vars = selected + [var]
                X_test = sm.add_constant(X[:, test_vars])
                model = sm.OLS(y, X_test).fit()
                pval = model.pvalues[-1]

                if pval < best_pval:
                    best_pval = pval
                    best_var = var

            if best_pval < entry_threshold:
                selected.append(best_var)
                remaining.remove(best_var)

                X_current = sm.add_constant(X[:, selected])
                model_current = sm.OLS(y, X_current).fit()
                r_squared_history.append(float(model_current.rsquared))
            else:
                break

    elif method == 'backward':
        selected = list(range(n_vars))
        r_squared_history = []

        while len(selected) > 0:
            X_test = sm.add_constant(X[:, selected])
            model = sm.OLS(y, X_test).fit()

            pvalues = model.pvalues[1:]
            max_pval_idx = np.argmax(pvalues)
            max_pval = pvalues[max_pval_idx]

            if max_pval > stay_threshold:
                selected.pop(max_pval_idx)

                if selected:
                    X_current = sm.add_constant(X[:, selected])
                    model_current = sm.OLS(y, X_current).fit()
                    r_squared_history.append(float(model_current.rsquared))
            else:
                break

    else:
        raise ValueError(f"Unknown method: {method}. Use 'forward' or 'backward'")

    if selected:
        X_final = sm.add_constant(X[:, selected])
        final_model = sm.OLS(y, X_final).fit()

        return {
            'selectedVariables': [variable_names[i] for i in selected],
            'selectedIndices': selected,
            'rSquaredHistory': r_squared_history,
            'coefficients': [float(c) for c in final_model.params],
            'stdErrors': [float(e) for e in final_model.bse],
            'tValues': [float(t) for t in final_model.tvalues],
            'pValues': [float(p) for p in final_model.pvalues],
            'rSquared': float(final_model.rsquared),
            'adjustedRSquared': float(final_model.rsquared_adj)
        }
    else:
        return {'selectedVariables': [], 'rSquared': 0.0}


def binary_logistic(x_matrix, y_values):
    """이항 로지스틱 회귀 (Binary Logistic Regression)"""
    import statsmodels.api as sm

    X = sm.add_constant(np.array(x_matrix))
    y = np.array(y_values)

    model = sm.Logit(y, X).fit(disp=0)

    predictions_prob = model.predict(X)
    predictions_class = (predictions_prob > 0.5).astype(int)
    accuracy = np.mean(predictions_class == y)

    return {
        'coefficients': [float(c) for c in model.params],
        'stdErrors': [float(e) for e in model.bse],
        'zValues': [float(z) for z in model.tvalues],
        'pValues': [float(p) for p in model.pvalues],
        'predictions': [float(p) for p in predictions_prob],
        'accuracy': float(accuracy),
        'aic': float(model.aic),
        'bic': float(model.bic),
        'pseudoRSquared': float(model.prsquared)
    }


def multinomial_logistic(x_matrix, y_values):
    """다항 로지스틱 회귀 (Multinomial Logistic Regression)"""
    import statsmodels.api as sm

    X = sm.add_constant(np.array(x_matrix))
    y = np.array(y_values)

    model = sm.MNLogit(y, X).fit(disp=0)

    predictions = model.predict(X)
    predicted_class = np.argmax(predictions, axis=1)
    accuracy = np.mean(predicted_class == y)

    return {
        'coefficients': model.params.values.tolist(),
        'pValues': model.pvalues.values.tolist(),
        'predictions': predictions.tolist(),
        'accuracy': float(accuracy),
        'aic': float(model.aic),
        'bic': float(model.bic)
    }


def ordinal_logistic(x_matrix, y_values):
    """순서형 로지스틱 회귀 (Ordinal Logistic Regression)"""
    from statsmodels.miscmodels.ordinal_model import OrderedModel

    X = np.array(x_matrix)
    y = np.array(y_values)

    model = OrderedModel(y, X, distr='logit').fit(disp=0)

    return {
        'coefficients': [float(c) for c in model.params],
        'stdErrors': [float(e) for e in model.bse],
        'zValues': [float(z) for z in model.tvalues],
        'pValues': [float(p) for p in model.pvalues],
        'aic': float(model.aic),
        'bic': float(model.bic)
    }


def probit_regression(x_matrix, y_values):
    """프로빗 회귀 (Probit Regression)"""
    import statsmodels.api as sm

    X = sm.add_constant(np.array(x_matrix))
    y = np.array(y_values)

    model = sm.Probit(y, X).fit(disp=0)

    predictions_prob = model.predict(X)
    predictions_class = (predictions_prob > 0.5).astype(int)
    accuracy = np.mean(predictions_class == y)

    return {
        'coefficients': [float(c) for c in model.params],
        'stdErrors': [float(e) for e in model.bse],
        'zValues': [float(z) for z in model.tvalues],
        'pValues': [float(p) for p in model.pvalues],
        'predictions': [float(p) for p in predictions_prob],
        'accuracy': float(accuracy),
        'aic': float(model.aic),
        'bic': float(model.bic)
    }


def poisson_regression(x_matrix, y_values):
    """포아송 회귀 (Poisson Regression)"""
    import statsmodels.api as sm

    X = sm.add_constant(np.array(x_matrix))
    y = np.array(y_values)

    model = sm.GLM(y, X, family=sm.families.Poisson()).fit()

    return {
        'coefficients': [float(c) for c in model.params],
        'stdErrors': [float(e) for e in model.bse],
        'zValues': [float(z) for z in model.tvalues],
        'pValues': [float(p) for p in model.pvalues],
        'deviance': float(model.deviance),
        'pearsonChi2': float(model.pearson_chi2),
        'aic': float(model.aic),
        'bic': float(model.bic)
    }


def negative_binomial_regression(x_matrix, y_values):
    """음이항 회귀 (Negative Binomial Regression)"""
    import statsmodels.api as sm

    X = sm.add_constant(np.array(x_matrix))
    y = np.array(y_values)

    model = sm.GLM(y, X, family=sm.families.NegativeBinomial()).fit()

    return {
        'coefficients': [float(c) for c in model.params],
        'stdErrors': [float(e) for e in model.bse],
        'zValues': [float(z) for z in model.tvalues],
        'pValues': [float(p) for p in model.pvalues],
        'aic': float(model.aic),
        'bic': float(model.bic)
    }
