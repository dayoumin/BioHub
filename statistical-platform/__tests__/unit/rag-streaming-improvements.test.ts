/**
 * RAG ìŠ¤íŠ¸ë¦¬ë° ê°œì„ ì‚¬í•­ í…ŒìŠ¤íŠ¸
 *
 * í…ŒìŠ¤íŠ¸ ëŒ€ìƒ:
 * 1. cleanThinkTags() - íƒœê·¸ ì œê±° ë¡œì§
 * 2. estimateTokenCount() - í† í° ìˆ˜ ì¶”ì •
 * 3. TextDecoder í”ŒëŸ¬ì‹œ (ë©€í‹°ë°”ì´íŠ¸ ì•ˆì „ì„±)
 * 4. AbortController + ì¬ì‹œë„ ë¡œì§
 */

import { OllamaRAGProvider } from '@/lib/rag/providers/ollama-provider'

describe('RAG ìŠ¤íŠ¸ë¦¬ë° ê°œì„ ì‚¬í•­ í…ŒìŠ¤íŠ¸', () => {
  // Helper: private ë©”ì„œë“œ ì ‘ê·¼ì„ ìœ„í•œ íƒ€ì… ìºìŠ¤íŒ…
  type OllamaProviderWithPrivate = OllamaRAGProvider & {
    cleanThinkTags(text: string): string
    estimateTokenCount(text: string): number
  }

  let provider: OllamaProviderWithPrivate

  beforeEach(() => {
    // í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ OllamaProvider ìƒì„± (ì‹¤ì œ Ollama ì„œë²„ ë¶ˆí•„ìš”)
    const rawProvider = new OllamaRAGProvider({
      name: 'Test Provider',
      embeddingModel: 'nomic-embed-text',
      inferenceModel: 'qwen2.5:7b',
      ollamaEndpoint: 'http://localhost:11434',
      vectorDbPath: '/test/rag.db',
      topK: 5,
      testMode: true
    })

    provider = rawProvider as OllamaProviderWithPrivate
  })

  describe('1. cleanThinkTags() - íƒœê·¸ ì œê±°', () => {
    it('ê¸°ë³¸ <think> íƒœê·¸ ì œê±°', () => {
      const input = 't-testëŠ”<think>ì´ê±´ ë‚´ë¶€ ì‚¬ê³ </think> ë‘ ê·¸ë£¹ì˜ í‰ê· ì„ ë¹„êµí•©ë‹ˆë‹¤.'
      const expected = 't-testëŠ” ë‘ ê·¸ë£¹ì˜ í‰ê· ì„ ë¹„êµí•©ë‹ˆë‹¤.'

      const result = provider.cleanThinkTags(input)

      expect(result).toBe(expected)
    })

    it('HTML ì´ìŠ¤ì¼€ì´í”„ëœ íƒœê·¸ ì œê±°', () => {
      const input = 'ë‹µë³€ì…ë‹ˆë‹¤.&lt;think&gt;ë‚´ë¶€ ì¶”ë¡ &lt;/think&gt; ê³„ì†ë©ë‹ˆë‹¤.'
      const expected = 'ë‹µë³€ì…ë‹ˆë‹¤. ê³„ì†ë©ë‹ˆë‹¤.'

      const result = provider.cleanThinkTags(input)

      expect(result).toBe(expected)
    })

    it('-sensitive íƒœê·¸ ì œê±°', () => {
      const input = 'ê²°ê³¼: -sensitive<think>ë¯¼ê°ì •ë³´</think> ìµœì¢… ë‹µë³€'
      const expected = 'ê²°ê³¼:  ìµœì¢… ë‹µë³€'

      const result = provider.cleanThinkTags(input)

      expect(result).toBe(expected)
    })

    it('ì—¬ëŸ¬ íƒœê·¸ ë™ì‹œ ì œê±°', () => {
      const input = '<think>A</think>í…ìŠ¤íŠ¸1&lt;think&gt;B&lt;/think&gt;í…ìŠ¤íŠ¸2-sensitive<think>C</think>í…ìŠ¤íŠ¸3'
      const expected = 'í…ìŠ¤íŠ¸1í…ìŠ¤íŠ¸2í…ìŠ¤íŠ¸3'

      const result = provider.cleanThinkTags(input)

      expect(result).toBe(expected)
    })

    it('íƒœê·¸ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜', () => {
      const input = 't-testëŠ” ë‘ ê·¸ë£¹ì˜ í‰ê· ì„ ë¹„êµí•˜ëŠ” í†µê³„ ë°©ë²•ì…ë‹ˆë‹¤.'

      const result = provider.cleanThinkTags(input)

      expect(result).toBe(input)
    })

    it('ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬', () => {
      const result = provider.cleanThinkTags('')

      expect(result).toBe('')
    })
  })

  describe('2. estimateTokenCount() - í† í° ìˆ˜ ì¶”ì •', () => {
    it('ìˆœìˆ˜ ì˜ë¬¸ í…ìŠ¤íŠ¸ (4ì â‰ˆ 1í† í°)', () => {
      const text = 'Hello world test' // 16ì â†’ ~4í† í°
      const result = provider.estimateTokenCount(text)

      expect(result).toBeGreaterThanOrEqual(3)
      expect(result).toBeLessThanOrEqual(6)
    })

    it('ìˆœìˆ˜ í•œê¸€ í…ìŠ¤íŠ¸ (2ì â‰ˆ 1í† í°)', () => {
      const text = 'ì•ˆë…•í•˜ì„¸ìš”' // 5ì â†’ ~2.5í† í°
      const result = provider.estimateTokenCount(text)

      expect(result).toBeGreaterThanOrEqual(2)
      expect(result).toBeLessThanOrEqual(4)
    })

    it('í˜¼í•© í…ìŠ¤íŠ¸ (í•œê¸€ + ì˜ë¬¸)', () => {
      const text = 't-testëŠ” ë‘ ê·¸ë£¹ì˜ í‰ê· ì„ ë¹„êµí•©ë‹ˆë‹¤.' // í•œê¸€ 14ì, ì˜ë¬¸ 6ì
      const result = provider.estimateTokenCount(text)

      // í•œê¸€: 14/2 = 7, ì˜ë¬¸: 6/4 = 1.5, êµ¬ë‘ì  ë“± â†’ ì•½ 10í† í°
      expect(result).toBeGreaterThanOrEqual(8)
      expect(result).toBeLessThanOrEqual(12)
    })

    it('ê¸´ ë¬¸ì¥', () => {
      const text = `
t-ê²€ì •(t-test)ì€ ë‘ ì§‘ë‹¨ì˜ í‰ê· ì„ ë¹„êµí•˜ëŠ” í†µê³„ì  ë°©ë²•ì…ë‹ˆë‹¤.
Student's t-testë¼ê³ ë„ ë¶ˆë¦¬ë©°, ì •ê·œì„± ê°€ì •ì„ í•„ìš”ë¡œ í•©ë‹ˆë‹¤.
      `.trim()

      const result = provider.estimateTokenCount(text)

      // ëŒ€ëµ 40-60 í† í° ì˜ˆìƒ
      expect(result).toBeGreaterThanOrEqual(30)
      expect(result).toBeLessThanOrEqual(70)
    })

    it('ë¹ˆ ë¬¸ìì—´ â†’ ìµœì†Œ 1í† í°', () => {
      const result = provider.estimateTokenCount('')

      expect(result).toBe(1)
    })

    it('ê³µë°±ë§Œ â†’ ìµœì†Œ 1í† í°', () => {
      const result = provider.estimateTokenCount('   ')

      expect(result).toBeGreaterThanOrEqual(1)
    })

    it('ì´ëª¨ì§€ í¬í•¨', () => {
      const text = 'í†µê³„ ë¶„ì„ ğŸ˜Š ë°ì´í„° ê³¼í•™ ğŸ”¬'
      const result = provider.estimateTokenCount(text)

      // ì´ëª¨ì§€ëŠ” ì—¬ëŸ¬ ë°”ì´íŠ¸ì´ì§€ë§Œ í† í° ìˆ˜ëŠ” 1-2ê°œ ì •ë„
      expect(result).toBeGreaterThanOrEqual(5)
      expect(result).toBeLessThanOrEqual(15)
    })
  })

  describe('3. TextDecoder í”ŒëŸ¬ì‹œ (ë©€í‹°ë°”ì´íŠ¸ ì•ˆì „ì„±)', () => {
    it('UTF-8 ë©€í‹°ë°”ì´íŠ¸ ë¬¸ì ë””ì½”ë”©', () => {
      // "ì•ˆë…•" ë¬¸ìì—´ì„ UTF-8 ë°”ì´íŠ¸ë¡œ ë¶„í• 
      const encoder = new TextEncoder()
      const bytes = encoder.encode('ì•ˆë…•')

      // TextDecoder í”ŒëŸ¬ì‹œ ì—†ì´ (ì˜ëª»ëœ ë°©ë²•)
      const decoderWithoutFlush = new TextDecoder()
      const chunk1 = decoderWithoutFlush.decode(bytes.slice(0, 3), { stream: true })
      const chunk2 = decoderWithoutFlush.decode(bytes.slice(3, 6), { stream: true })
      // ë§ˆì§€ë§‰ í”ŒëŸ¬ì‹œ ì—†ìŒ â†’ ë§ˆì§€ë§‰ ë°”ì´íŠ¸ ì†ì‹¤ ê°€ëŠ¥

      // TextDecoder í”ŒëŸ¬ì‹œ ìˆìŒ (ì˜¬ë°”ë¥¸ ë°©ë²•)
      const decoderWithFlush = new TextDecoder()
      const chunk3 = decoderWithFlush.decode(bytes.slice(0, 3), { stream: true })
      const chunk4 = decoderWithFlush.decode(bytes.slice(3, 6), { stream: true })
      const flush = decoderWithFlush.decode() // í”ŒëŸ¬ì‹œ í˜¸ì¶œ

      const withFlush = chunk3 + chunk4 + flush
      expect(withFlush).toBe('ì•ˆë…•')
    })

    it('ìŠ¤íŠ¸ë¦¼ ëì—ì„œ ë¶ˆì™„ì „í•œ ë©€í‹°ë°”ì´íŠ¸ ë¬¸ì ì²˜ë¦¬', () => {
      const encoder = new TextEncoder()
      const bytes = encoder.encode('í…ŒìŠ¤íŠ¸') // 9ë°”ì´íŠ¸ (í•œê¸€ 3ì Ã— 3ë°”ì´íŠ¸)

      const decoder = new TextDecoder()

      // 8ë°”ì´íŠ¸ë§Œ ì½ìŒ (ë§ˆì§€ë§‰ 1ë°”ì´íŠ¸ ë‚¨ìŒ)
      const partial = decoder.decode(bytes.slice(0, 8), { stream: true })
      const finalFlush = decoder.decode() // ë‚¨ì€ 1ë°”ì´íŠ¸ í”ŒëŸ¬ì‹œ

      const result = partial + finalFlush
      expect(result).toBe('í…ŒìŠ¤íŠ¸')
    })
  })

  describe('4. AbortController + ì¬ì‹œë„ ë¡œì§ (í†µí•© ì‹œë‚˜ë¦¬ì˜¤)', () => {
    it('AbortController ì‹œê·¸ë„ ì „ë‹¬ í™•ì¸ (Mock)', () => {
      const abortController = new AbortController()

      // AbortSignal ê°ì²´ ìƒì„± í™•ì¸
      expect(abortController.signal).toBeDefined()
      expect(abortController.signal.aborted).toBe(false)

      // ì·¨ì†Œ í˜¸ì¶œ
      abortController.abort()
      expect(abortController.signal.aborted).toBe(true)
    })

    it('Exponential backoff ê³„ì‚°', () => {
      // ì¬ì‹œë„ ì§€ì—° ì‹œê°„ ê²€ì¦
      const delays = [1, 2, 3].map((attempt) => 1000 * Math.pow(2, attempt - 1))

      expect(delays).toEqual([1000, 2000, 4000]) // 1s, 2s, 4s
    })

    it('AbortError ë°œìƒ ì‹œ ì¦‰ì‹œ ì¢…ë£Œ', async () => {
      const abortController = new AbortController()
      abortController.abort()

      const error = new Error('Aborted')
      error.name = 'AbortError'

      // AbortErrorëŠ” ì¬ì‹œë„ ì—†ì´ ì¦‰ì‹œ ì „íŒŒë˜ì–´ì•¼ í•¨
      expect(error.name).toBe('AbortError')
    })
  })

  describe('5. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°', () => {
    it('TTFT ê³„ì‚° (ì²« í† í°ê¹Œì§€ ì‹œê°„)', () => {
      const generationStartTime = Date.now()
      const firstTokenTime = generationStartTime + 342 // 342ms í›„ ì²« í† í°

      const ttft = firstTokenTime - generationStartTime

      expect(ttft).toBe(342)
    })

    it('TPS ê³„ì‚° (ì´ˆë‹¹ í† í° ìˆ˜)', () => {
      const tokenCount = 87
      const generationTime = 3000 // 3ì´ˆ

      const tokensPerSecond = (tokenCount / generationTime) * 1000

      expect(tokensPerSecond).toBeCloseTo(29.0, 1) // 87 / 3 = 29 TPS
    })

    it('TPS: 0ì´ˆ ë°©ì–´ ì²˜ë¦¬', () => {
      const tokenCount = 10
      const generationTime = 0

      const tokensPerSecond = generationTime > 0 ? (tokenCount / generationTime) * 1000 : undefined

      expect(tokensPerSecond).toBeUndefined()
    })
  })

  describe('6. ì‹¤ì œ ìŠ¤íŠ¸ë¦¬ë° ì‹œë‚˜ë¦¬ì˜¤ (Mock)', () => {
    it('ì²­í¬ë³„ íƒœê·¸ ì œê±° + í† í° ì¹´ìš´íŒ…', () => {
      const chunks = [
        't-testëŠ” ',
        '<think>ë‚´ë¶€ ì¶”ë¡ </think>',
        'ë‘ ê·¸ë£¹ì˜ ',
        'í‰ê· ì„ ë¹„êµí•©ë‹ˆë‹¤.',
      ]

      let fullAnswer = ''
      let tokenCount = 0

      for (const chunk of chunks) {
        const cleanedChunk = provider.cleanThinkTags(chunk)
        fullAnswer += cleanedChunk
        tokenCount += provider.estimateTokenCount(cleanedChunk)
      }

      expect(fullAnswer).toBe('t-testëŠ” ë‘ ê·¸ë£¹ì˜ í‰ê· ì„ ë¹„êµí•©ë‹ˆë‹¤.')
      expect(tokenCount).toBeGreaterThan(0)
    })

    it('ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ë©”íƒ€ë°ì´í„° ìƒì„±', () => {
      const startTime = Date.now()
      const firstTokenTime = startTime + 200
      const endTime = startTime + 2500
      const tokenCount = 45

      const responseTime = endTime - startTime
      const ttft = firstTokenTime - startTime
      const generationTime = endTime - startTime
      const tokensPerSecond = (tokenCount / generationTime) * 1000

      const metadata = {
        responseTime,
        tokensUsed: tokenCount,
        ttft,
        tokensPerSecond,
      }

      expect(metadata.responseTime).toBe(2500)
      expect(metadata.ttft).toBe(200)
      expect(metadata.tokensUsed).toBe(45)
      expect(metadata.tokensPerSecond).toBeCloseTo(18.0, 1)
    })
  })
})
