# BioResearch Platform 계획서

**작성일**: 2026-02-06
**목표**: 생물학 연구자를 위한 올인원 연구 도구 플랫폼
**원칙**: 단순 AI wrapper가 아닌, 실제 계산/검증/가공 엔진
**상태**: 계획 단계 (v1.0)

---

## 1. 비전

### 1-1. 대상 사용자 (페르소나)

| 페르소나 | 설명 | 주요 니즈 |
|----------|------|----------|
| **수산과학 연구자** (1차) | 양식/어류생태 연구, 대학원생~교수 | 통계 분석 + 성장곡선 + 학명검증 + 논문작성 |
| **해양생태 연구자** | 생물다양성/군집 연구 | 생태지수 + 공간분석 + 종 분포도 |
| **분자생물 연구자** | 개체군유전/계통분류 | NCBI 연동 + 유전다양성 + 계통수 |
| **환경모니터링 담당자** | 수질/환경 데이터 관리 | 수질기준 판정 + 시계열 분석 |

### 1-2. 현재 연구자의 워크플로우 (문제점)

```
종 동정     → WoRMS 웹사이트 수동 검색
    ↓
데이터 수집  → Excel에서 정리
    ↓
통계 분석   → SPSS/R 별도 프로그램
    ↓
유전자 분석 → NCBI 웹사이트 별도 접속
    ↓
문헌 조사   → PubMed/Google Scholar 별도 접속
    ↓
논문 작성   → Word/한글에서 수동으로 표/그래프 복사-붙여넣기
```

**문제**: 6개 이상의 도구를 오가며 복사-붙여넣기 반복. 데이터 흐름이 끊김.

### 1-3. 목표 워크플로우

```
[BioResearch Platform - 하나의 브라우저 탭]

1. 종 정보 조회
   학명 입력 → 분류체계 + 생태정보 + 분포도 + 관련 논문 한번에

2. 데이터 분석
   CSV 업로드 → 자동 변수 탐지 → 통계 추천 → 분석 실행 → 결과

3. 결과 활용
   분석 결과 → APA 표 자동 생성 → 논문 Methods/Results 초안
   분석 결과 → 관련 논문 자동 검색 → 선행연구 비교

4. 기록 관리
   모든 분석 히스토리 자동 저장 → 재현 가능
```

### 1-4. 핵심 차별점

| 차별점 | 설명 |
|--------|------|
| **데이터 프라이버시** | 모든 계산이 브라우저 내 실행 (서버 전송 없음) |
| **워크플로우 연결** | 외부 API 조회 → 우리 엔진으로 가공 → 논문 도구로 출력 |
| **도메인 특화** | 수산/해양/생물학 용어, 예시, 기준값 내장 |
| **오프라인 가능** | Pyodide + 로컬 DB → 인터넷 없이도 통계 분석 |

### 1-5. 경쟁 환경 분석

| 기존 도구 | 강점 | 약점 (우리의 기회) |
|-----------|------|-------------------|
| **SPSS** | 통계 표준, 신뢰성 | 비쌈 ($100+/월), 생태 도구 없음, 외부 DB 연동 없음 |
| **R/RStudio** | 무료, 확장성 | 코딩 필요, 비전문가 진입장벽 높음 |
| **FishStatJ** (FAO) | 수산 특화 | 구식 UI, 통계 기능 제한적, 오프라인 전용 |
| **PAST** (palaeontology) | 무료, 생태지수 | 고급 통계 부족, 외부 연동 없음, 구식 |
| **rfishbase** (R) | FishBase 연동 | R 코딩 필수, UI 없음 |
| **Galaxy** (bioinformatics) | 시퀀싱 파이프라인 | 통계/생태 분석 약함, 서버 필요 |

**우리의 포지션**: SPSS급 통계 + PAST급 생태지수 + rfishbase급 DB연동 → **코딩 없이, 브라우저에서, 무료로**

---

## 2. 현재 자산

| 자산 | 상태 | 기술 |
|------|------|------|
| 통계 분석 엔진 | 45개 메서드 완료 | Pyodide (SciPy, statsmodels, pingouin) |
| Smart Flow | 자연어 → 통계 추천 | Decision Tree + LLM |
| 학명 검증 서비스 | 별도 존재 (별도 레포) | WoRMS API 기반, Next.js 앱 (통합 필요) |
| RAG 시스템 | 기본 구현 | Ollama + sql.js + IndexedDB |
| 시각화 엔진 | 7종 차트 | matplotlib + Plotly (Pyodide) |
| Design System | 11개 섹션 | shadcn/ui + Tailwind |

---

## 3. 서비스 모듈 설계

> **참고**: 모듈 번호(A~F)는 기능 분류 순서이고, 구현 순서(Phase 15-1~6)와 다름.
> 구현은 의존성/난이도 기준으로 정함 (5장 참조).

### Module A: 종 정보 허브 (Species Intelligence Hub)

**목적**: 학명 하나로 모든 생물 정보를 한 화면에

**워크플로우**:
```
학명 입력: "Paralichthys olivaceus"
    │
    ├─[WoRMS API]─→ 분류 체계 (Kingdom → Species)
    │                 동의어 목록, 유효명 확인
    │
    ├─[FishBase API]─→ 생태 정보
    │                   최대 체장/체중, 서식 수심
    │                   분포 해역, 식성
    │
    ├─[GBIF API]─→ 전세계 채집 기록 (위경도)
    │               │
    │               └─[우리 엔진]─→ 분포 지도 시각화 (Leaflet)
    │                               공간 통계 (밀도, 클러스터)
    │                               시기별 출현 패턴 분석
    │
    ├─[OBIS API]─→ 해양생물 채집 기록 (GBIF 보완)
    │               해양 특화 메타데이터 (수심, 수온)
    │
    ├─[NCBI Taxonomy]─→ TaxID, 유전자 정보 링크
    │
    └─[OpenAlex API]─→ 관련 논문 목록
                        │
                        └─[우리 엔진]─→ 연도별 논문 수 트렌드
                                        주요 연구 주제 워드클라우드
                                        인용 네트워크 시각화
```

**우리가 가공하는 부분** (핵심 가치):
- GBIF/OBIS 좌표 데이터 → **공간 통계** (커널 밀도 추정, 핫스팟 분석)
  - 주의: Moran's I 등 고급 공간통계는 PySAL 라이브러리 필요. Pyodide에서 PySAL 미지원 시 → 커널 밀도 + scipy 기반 대안 사용
- GBIF 시계열 → **출현 패턴 분석** (계절성, 장기 변동)
- FishBase 성장 파라미터 → **von Bertalanffy 곡선 시각화** + 사용자 데이터 비교
- OpenAlex 논문 데이터 → **연구 트렌드 분석** (연도별, 주제별)

**기술 구현**:
- 외부 API: `fetch()` (CORS 지원 API) 또는 Cloudflare Workers 프록시
- 지도: Leaflet.js (오픈소스, 서버 불필요)
- 통계: Pyodide (기존 엔진 확장)
- 캐시: IndexedDB (동일 종 재조회 방지, TTL 24시간)

**API 장애 대응**:
- 각 API 독립 호출 → 하나 실패해도 나머지 표시
- 실패 시 "데이터 없음" 표시 + 재시도 버튼
- IndexedDB 캐시가 있으면 오프라인에서도 이전 결과 표시

---

### Module B: 생태 분석 도구 (Ecological Analysis Tools)

**목적**: 수산/생태학 전용 분석 도구 (기존 통계 엔진 확장)

#### B-1. 생물다양성 지수 계산기

**입력**: 종별 개체수 데이터 (CSV)
```csv
종명,개체수
넙치,45
조피볼락,32
참돔,18
방어,7
```

**출력**:
| 지수 | 값 | 해석 |
|------|-----|------|
| Shannon-Wiener (H') | 1.24 | 중간 다양성 |
| Simpson (1-D) | 0.71 | 높은 우점도 |
| Margalef (d) | 0.74 | 낮은 풍부도 |
| Pielou 균등도 (J') | 0.89 | 높은 균등성 |
| 종 풍부도 (S) | 4 | - |

**가공**: 단순 계산이 아니라 → **비교 분석**
- 지역 간 다양성 비교 (Hutcheson's t-test for Shannon H')
- 시기별 다양성 변화 추이 (시계열)
- 희귀화 곡선 (Rarefaction curve) — 표본 크기 보정
- 종-면적 관계 (Species-Area Relationship)

**기술**: `scipy.stats` + `numpy` (Pyodide), 모든 지수 수식 직접 구현 (단순 공식)

**결과 내보내기**: CSV + APA 형식 표

#### B-2. 성장 곡선 분석

**입력**: 연령-체장 데이터
```csv
연령(년),체장(cm)
1,15.2
1,16.1
2,25.3
2,24.8
3,32.1
...
```

**출력**:
- von Bertalanffy: L(t) = L_inf * (1 - exp(-K * (t - t0)))
- Gompertz: L(t) = L_inf * exp(-b * exp(-K * t))
- Logistic 성장 모델
- 모델 비교 (AIC/BIC)
- 성장 곡선 그래프 + 95% 신뢰구간

**가공**:
- 모델 파라미터 추정 (L_inf, K, t0) + 표준오차
- FishBase의 기존 성장 파라미터와 **자동 비교** (핵심)
  → "본 연구의 L_inf=42.3cm은 FishBase 기록(45.0cm)과 유사하다"
- 성별 간 성장 차이 검정 (Likelihood Ratio Test)
- 성장 성능 지수 (Growth Performance Index, φ') 계산

**기술**: `scipy.optimize.curve_fit` (Pyodide)

#### B-3. 체장-체중 관계식

**입력**: 체장, 체중 데이터
**출력**: W = aL^b (log-log 선형 회귀)
- 파라미터 a, b 추정 + 95% CI
- b=3 (등척성장) 여부 t-검정
- 비만도 (Condition Factor, K = W/L^3 * 100) 계산
- FishBase 기록값과 자동 비교

#### B-4. CPUE 분석 (단위노력당어획량)

**입력**: 날짜, 어획량, 노력량 데이터
**출력**:
- CPUE 시계열 그래프
- 계절 분해 (seasonal decomposition) — statsmodels
- 추세 분석 (Mann-Kendall test) ← 기존 통계 엔진 활용
- 자원량 지수 추정

#### B-5. 수질 기준 판정

**입력**: 수온, DO, pH, 염분, 탁도 등
**출력**:
- 환경부 수질환경기준 / 해양수산부 해양환경기준 자동 판정
- 기준 초과 항목 강조 (색상 표시)
- 시계열 변화 그래프 + 기준선 오버레이
- 항목 간 상관분석 (기존 엔진 활용)

**기준값**: JSON으로 내장 (환경부 고시 기준, 업데이트 가능)

---

### Module C: 문헌 도구 (Literature Intelligence)

**목적**: 논문 검색 + 결과 가공 (단순 검색 창이 아님)

#### C-1. 스마트 문헌 검색

**워크플로우**:
```
[사용자가 ANOVA 분석 완료]
    │
    ├─ 자동 키워드 추출: "one-way ANOVA" + "Paralichthys olivaceus" + "body weight"
    │
    └─[OpenAlex API]─→ 관련 논문 50건
                        │
                        └─[우리 엔진]─→ 분석 결과 가공:
                            ├─ 연도별 논문 수 그래프
                            ├─ 주요 저자 네트워크
                            ├─ 학술지별 분포 (pie chart)
                            ├─ 키워드 공출현 네트워크
                            └─ "이 분석과 유사한 통계를 사용한 논문" 필터
```

**핵심 가치**: "비슷한 분석을 한 선행연구"를 자동으로 찾아줌

#### C-2. 메타분석 지원

**워크플로우**:
```
[사용자가 여러 논문의 효과크기를 입력]
논문1: Cohen's d = 0.45, n=30
논문2: Cohen's d = 0.62, n=25
논문3: Cohen's d = 0.38, n=50
    │
    └─[우리 엔진]─→
        ├─ Forest Plot 생성
        ├─ 통합 효과크기 (Random/Fixed effects model)
        ├─ 이질성 검정 (Q, I-squared, tau-squared)
        ├─ 출판 편향 (Funnel plot, Egger's test)
        └─ 논문용 표 자동 생성 (APA 형식)
```

**기술**: `scipy.stats` + 자체 구현 (DerSimonian-Laird 추정 등)
- 전용 Python 메타분석 라이브러리(PythonMeta)는 Pyodide 호환 미확인 → scipy 기반 자체 구현이 안전

#### C-3. 인용 관리 (가벼운 버전)

- DOI 입력 → CrossRef API → 서지 정보 자동 추출
- APA 7th / KCI / Vancouver 형식 자동 변환
- BibTeX 내보내기
- Zotero/Mendeley 대체가 아니라 **빠른 참고문헌 생성** 용도

---

### Module D: 논문 작성 도구 (Academic Writing Tools)

**목적**: 분석 결과 → 논문 구성요소 자동 생성

#### D-1. 통계 보고서 자동 생성

**핵심**: 방금 돌린 분석에서 바로 생성 (AI wrapper가 아닌 데이터 바인딩)

```
[ANOVA 분석 완료 → 버튼 클릭]

출력 1: Methods 섹션 (템플릿 + 데이터)
─────────────────────────────────
"사료 종류(A, B, C)가 넙치 체중에 미치는 영향을 검증하기 위해
일원배치 분산분석(one-way ANOVA)을 실시하였다. 사전에
Shapiro-Wilk 정규성 검정(W=0.967, p=.142)과
Levene의 등분산성 검정(F(2,57)=1.23, p=.300)을
실시하여 모수 검정의 가정을 확인하였다."

출력 2: Results 섹션
─────────────────────────────────
"사료 종류에 따른 넙치 체중의 차이는 통계적으로 유의하였다,
F(2, 57) = 4.23, p = .019, eta-sq = .129.
Tukey HSD 사후검정 결과, 사료 A(M=245.3, SD=32.1)와
사료 C(M=212.8, SD=28.7) 간 유의한 차이가 있었다(p=.014)."

출력 3: APA 표
─────────────────────────────────
Table 1
One-Way ANOVA Results for Body Weight by Feed Type
───────────────────────────────
Source    SS        df    MS       F      p      eta-sq
───────────────────────────────
Between   12345.6   2    6172.8   4.23   .019   .129
Within    83210.4   57   1459.8
Total     95556.0   59
───────────────────────────────

출력 4: Figure + Caption
─────────────────────────────────
[막대 그래프 자동 생성]
"Fig. 1. Mean body weight (+-SD) of P. olivaceus by feed type.
Different letters indicate significant differences (Tukey HSD, p < .05)."
```

**LLM 역할** (보조적):
- 템플릿에서 자연스러운 문장 연결
- 한국어/영어 전환
- 학술지 스타일 맞춤 (한국수산과학회지, Aquaculture, Fisheries Research 등)

#### D-2. 분석 히스토리 (연구 로그)

```
[자동 기록 - 사용자 개입 없음]

2026-02-06 14:30  데이터 업로드: 넙치_사료실험_2026.csv (60행, 5변수)
2026-02-06 14:31  정규성 검정: 체중 → 정규 (p=.142)
2026-02-06 14:32  등분산성 검정: 사료종류별 → 등분산 (p=.300)
2026-02-06 14:33  ANOVA 실행: F(2,57)=4.23, p=.019 *
2026-02-06 14:34  사후검정: Tukey HSD → A-C 유의차 (p=.014)
2026-02-06 14:35  보고서 생성: anova_results_20260206.docx
```

**가치**:
- 분석 재현성 보장 (동일 데이터 + 동일 설정 → 동일 결과)
- "이전에 어떤 분석했더라?" 검색 가능
- 논문 리뷰어 대응: "분석 과정을 보여주세요" → 로그 내보내기 (JSON/CSV)

**저장**: IndexedDB (브라우저 로컬, 서버 전송 없음)

---

### Module E: NCBI 연결 + 가공

**목적**: 유전자/서열 데이터를 조회하고, 통계적으로 가공

#### E-1. 유전자 정보 조회

```
[종명 또는 유전자명 입력]
    │
    ├─[NCBI Entrez API]─→ 유전자 목록
    │                      서열 정보 (FASTA)
    │                      관련 논문 (PubMed)
    │
    └─[우리 엔진]─→ 가공:
        ├─ 서열 기본 통계 (GC content, 길이 분포)
        ├─ 여러 종의 동일 유전자 비교 → 유사도 행렬
        ├─ 유사도 행렬 → 클러스터 분석 (기존 엔진)
        ├─ 계통수 시각화 (UPGMA/NJ - 간단한 수준)
        └─ 유전적 다양성 지수 (nucleotide diversity pi, haplotype diversity)
```

#### E-2. Population Genetics (개체군 유전학)

```
[미토콘드리아 DNA haplotype 데이터 업로드]
    │
    └─[Pyodide 엔진]─→
        ├─ Haplotype 빈도 분석
        ├─ Hardy-Weinberg 평형 검정 (chi-square 기반, scipy.stats)
        ├─ Fst (유전적 분화도) 계산 (Weir & Cockerham)
        ├─ AMOVA (분자분산분석) — scipy 기반 자체 구현
        ├─ Mantel test (유전적 거리 vs 지리적 거리) — scipy.stats
        └─ Haplotype network 시각화 (Minimum Spanning Network)
```

**기술 제약**:
- 전용 개체군유전 라이브러리 (Arlequin, GenAlEx)는 데스크탑 전용 → Pyodide 불가
- scipy.stats + numpy로 핵심 검정 자체 구현 (공식이 명확한 것들)
- 대규모 서열 정렬(alignment)은 범위 밖 → NCBI BLAST 결과를 가져와서 분석

**주의**: BLAST 같은 대규모 서열 정렬은 하지 않음 (NCBI가 이미 최고).
우리는 **결과를 가져와서 통계 분석**하는 것.

---

### Module F: 데이터 변환/정리 도구

**목적**: 연구자의 반복적인 데이터 정리 작업 자동화

| 도구 | 입력 | 출력 |
|------|------|------|
| **와이드↔롱 변환** | 반복측정 데이터 | tidydata 형식 |
| **이상치 탐지** | 수치 데이터 | Grubbs/IQR 결과 + 시각화 |
| **결측치 처리** | 결측 있는 데이터 | 보간(선형/스플라인)/대치(평균/중위수) 옵션 |
| **정규성 일괄 검정** | 여러 변수 | Shapiro-Wilk 결과표 |
| **데이터 코딩** | 범주형 변수 | 더미/효과 코딩 |
| **단위 변환** | mm→cm, g→kg 등 | 변환된 열 추가 |

---

## 4. 아키텍처

### 전체 구조

```
+------------------------------------------------------+
|              BioResearch Platform (브라우저)            |
|                                                       |
|  +--------------------------------------------------+ |
|  |          Workflow Hub (워크플로우 허브)              | |
|  |  분석 히스토리 | 데이터 파이프라인 | 연구 로그       | |
|  +--------+-----------------+----------------+------+ |
|           |                 |                |        |
|  +--------+---+  +----------+-----+  +-------+-----+ |
|  | 계산 엔진   |  | 외부 연결       |  | 출력 도구    | |
|  | (Pyodide)  |  | (API Hub)      |  | (Export)    | |
|  |            |  |                |  |             | |
|  | 통계 분석   |  | WoRMS (CORS)  |  | APA 표      | |
|  | 생태 지수   |  | FishBase      |  | 논문 초안    | |
|  | 성장 곡선   |  | GBIF (CORS)   |  | PDF 보고서  | |
|  | 메타분석    |  | OBIS (CORS)   |  | 분석 로그   | |
|  | 개체군유전  |  | NCBI (Proxy)  |  | 서지정보    | |
|  | 공간 통계   |  | OpenAlex(CORS)|  | CSV/Excel   | |
|  +------------+  | CrossRef(CORS)|  +-------------+ |
|                  +---------------+                    |
|  +--------------------------------------------------+ |
|  |                 공통 인프라                         | |
|  |  IndexedDB(캐시) | Leaflet(지도) | LLM(보조)      | |
|  +--------------------------------------------------+ |
+------------------------------------------------------+
         |                    |
    Cloudflare Pages     Cloudflare Workers
    (정적 호스팅)        (API 키 프록시, CORS 프록시)
```

### 외부 API 상세

| API | Base URL | CORS | 인증 | Rate Limit | 데이터 형식 |
|-----|----------|:----:|------|-----------|------------|
| **WoRMS** | `marinespecies.org/rest` | ✅ | 불필요 | - | JSON |
| **GBIF** | `api.gbif.org/v1` | ✅ | 불필요 | - | JSON |
| **OBIS** | `api.obis.org/v3` | ✅ | 불필요 | - | JSON |
| **OpenAlex** | `api.openalex.org` | ✅ | 불필요 (polite pool: email) | 100,000/일 | JSON |
| **CrossRef** | `api.crossref.org` | ✅ | 불필요 (polite pool: email) | 50/초 | JSON |
| **NCBI Entrez** | `eutils.ncbi.nlm.nih.gov` | ❌ | API key 권장 | 10/초 (key 없을 때 3/초) | JSON/XML |
| **FishBase** | `fishbase.ropensci.org` | ⚠️ 미확인 | 불필요 | - | JSON |
| **BOLD** | `v4.boldsystems.org/api` | ⚠️ 미확인 | 불필요 | - | JSON/TSV |

```
[CORS 지원 - 브라우저 직접 호출]
├── WoRMS REST API ✅ (검증됨)
├── GBIF API ✅ (검증됨)
├── OBIS API ✅ (검증됨)
├── OpenAlex API ✅ (검증됨)
└── CrossRef API ✅ (검증됨)

[CORS 미지원 - Cloudflare Workers 프록시 필요]
├── NCBI Entrez API ❌ (검증됨: Access-Control-Allow-Origin 헤더 없음)
├── FishBase API ⚠️ (미검증, 프록시 준비 필요)
├── BOLD Systems API ⚠️ (미검증, 프록시 준비 필요)
└── OpenRouter (LLM) ❌ (API 키 보호 겸용)
```

### 데이터 흐름 패턴

```
Pattern 1: 조회 → 가공 → 시각화
[외부 API] → JSON → [Pyodide 통계] → [차트/표] → [논문 도구]

Pattern 2: 업로드 → 분석 → 보고서
[CSV 업로드] → [Pyodide 분석] → [결과] → [APA 보고서]

Pattern 3: 분석 → 문헌 연결
[분석 결과] → [키워드 추출] → [OpenAlex 검색] → [관련 논문]

Pattern 4: 외부 데이터 → 비교 분석
[FishBase 기준값] + [사용자 데이터] → [비교 통계] → [보고서]
```

### API 장애 대응 전략

| 상황 | 대응 |
|------|------|
| 특정 API 타임아웃 | 10초 타임아웃 → "데이터 조회 실패" + 재시도 버튼 |
| 특정 API 일시 장애 | 다른 API 결과는 정상 표시 (독립 호출) |
| CORS 프록시(Workers) 장애 | NCBI/FishBase 패널만 비활성화, 나머지 정상 |
| 전체 오프라인 | Pyodide 기반 기능 (통계, 생태지수) 100% 동작, API 연동만 비활성 |
| 반복 조회 | IndexedDB 캐시 (TTL 24시간) → API 호출 절약 |

---

## 5. 구현 로드맵

> 구현 순서는 모듈 번호(A~F)가 아닌, **의존성/위험도** 기준.
> Phase 15-1(Module B)을 먼저 하는 이유: 외부 API 의존 없이 Pyodide만으로 구현 가능.

### Phase 15-1: 생태 분석 도구 (Module B) — 2주

**이유**: 기존 Pyodide 엔진 확장만으로 구현. 외부 의존 없음. 가장 낮은 위험.

| 기능 | 시간 | 기술 |
|------|------|------|
| 생물다양성 지수 계산기 | 2일 | scipy, numpy |
| 성장 곡선 분석 (vBGF) | 2일 | scipy.optimize |
| 체장-체중 관계식 | 1일 | scipy.stats (기존 회귀 확장) |
| CPUE 분석 | 2일 | statsmodels (시계열) |
| 수질 기준 판정 | 1일 | 규칙 기반 |
| UI + 테스트 | 2일 | |

### Phase 15-2: 종 정보 허브 (Module A) — 2주

**이유**: 외부 API 연결 + 결과 가공의 핵심 모듈. Cloudflare Workers 설정 포함.

| 기능 | 시간 | 기술 |
|------|------|------|
| WoRMS 연동 + 학명 검증 통합 | 2일 | fetch API |
| FishBase 연동 + 생태정보 표시 | 2일 | fetch API (+ Workers 프록시) |
| GBIF + OBIS 연동 + 분포 지도 | 3일 | Leaflet.js |
| GBIF/OBIS 데이터 통계 가공 | 2일 | Pyodide |
| Cloudflare Workers 프록시 셋업 | 1일 | Wrangler |

### Phase 15-3: 문헌 도구 (Module C) — 1.5주

| 기능 | 시간 | 기술 |
|------|------|------|
| OpenAlex 논문 검색 | 2일 | fetch API |
| 검색 결과 통계 가공 (트렌드, 저자 등) | 2일 | Pyodide |
| CrossRef DOI → 서지정보 | 1일 | fetch API |
| 인용 형식 변환 (APA 7th / KCI) | 1일 | 템플릿 기반 |
| 메타분석 도구 (Forest plot) | 2일 | Pyodide + Plotly |

### Phase 15-4: 논문 작성 도구 (Module D) — 1.5주

| 기능 | 시간 | 기술 |
|------|------|------|
| 분석 → Methods/Results 자동 생성 | 3일 | 템플릿 + LLM 보조 |
| APA 표 자동 포맷팅 | 2일 | 규칙 기반 |
| Figure caption 생성 | 1일 | 템플릿 |
| 분석 히스토리 로그 | 2일 | IndexedDB |

### Phase 15-5: NCBI 연결 + 개체군유전 (Module E) — 2주

| 기능 | 시간 | 기술 |
|------|------|------|
| NCBI Entrez 연동 (Workers 프록시) | 2일 | Cloudflare Workers |
| 서열 기본 통계 | 1일 | Pyodide (자체 구현) |
| 개체군 유전학 도구 (Fst, HWE, AMOVA) | 4일 | Pyodide (scipy 기반 자체 구현) |
| Haplotype network 시각화 | 3일 | D3.js (force-directed graph) |

### Phase 15-6: 데이터 도구 + 통합 (Module F) — 1주

| 기능 | 시간 | 기술 |
|------|------|------|
| 와이드↔롱 변환 | 1일 | Pyodide (pandas) |
| 이상치/결측치 도구 | 1일 | 기존 엔진 확장 |
| 단위 변환 | 0.5일 | 규칙 기반 |
| 통합 테스트 + UX 개선 | 2일 | |

### 총 예상 일정

| Phase | 기간 | 의존성 | 목표 시점 |
|-------|------|--------|----------|
| 15-1 생태 분석 | 2주 | 없음 (즉시 시작 가능) | Q1 2026 |
| 15-2 종 정보 허브 | 2주 | Cloudflare 배포 후 | Q1 2026 |
| 15-3 문헌 도구 | 1.5주 | 15-2와 병렬 가능 | Q2 2026 |
| 15-4 논문 작성 | 1.5주 | 15-1 완료 후 | Q2 2026 |
| 15-5 NCBI + 유전 | 2주 | 15-2 Workers 후 | Q2 2026 |
| 15-6 데이터 도구 | 1주 | 아무때나 | Q2 2026 |
| **합계** | **~10주** | | |

---

## 6. Cloudflare 배포 가이드

> ROADMAP.md Phase 10-0에도 요약 기재. 여기서는 상세 버전.

### 즉시 배포 (개인용)

**현재 상태**: 바로 배포 가능

| 항목 | 현재 상태 | Cloudflare Pages 제한 | 판정 |
|------|----------|---------------------|------|
| 빌드 크기 | ~34MB | 제한 없음 | OK |
| 최대 파일 | 4.4MB (Plotly 청크) | 25MB | OK |
| 서버 런타임 | 없음 (순수 정적) | 정적만 가능 | OK |
| Pyodide | CDN 로드 (~40MB 코어+scipy) | 사용자 브라우저 캐싱 | OK |
| API routes | 없음 | 없음 | OK |

**참고**: Pyodide 오프라인 번들은 ~200MB이지만, CDN 모드에서는 코어(~10MB) + 필요 패키지(scipy ~30MB)만 다운로드. 브라우저 캐시로 재방문 시 다운로드 없음.

**배포 명령**:
```bash
cd stats
pnpm build
npx wrangler pages deploy out --project-name=stats
```

### 배포 시 필수 설정

**1. SPA 라우팅 (`public/_redirects`)**:
```
/* /index.html 200
```

**2. 캐시 헤더 (`public/_headers`)**:
```
/*.wasm
  Cache-Control: public, max-age=31536000, immutable

/*.js
  Cache-Control: public, max-age=86400

/index.html
  Cache-Control: no-cache
```

**3. 환경변수** (Pages 대시보드에서 설정):
```
NEXT_PUBLIC_OPENROUTER_API_KEY=xxx  (빌드 시 주입)
NEXT_PUBLIC_PYODIDE_USE_LOCAL=false
```

### 서비스 전환 시 추가 사항

| 문제 | 개인용 | 서비스 시 |
|------|--------|----------|
| API 키 노출 | `NEXT_PUBLIC_` 브라우저 노출 | Workers 프록시 필수 |
| 사용자 인증 | 없음 | Cloudflare Access 또는 자체 auth |
| Rate Limiting | 본인만 사용 | Workers에서 사용자별 제한 |
| 대역폭 | 무료 100GB/월 (~2,500명) | 유료 플랜 검토 |
| CORS 프록시 | 불필요 | NCBI, FishBase 등 필요 |

### Workers 프록시 아키텍처 (서비스 시)

```
[브라우저]
    +--> 정적 파일 --> Cloudflare Pages (직접)
    |
    +--> API 호출 --> Cloudflare Workers
                      +-- /api/llm      --> OpenRouter (키 숨김)
                      +-- /api/ncbi     --> NCBI Entrez (CORS 프록시)
                      +-- /api/fishbase --> FishBase (CORS 프록시)
                      +-- /api/bold     --> BOLD Systems (CORS 프록시)
```

---

## 7. 빌드 vs 연결 vs 안함 최종 정리

### 빌드 (우리가 직접 만듦)

| 기능 | 이유 |
|------|------|
| 통계 분석 엔진 | 핵심 (이미 완료) |
| 생태 분석 도구 | Pyodide 확장, 도메인 차별화 |
| 논문 보고서 생성 | 분석 결과 연동이 핵심 가치 |
| 분석 히스토리 | 연구 재현성 보장 |
| 메타분석 | 기존 통계 엔진 활용 |
| 개체군 유전학 | Pyodide scipy 기반 자체 구현 |
| 데이터 변환 도구 | 연구자 생산성 |

### 연결 + 가공 (외부 API 조회 → 우리가 통계 가공)

| 외부 서비스 | 가져오는 것 | 우리가 가공하는 것 |
|------------|-----------|-----------------|
| WoRMS | 분류 체계, 동의어 | 학명 검증 + 통합 보기 |
| FishBase | 성장 파라미터, 생태 정보 | 사용자 데이터와 비교 분석 |
| GBIF | 좌표, 채집 기록 | 분포 지도 + 공간 통계 |
| OBIS | 해양생물 좌표, 수심/수온 | GBIF 보완 + 해양 환경 통계 |
| NCBI Entrez | 유전자, 서열 | 서열 통계 + 다양성 지수 |
| OpenAlex | 논문 메타데이터 | 트렌드 분석 + 저자 네트워크 |
| CrossRef | DOI → 서지정보 | 인용 형식 변환 |

### 안함 (기존 도구가 이미 최고)

| 기능 | 대안 | 이유 |
|------|------|------|
| 전자실험노트 (풀) | Benchling, LabArchives | 너무 큰 범위 |
| 프로젝트 관리 | Notion, Trello | 본업 아님 |
| 서열 정렬 (BLAST) | NCBI BLAST | 재구현 불가 |
| 단백질 구조 예측 | AlphaFold | 재구현 불가 |
| 이미지 분석 (딥러닝) | ImageJ, CellProfiler | 전문 도구 존재 |
| 원고 투고 시스템 | 학회별 시스템 | 표준화 불가 |
| 시퀀싱 파이프라인 | Galaxy | 서버 필요, 범위 밖 |

---

## 8. 플랫폼 이름 후보

| 이름 | 컨셉 | 비고 |
|------|------|------|
| **BioResearch Hub** | 생물학 연구 허브 | 범용적, 확장성 |
| **AquaLab** | 수산 연구실 | 수산 특화 느낌 |
| **BioStat Toolkit** | 생물통계 도구 모음 | 통계 강조 |
| **MarineStat** | 해양 통계 | 해양 한정 |
| **FieldLab** | 현장 연구실 | 범용적 |

---

## 9. 성공 지표

| 지표 | 목표 | 측정 시점 |
|------|------|----------|
| 통계 분석 메서드 | 45+ (현재 달성) | Phase 15 시작 전 |
| 생태 분석 도구 | 5개+ (B-1~B-5) | Phase 15-1 완료 시 |
| 외부 API 연동 | 6개+ (WoRMS~CrossRef) | Phase 15-2 완료 시 |
| 논문 도구 | Methods/Results/Table 자동 생성 | Phase 15-4 완료 시 |
| 분석 히스토리 | 무제한 로컬 저장 + 검색 | Phase 15-4 완료 시 |
| API 응답 시간 | 캐시 히트 <100ms, 미스 <3초 | Phase 15-2 완료 시 |
| 오프라인 기능 | Pyodide 기반 100% 동작 | 상시 유지 |
| Cloudflare 배포 | Pages + Workers 안정 운영 | Phase 15-2 시작 전 |

---

## 10. 네트워크 효과 및 락인 전략

> 기술만으로는 차별화 유지가 어려움. AI 도구가 빠르게 진화하는 환경에서
> **네트워크 효과**와 **전환 비용(switching cost)**이 핵심 경쟁력.

### 10-1. 락인 효과 (사용자가 떠나기 어려운 이유)

| 전략 | 내용 | 전환 비용 |
|------|------|----------|
| **분석 히스토리 축적** | 모든 분석 로그가 IndexedDB에 누적 (재현 가능) | 높음: 다른 도구로 이관 불가 |
| **커스텀 벡터스토어** | 사용자가 만든 RAG DB (논문, 메모) | 높음: 재구축 비용 큼 |
| **종 정보 즐겨찾기** | 자주 조회하는 종 + 비교 데이터 | 중간: 데이터 재입력 필요 |
| **논문 템플릿 커스터마이징** | 자기 학술지/연구실 스타일 저장 | 중간: 재설정 필요 |
| **인용 라이브러리** | 누적된 DOI + 서지정보 | 중간: BibTeX export로 완화 가능 |

**핵심**: 사용할수록 **개인화된 데이터가 쌓여서** 다른 도구로 가기 어려워짐.
단, 사용자 데이터 내보내기(export)는 항상 지원해야 함 → 신뢰 = 오히려 더 오래 머무름.

### 10-2. 네트워크 효과 (사용자가 늘수록 가치 증가)

| 유형 | 전략 | 가치 증가 메커니즘 |
|------|------|------------------|
| **공유 템플릿** | 논문 보고서 템플릿을 커뮤니티에 공유 | 사용자가 많을수록 템플릿 풍부 |
| **분석 레시피** | "이 데이터 유형에는 이 분석" 레시피 공유 | 초보자 진입장벽 낮춤 |
| **수질 기준 DB** | 지역별 기준값을 사용자가 추가/검증 | 커뮤니티 기반 DB 구축 |
| **종별 성장 파라미터** | 사용자 연구 결과를 (선택적) 공유 | FishBase 보완 크라우드소싱 |
| **통계 해석 가이드** | 분야별 해석 가이드를 사용자가 기여 | "수산 분야에서 이 p-value는..." |

**참고**: 초기에는 네트워크 효과 없이도 개인 도구로서 가치가 있어야 함 (cold start 해결).

### 10-3. 시장 환경 변화 대응

| 위협 | 현재 상황 | 대응 |
|------|----------|------|
| **AI Cowork 도구** (Cursor, Claude Code 등) | R/Python 코드를 AI가 대신 작성 → 코딩 장벽 낮아짐 | 우리 강점: "코드 없이" + "워크플로우 연결" + "도메인 특화" → AI로 코드 짜는 것보다 여전히 빠름 |
| **범용 AI 어시스턴트** (ChatGPT, Claude) | "통계 분석해줘" 하면 코드 생성 | 우리 강점: 검증된 라이브러리 사용 (hallucination 없음) + 재현성 보장 + 데이터 프라이버시 |
| **기존 도구의 AI 통합** (SPSS + AI, JMP + AI) | SPSS가 AI 기능 추가할 수 있음 | 우리 강점: 무료 + 브라우저 기반 + 오프라인 가능 + 오픈 생태계 |
| **오픈소스 경쟁** (R Shiny 앱 등) | 누군가 유사 웹앱을 R Shiny로 만들 수 있음 | 우리 강점: Pyodide(서버 불필요) + 통합 플랫폼(단일 도구가 아님) |

### 10-4. 해자(Moat) 전략 — 장기 경쟁 우위

```
단기 해자 (1년):
  도메인 특화 (수산과학 용어/기준/예시) → 범용 도구가 쉽게 따라오기 어려움

중기 해자 (2-3년):
  사용자 데이터 축적 (분석 로그, 템플릿, 인용 라이브러리)
  + 커뮤니티 콘텐츠 (분석 레시피, 해석 가이드)

장기 해자 (3년+):
  네트워크 효과 (공유 템플릿, 크라우드소싱 DB)
  + 생태계 (연구실 단위 도입 → 조직 내 표준화)
  + 브랜드 신뢰 (논문에서 "BioResearch Hub를 사용하여 분석하였다" 인용)
```

**가장 강력한 락인**: 논문에 도구명이 인용되면, 같은 연구실/학회에서 자연스럽게 채택.
→ 초기 타겟: 특정 학회(한국수산과학회 등)에서 워크숍/튜토리얼 개최.

---

## 11. 리스크 및 완화

### 기술 리스크

| 리스크 | 영향 | 확률 | 완화 방안 |
|--------|------|------|----------|
| FishBase API 불안정/폐쇄 | Module A 기능 축소 | 중 | OBIS/GBIF에서 일부 보완, ropensci 대안 모니터링 |
| PySAL Pyodide 미지원 | 고급 공간통계 불가 | 높 | scipy 기반 대안 (커널밀도, 거리행렬) |
| Pyodide 메모리 한계 | 대용량 데이터 처리 불가 | 중 | 데이터 샘플링 + 경고 메시지 |
| NCBI API rate limit | 조회 속도 제한 | 낮 | API key 등록 (10req/s), 캐시 적극 활용 |
| 외부 API 스키마 변경 | 파싱 오류 | 낮 | API 응답 스키마 검증 레이어 추가 |

### 시장 리스크

| 리스크 | 영향 | 확률 | 완화 방안 |
|--------|------|------|----------|
| AI 코딩 도구가 R/Python 장벽 제거 | 우리 플랫폼 존재 이유 약화 | 중 | 워크플로우 연결 + 도메인 특화로 차별화 |
| SPSS/JMP가 AI 기능 통합 | 기존 사용자 이탈 방지 | 낮 | 무료 + 브라우저 + 오프라인 강점 유지 |
| 유사 오픈소스 등장 | 직접 경쟁 | 낮 | 선점 + 커뮤니티 + 사용자 데이터 축적 |

---

**다음 단계**:
1. Cloudflare Pages 배포 (즉시)
2. Phase 15-1 생태 분석 도구 (첫 번째 확장)
3. Phase 15-2 종 정보 허브 (외부 연결 시작)
