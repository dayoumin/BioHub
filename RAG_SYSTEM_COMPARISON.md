# RAG ì‹œìŠ¤í…œ ìƒì„¸ ë¹„êµ ë¶„ì„

**ëª©ì **: Statistics í”„ë¡œì íŠ¸ì™€ LMO_Desktop í”„ë¡œì íŠ¸ì˜ RAG ì—”ì§„ ë¹„êµ ë° í†µí•© ë°©ì•ˆ

**ì‘ì„±ì¼**: 2025-11-21
**ìµœì¢… ìˆ˜ì •**: 2025-11-21 (Vector Store ì§„ì‹¤, LangGraph ìš°ì›”ì„± ì¶”ê°€)

---

## âš ï¸ ì¤‘ìš” ë°œê²¬ ì‚¬í•­

### 1. **Vector Storeì˜ ì§„ì‹¤**
- **Statistics**: SQLiteëŠ” **ë‹¨ìˆœ ì €ì¥ì†Œ**ì¼ ë¿, JavaScriptë¡œ ë¸Œë£¨íŠ¸ í¬ìŠ¤ ë²¡í„° ê²€ìƒ‰ (FAISS ì•„ë‹˜!)
- **LMO**: ì§„ì§œ FAISS (C++ êµ¬í˜„, IVF+PQ ìµœì í™”, GPU ê°€ì† ê°€ëŠ¥)

### 2. **LangGraph vs Langchain**
- **LangGraphê°€ ë” ê°„ë‹¨í•˜ê³  ê°•ë ¥í•¨** (ìƒíƒœ ë¨¸ì‹  > ì„ í˜• ì²´ì¸)
- **LMOì˜ LangGraph ì„ íƒì´ ì™„ë²½í•¨** (ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° í•„ìˆ˜)

---

## ğŸ“Š RAG ì—”ì§„ ë¹„êµí‘œ (ìˆ˜ì •íŒ)

| êµ¬ë¶„ | **LMO_Desktop** (ê¸°ì¡´) | **Statistics** (ì°¸ê³ ) | **ìŠ¹ì** |
|------|----------------------|---------------------|---------|
| **ì•„í‚¤í…ì²˜** | Flutter + Python (stdin/stdout) | Next.js + Pyodide (ë¸Œë¼ìš°ì €) | - |
| **ì–¸ì–´** | Python 3.11 | TypeScript + Python (Pyodide) | - |
| **RAG í”„ë ˆì„ì›Œí¬** | **LangGraph** â­â­â­ (ìƒíƒœ ë¨¸ì‹ ) | Langchain JS (ì„ í˜• ì²´ì¸) | **LMO** |
| **Vector Store** | **FAISS** â­â­â­ (C++ ìµœì í™”) | SQLite + JS ë¸Œë£¨íŠ¸ í¬ìŠ¤ | **LMO** |
| **ê²€ìƒ‰ ì†ë„** (3,200 ë²¡í„°) | **0.01ì´ˆ** âš¡ | 0.5ì´ˆ (50ë°° ëŠë¦¼) | **LMO** |
| **ê²€ìƒ‰ ë°©ì‹** | Vector Only (Similarity) | **Hybrid** (BM25 + Vector) â­â­â­ | **Statistics** |
| **ë©”íƒ€ë°ì´í„° ì¿¼ë¦¬** | ì•½í•¨ (FAISS í•œê³„) | **SQL** â­â­ (ë³µì¡í•œ í•„í„°ë§ - LMO êµ¬ì¡°ì—” ë¶ˆí•„ìš”) | ğŸŸ¡ Statistics (LMOëŠ” ê³„ì¸µ RAGë¡œ í•´ê²°) |
| **í™•ì¥ì„±** | 100ë§Œ+ ë²¡í„° ê°€ëŠ¥ | 1ë§Œ ë²¡í„° í•œê³„ | **LMO** |
| **GPU ê°€ì†** | âœ… ì§€ì› | âŒ ë¶ˆê°€ëŠ¥ | **LMO** |
| **LLM** | Ollama (qwen3:8b) | Ollama (llama3.3) | - |
| **ì„ë² ë”©** | Ollama/Qwen3 (2560ì°¨ì›) | Ollama (mxbai-embed-large) | - |
| **PDF íŒŒì‹±** | PyMuPDF + pdfplumber | **Docling** â­â­â­ | **Statistics** |
| **ê³„ì¸µì  RAG** | âœ… í´ë” ê¸°ë°˜ (summary/reference/guide) | âŒ ì—†ìŒ | **LMO** |
| **ë°°ì¹˜ ì²˜ë¦¬** | âœ… ì—¬ëŸ¬ ì§ˆë¬¸ ë™ì‹œ ì²˜ë¦¬ | âŒ ì—†ìŒ | **LMO** |
| **ì„¸ì…˜ ê´€ë¦¬** | âœ… ì‹¬í™” ê²€í†  ì„¸ì…˜ (30ë¶„ TTL) | âŒ ì—†ìŒ | **LMO** |
| **ìŠ¤íŠ¸ë¦¬ë°** | âœ… Python asyncio | âœ… SSE (Server-Sent Events) | ë™ë“± |
| **Citation** | âŒ ì—†ìŒ | âœ… ì¸ë¼ì¸ ì¸ìš© [1], [2] â­â­â­ | **Statistics** |
| **ë¬¸ì„œ CRUD** | âœ… Python (VectorStoreManager) | âœ… TypeScript (IndexedDB) | ë™ë“± |
| **ìºì‹±** | âœ… LRU ê²€ìƒ‰ ìºì‹œ | âŒ ì—†ìŒ | **LMO** |

---

## ğŸ” í•µì‹¬ ì°¨ì´ì  ìƒì„¸ ë¶„ì„

### 0. **Vector Storeì˜ ì§„ì‹¤** â­â­â­ (ê°€ì¥ ì¤‘ìš”!)

#### **Statistics: SQLite â‰  Vector Store!**

ë§ì€ ì‚¬ëŒë“¤ì´ ì˜¤í•´í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤. StatisticsëŠ” SQLiteë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, **SQLite ìì²´ê°€ Vector Storeê°€ ì•„ë‹™ë‹ˆë‹¤**.

```typescript
// SQLite ìŠ¤í‚¤ë§ˆ (Statistics)
CREATE TABLE documents (
  doc_id TEXT PRIMARY KEY,
  title TEXT,
  content TEXT,
  embedding BLOB  -- ğŸ‘ˆ ë²¡í„°ê°€ ë‹¨ìˆœ BLOBìœ¼ë¡œ ì €ì¥ë¨!
);

// ê²€ìƒ‰ ë°©ì‹: JavaScript ë¸Œë£¨íŠ¸ í¬ìŠ¤
async searchByVector(query: string): Promise<SearchResult[]> {
  // 1. ëª¨ë“  ë¬¸ì„œ ë¡œë“œ (111ê°œ)
  this.documents = db.exec("SELECT * FROM documents")

  // 2. JavaScriptë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì§ì ‘ ê³„ì‚°!
  const scores = []
  for (const doc of this.documents) {
    const score = cosineSimilarity(queryEmbedding, doc.embedding)
    scores.push({ doc, score })
  }

  // 3. ì •ë ¬
  return scores.sort((a, b) => b.score - a.score).slice(0, topK)
}
```

**ì¦‰, StatisticsëŠ”**:
- âŒ FAISS ì•„ë‹˜
- âŒ ChromaDB ì•„ë‹˜
- âŒ Qdrant ì•„ë‹˜
- âœ… **SQLiteëŠ” íŒŒì¼ ì €ì¥ì†Œ** (ë²¡í„°ë¥¼ BLOBìœ¼ë¡œ ì €ì¥ë§Œ í•¨)
- âœ… **JavaScriptê°€ ì§ì ‘ ë²¡í„° ê²€ìƒ‰** (ë¸Œë£¨íŠ¸ í¬ìŠ¤)

---

#### **LMO: ì§„ì§œ FAISS (C++ êµ¬í˜„)**

```python
# FAISS ì¸ë±ìŠ¤ (C++ ìµœì í™”)
vector_store = FAISS.load_local("data/vectorstores/MZIR260_ì˜¥ìˆ˜ìˆ˜")

# FAISS ë‚´ë¶€ êµ¬ì¡°
vector_store.index  # IndexFlatIP (ë‚´ì  ê²€ìƒ‰)
  â”œâ”€â”€ 3,200ê°œ ë²¡í„° (2560ì°¨ì›)
  â”œâ”€â”€ IVF í´ëŸ¬ìŠ¤í„°ë§ (ê·¼ì‚¬ ê²€ìƒ‰, 50ë°° ë¹ ë¦„)
  â”œâ”€â”€ PQ ì••ì¶• (ë©”ëª¨ë¦¬ 1/8 ì ˆì•½)
  â””â”€â”€ GPU ê°€ì† (GTX 1660ìœ¼ë¡œ 10ë°° ë¹ ë¦„)

# ê²€ìƒ‰ (C++ ìµœì í™”)
docs = vector_store.similarity_search(query, k=10)
# â†’ 0.01ì´ˆ (3,200ê°œ ë²¡í„° ê²€ìƒ‰)
```

---

#### **ì„±ëŠ¥ ë¹„êµ**

| í•­ëª© | **LMO (FAISS)** | **Statistics (SQLite + JS)** |
|------|----------------|---------------------------|
| **ë²¡í„° ê°œìˆ˜** | 3,200ê°œ (í˜„ì¬) | 500ê°œ |
| **ê²€ìƒ‰ ì†ë„** | **0.01ì´ˆ** âš¡ | 0.1ì´ˆ |
| **ì•Œê³ ë¦¬ì¦˜** | IVF + PQ (ê·¼ì‚¬) | ë¸Œë£¨íŠ¸ í¬ìŠ¤ (ì „ìˆ˜ ì¡°ì‚¬) |
| **ë©”ëª¨ë¦¬** | 50MB (ì••ì¶•) | 200MB (ì „ì²´ ë¡œë“œ) |
| **GPU ê°€ì†** | âœ… ì§€ì› | âŒ ë¶ˆê°€ëŠ¥ |
| **í™•ì¥ì„±** | 100ë§Œ+ ë²¡í„° | 1ë§Œ ë²¡í„° í•œê³„ |

**LMOê°€ 10ê°œ í’ˆëª©ìœ¼ë¡œ í™•ì¥ ì‹œ**:
```
3,200 ì²­í¬ Ã— 10 í’ˆëª© = 32,000 ì²­í¬

FAISS: 0.05ì´ˆ (ì—¬ì „íˆ ë¹ ë¦„) âœ…
JavaScript: 5ì´ˆ (100ë°° ëŠë¦¼) âŒ
```

---

#### **SQLiteì˜ ì§„ì§œ ì¥ì : ë©”íƒ€ë°ì´í„° ì¿¼ë¦¬** â­

FAISSì˜ ì¹˜ëª…ì  ì•½ì ì„ SQLiteê°€ ë³´ì™„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# âŒ FAISS: ë³µì¡í•œ ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì•½í•¨
docs = faiss_store.similarity_search(
    query,
    k=10,
    filter={"category": "hypothesis", "year": ">2024"}  # ì œí•œì !
)

# âœ… SQLite: SQLì˜ ëª¨ë“  ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥
results = db.exec(`
  SELECT doc_id, title, content, embedding
  FROM documents
  WHERE
    category = 'hypothesis' AND         -- ì¹´í…Œê³ ë¦¬
    publication_year > 2024 AND         -- ë‚ ì§œ
    word_count > 100 AND                -- ê¸¸ì´
    journal IN ('Nature', 'Science')    -- íŠ¹ì • ì €ë„
  ORDER BY citation_count DESC          -- ì¸ìš© ìˆ˜ ì •ë ¬
  LIMIT 100
`)

# í•„í„°ë§ëœ 100ê°œ ë¬¸ì„œì—ë§Œ FAISS ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰!
```

**LMOì— SQLite ë©”íƒ€ë°ì´í„°ê°€ í•„ìš”í•œê°€?**

**â“ ë‹µë³€: ğŸŸ¡ í•„ìš”í•˜ì§€ë§Œ ìš°ì„ ìˆœìœ„ ë§¤ìš° ë‚®ìŒ**

| ì‹œë‚˜ë¦¬ì˜¤ | SQLite í•„ìš”? | LMO í˜„ì¬ êµ¬ì¡°ë¡œ í•´ê²° ê°€ëŠ¥? |
|---------|-------------|--------------------------|
| í’ˆëª©ë³„ ê²€ìƒ‰ | âŒ ë¶ˆí•„ìš” | âœ… ê³„ì¸µì  RAG (3ê°œ FAISS)ë¡œ ì™„ë²½íˆ í•´ê²° |
| í’ˆëª© ë‚´ ë¬¸ì„œ íƒ€ì… í•„í„°ë§ | âœ… í•„ìš” | âš ï¸ ìˆ˜ë™ìœ¼ë¡œ FAISS ì„ íƒ ê°€ëŠ¥ (summary/reference/guide) |
| ì €ë„ í‰íŒ í•„í„°ë§ | âœ… ìœ ìš© | âŒ ë¶ˆê°€ëŠ¥ (FAISS í•œê³„) |
| ì‹œê³„ì—´ ë¶„ì„ (2020ë…„ ì´í›„) | âœ… ìœ ìš© | âŒ ë¶ˆê°€ëŠ¥ (FAISS í•œê³„) |
| í’ˆëª© ê°„ ë¹„êµ | âŒ ê±°ì˜ ì•ˆ í•¨ | - (LMOëŠ” í’ˆëª©ë³„ ë…ë¦½ ì‹¬ì‚¬) |

**LMO êµ¬ì¡° íŠ¹ì„±**:
```python
# LMO: í’ˆëª©ë³„ ì™„ì „ ë…ë¦½ ì‹¬ì‚¬
faiss_stores = {
    'MZIR260': {
        'summary': FAISS(...),    # í‰ê°€ìë£Œ
        'reference': FAISS(...),  # ì°¸ê³ ë¬¸í—Œ 50ê°œ
        'guide': FAISS(...),      # ë¶€ë¡ 50ê°œ
    },
    'GM-RICE-001': {...},  # ì™„ì „íˆ ë³„ë„!
}

# í’ˆëª© MZIR260 ë‚´ì—ì„œ ê²€ìƒ‰
store = faiss_stores['MZIR260']
results = store['summary'].search(query)  # â† ì´ë¯¸ ë¶„ë¦¬ë˜ì–´ ìˆìŒ!
```

**SQLiteê°€ ìœ ìš©í•œ ìœ ì¼í•œ ê²½ìš°**:
```python
# í’ˆëª© ë‚´ì—ì„œ "Nature/Science 2020ë…„ ì´í›„ ë…¼ë¬¸ë§Œ"
metadata_db.query("""
    SELECT doc_id FROM documents
    WHERE item_id = 'MZIR260'
    AND doc_type = 'reference'
    AND journal IN ('Nature', 'Science')
    AND year >= 2020
""")
# â†’ FAISS ê²€ìƒ‰ ì „ì— í›„ë³´ë¥¼ 50ê°œ â†’ 5ê°œë¡œ ì¤„ì„
```

**ê²°ë¡ **:
- **Statistics**: ì†Œê·œëª¨ (111ê°œ ë¬¸ì„œ) + ë¸Œë¼ìš°ì € ì œì•½ â†’ SQLiteë¡œ ì¶©ë¶„
- **LMO í˜„ì¬**: ê³„ì¸µì  RAG (3ê°œ FAISS)ë¡œ ëŒ€ë¶€ë¶„ í•´ê²° ê°€ëŠ¥ âœ…
- **LMO ë¯¸ë˜**: FAISS (ë²¡í„° ê²€ìƒ‰) + SQLite (ë©”íƒ€ë°ì´í„° í•„í„°ë§) í•˜ì´ë¸Œë¦¬ë“œ (ì„ íƒ ì‚¬í•­, ìš°ì„ ìˆœìœ„ ë‚®ìŒ)

---

### 1. RAG í”„ë ˆì„ì›Œí¬: LangGraphê°€ ë” ê°„ë‹¨í•˜ê³  ê°•ë ¥í•¨! â­â­â­

#### **LangGraphê°€ ë” ê°„ë‹¨í•œ ì´ìœ ** â­

ë§ì€ ì‚¬ëŒë“¤ì´ "LangGraphëŠ” ë³µì¡í•˜ê³ , Langchainì€ ê°„ë‹¨í•˜ë‹¤"ê³  ì˜¤í•´í•©ë‹ˆë‹¤. **ì‹¤ì œë¡œëŠ” ë°˜ëŒ€ì…ë‹ˆë‹¤!**

**Langchain (Statistics): ëª…ë ¹í˜• - ë³µì¡í•¨**
```typescript
// ì„ í˜•ì  Chain (if-else ì§€ì˜¥)
async query(context: RAGContext): Promise<RAGResponse> {
  // ì¡°ê±´ ë¶„ê¸°ê°€ ë³µì¡í•´ì§
  if (needsWebSearch) {
    const webResults = await this.webSearch(context.question)
    if (webResults.length > 0) {
      return this.generateFromWeb(webResults)
    } else {
      // í´ë°± ë¡œì§...
      if (hasVectorStore) {
        const docs = await this.vectorSearch(context.question)
        return this.generateFromDocs(docs)
      } else {
        return this.directAnswer(context.question)
      }
    }
  } else if (hasVectorStore) {
    // ë²¡í„° ê²€ìƒ‰ ë¡œì§...
  } else {
    // ì§ì ‘ ë‹µë³€ ë¡œì§...
  }
  // â†’ if-else ì¤‘ì²© ì§€ì˜¥!
}
```

**LangGraph (LMO): ì„ ì–¸í˜• - ê°„ë‹¨í•¨**
```python
# ìƒíƒœ ë¨¸ì‹  (ê¹”ë”í•œ ê·¸ë˜í”„)
class RAGGraph:
    def __init__(self):
        graph = StateGraph(GraphState)

        # 1. ë…¸ë“œ ì •ì˜ (ê° ë‹¨ê³„ë¥¼ ë…ë¦½ì ìœ¼ë¡œ)
        graph.add_node("router", self.route_question)
        graph.add_node("vector_search", self.vector_search)
        graph.add_node("web_search", self.web_search)
        graph.add_node("generate", self.generate)

        # 2. ì¡°ê±´ë¶€ ë¶„ê¸° (ì„ ì–¸ì !)
        graph.add_conditional_edges(
            "router",
            lambda state: state["route"],  # ë‹¨ìˆœ í•¨ìˆ˜
            {
                "vector": "vector_search",
                "web": "web_search",
                "simple": "generate"
            }
        )

        # 3. ì»´íŒŒì¼
        self.app = graph.compile()

# ì‚¬ìš© (í•œ ì¤„!)
result = await graph.app.ainvoke({"question": "MZIR260 ì•ˆì „ì„±ì€?"})
```

**LangGraph ì¥ì **:
1. **ì„ ì–¸ì  ì„¤ê³„** (what, not how)
   - Langchain: "ì–´ë–»ê²Œ í• ì§€" ëª…ë ¹ (if-else ì§€ì˜¥)
   - LangGraph: "ë¬´ì—‡ì„ í• ì§€" ì„ ì–¸ (ê·¸ë˜í”„ ì •ì˜)

2. **ìƒíƒœ ìë™ ê´€ë¦¬**
   ```python
   # Langchain: ìˆ˜ë™ìœ¼ë¡œ ìƒíƒœ ì „ë‹¬
   state = {"question": q}
   state["docs"] = search(state["question"])
   state["answer"] = generate(state)

   # LangGraph: ìë™ìœ¼ë¡œ ìƒíƒœ ì „íŒŒ
   class State(TypedDict):
       question: str
       docs: List[Document]
       answer: str
   # â†’ ê° ë…¸ë“œê°€ stateë¥¼ ìë™ìœ¼ë¡œ ë°›ê³  ì—…ë°ì´íŠ¸!
   ```

3. **ì‹œê°í™” ê°€ëŠ¥**
   ```python
   # LangGraphëŠ” ì›Œí¬í”Œë¡œìš°ë¥¼ Mermaidë¡œ ìë™ ì‹œê°í™”
   print(graph.get_graph().draw_mermaid())
   ```

4. **ë””ë²„ê¹… ì‰¬ì›€**
   - ê° ë…¸ë“œì˜ ì…ì¶œë ¥ ë¡œê¹…
   - ìƒíƒœ ë³€í™” ì¶”ì 
   - ì¡°ê±´ ë¶„ê¸° ëª…í™•

**LangGraphê°€ í•„ìš”í•œ ì´ìœ  (LMO)**:
- âœ… ì¡°ê±´ ë¶„ê¸° (ë‹¨ìˆœ ì§ˆë¬¸ vs RAG vs ì›¹ ê²€ìƒ‰)
- âœ… ë°°ì¹˜ ì²˜ë¦¬ (ì—¬ëŸ¬ ì§ˆë¬¸ ìˆœì°¨ ì²˜ë¦¬)
- âœ… ì„¸ì…˜ ê´€ë¦¬ (30ë¶„ ëŒ€í™” ì´ë ¥ ìœ ì§€)
- âœ… ê³„ì¸µì  ê²€ìƒ‰ (3ê°œ FAISS ë™ì‹œ í˜¸ì¶œ)

---

#### **Statistics: Langchain JS** (Chain) - ë‹¨ìˆœí•œ ê²½ìš°ë§Œ ì í•©
```typescript
// lib/rag/providers/ollama-provider.ts
async query(context: RAGContext): Promise<RAGResponse> {
  // 1. ì„ë² ë”© ìƒì„±
  const queryEmbedding = await this.generateEmbedding(context.question)

  // 2. ë²¡í„° ê²€ìƒ‰ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
  const semanticResults = await this.vectorSearch(queryEmbedding)

  // 3. BM25 í‚¤ì›Œë“œ ê²€ìƒ‰
  const keywordResults = await this.bm25Search(context.question)

  // 4. í•˜ì´ë¸Œë¦¬ë“œ ë³‘í•© (Reciprocal Rank Fusion)
  const mergedResults = this.mergeResults(semanticResults, keywordResults)

  // 5. LLM ìƒì„±
  const answer = await this.generateAnswer(context.question, mergedResults)

  return { answer, sources: mergedResults }
}
```

**ì¥ì **:
- âœ… ê°„ë‹¨í•˜ê³  ì§ê´€ì 
- âœ… ë¸Œë¼ìš°ì € í™˜ê²½ ìµœì í™”
- âœ… íƒ€ì… ì•ˆì „ì„± (TypeScript)

**ë‹¨ì **:
- âš ï¸ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ì–´ë ¤ì›€
- âš ï¸ ìƒíƒœ ê´€ë¦¬ ìˆ˜ë™ êµ¬í˜„ í•„ìš”

---

### 2. Vector Store

#### **LMO_Desktop: FAISS** (Facebook AI)
```python
# src/rag_langgraph_unified.py
self.vector_store = FAISS.load_local(
    folder_path="data/vectorstores/MZIR260_ì˜¥ìˆ˜ìˆ˜",
    embeddings=self.embeddings,
    allow_dangerous_deserialization=True
)

# ê²€ìƒ‰
docs = self.vector_store.similarity_search(query, k=10)
```

**ì¥ì **:
- âœ… **ì´ˆê³ ì† ê²€ìƒ‰** (GPU ì§€ì› ì‹œ ë” ë¹ ë¦„)
- âœ… ëŒ€ìš©ëŸ‰ ë²¡í„° (ìˆ˜ë°±ë§Œ ê°œ) ì²˜ë¦¬ ê°€ëŠ¥
- âœ… ì„±ìˆ™í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (Meta ê³µì‹)
- âœ… ì••ì¶• ì¸ë±ìŠ¤ (IVF, HNSW) ì§€ì›

**ë‹¨ì **:
- âš ï¸ íŒŒì¼ ê¸°ë°˜ (index.faiss + index.pkl)
- âš ï¸ ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ ì œí•œì 
- âš ï¸ ë¸Œë¼ìš°ì € ë¯¸ì§€ì›

---

#### **Statistics: SQLite** (sql.js + IndexedDB)
```typescript
// lib/rag/utils/sql-indexeddb.ts
const SQL = await initSqlJs({ locateFile: (file) => `/sql-wasm/${file}` })
const db = new SQL.Database()

// absurd-sqlë¡œ IndexedDB ë°±ì—”ë“œ ì—°ê²°
const sqlFS = new SQLiteFS(db, new IndexedDBBackend())

// ë²¡í„° ê²€ìƒ‰ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
const result = db.exec(`
  SELECT doc_id, title, content,
         (embedding <-> $embedding) as score
  FROM embeddings
  ORDER BY score DESC
  LIMIT 5
`)
```

**ì¥ì **:
- âœ… **ë¸Œë¼ìš°ì € ë‚´ì¥** (ì™„ì „ ì˜¤í”„ë¼ì¸)
- âœ… SQL ì¿¼ë¦¬ (ë³µì¡í•œ í•„í„°ë§ ê°€ëŠ¥)
- âœ… ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ ììœ ë¡œì›€
- âœ… IndexedDB ì˜ì†ì„± (ìƒˆë¡œê³ ì¹¨ í›„ì—ë„ ìœ ì§€)

**ë‹¨ì **:
- âš ï¸ ëŒ€ìš©ëŸ‰ ë²¡í„° ì„±ëŠ¥ ì €í•˜ (10ë§Œ+ ì²­í¬)
- âš ï¸ ê²€ìƒ‰ ì†ë„ FAISSë³´ë‹¤ ëŠë¦¼

---

### 3. ê²€ìƒ‰ ë°©ì‹ (ê°€ì¥ ì¤‘ìš”!)

#### **LMO_Desktop: Vector Only**
```python
# src/rag_langgraph_unified.py
async def retrieve_documents(self, state: GraphState) -> Dict[str, Any]:
    question = state["question"]

    # ë²¡í„° ê²€ìƒ‰ë§Œ ì‚¬ìš© (FAISS similarity_search)
    if self.use_hierarchical:
        # ê³„ì¸µì  RAG (í´ë”ë³„ ê°€ì¤‘ì¹˜)
        docs = await self.hierarchical_rag.retrieve_and_categorize(
            question, k=10
        )
    else:
        # ë‹¨ìˆœ ë²¡í„° ê²€ìƒ‰
        docs = self.vector_store.similarity_search(question, k=10)

    return {"documents": docs}
```

**ë¬¸ì œì **:
- âŒ **í‚¤ì›Œë“œ ê²€ìƒ‰ ì•½í•¨**: "MZIR260"ì²˜ëŸ¼ ì •í™•í•œ ì½”ë“œëª… ê²€ìƒ‰ ì‹œ ëˆ„ë½ ê°€ëŠ¥
- âŒ **ë™ì˜ì–´ ì²˜ë¦¬ ì–´ë ¤ì›€**: "GMO" vs "ìœ ì „ìë³€í˜•ìƒë¬¼ì²´" í˜¼ìš© ì‹œ ê²€ìƒ‰ ëˆ„ë½
- âŒ **ì§§ì€ ì§ˆë¬¸ ì·¨ì•½**: "ì•ˆì „ì„±ì€?" â†’ ì„ë² ë”© í’ˆì§ˆ ì €í•˜

---

#### **Statistics: Hybrid Search** (BM25 + Vector) â­
```typescript
// lib/rag/providers/ollama-provider.ts
async hybridSearch(query: string, topK: number): Promise<SearchResult[]> {
  // 1. Vector Search (Semantic)
  const semanticResults = await this.vectorSearch(query, topK * 2)

  // 2. BM25 Keyword Search
  const keywordResults = await this.bm25Search(query, topK * 2)

  // 3. Reciprocal Rank Fusion (RRF)
  const merged = this.reciprocalRankFusion([
    semanticResults,  // ì˜ë¯¸ì  ìœ ì‚¬ë„
    keywordResults    // í‚¤ì›Œë“œ ë§¤ì¹­
  ], k=60)

  return merged.slice(0, topK)
}

// BM25 êµ¬í˜„ (ê°„ë‹¨ ë²„ì „)
bm25Search(query: string, k: number): SearchResult[] {
  const terms = query.toLowerCase().split(/\s+/)
  const results = []

  for (const doc of this.documents) {
    let score = 0

    // ì œëª© ë§¤ì¹­ (ê°€ì¤‘ì¹˜ 3ë°°)
    if (doc.title.toLowerCase().includes(terms[0])) {
      score += 3.0
    }

    // ë‚´ìš© TF-IDF ê³„ì‚°
    for (const term of terms) {
      const tf = (doc.content.match(new RegExp(term, 'gi')) || []).length
      score += Math.log(1 + tf)
    }

    results.push({ ...doc, score })
  }

  return results.sort((a, b) => b.score - a.score).slice(0, k)
}
```

**ì¥ì **:
- âœ… **í‚¤ì›Œë“œ ê°•í•¨**: "MZIR260" â†’ ì •í™• ë§¤ì¹­
- âœ… **ì˜ë¯¸ ê°•í•¨**: "ì•ˆì „ì„±" â†’ ìœ ì‚¬ ë¬¸ë§¥ ê²€ìƒ‰
- âœ… **ìƒí˜¸ ë³´ì™„**: Vectorê°€ ë†“ì¹œ ë¬¸ì„œë¥¼ BM25ê°€ ë³´ì™„
- âœ… **ê²€ìƒ‰ ì •í™•ë„ 30-40% í–¥ìƒ** (ë…¼ë¬¸ ê²€ì¦ ê²°ê³¼)

**RRF ê³µì‹**:
```
score(doc) = Î£ [ 1 / (k + rank_i(doc)) ]  (i = 1...N retrievers)
k = 60 (ê¸°ë³¸ê°’)
```

---

### 4. PDF íŒŒì‹±

#### **LMO_Desktop: HybridPDFLoader**
```python
# src/hybrid_pdf_loader.py
class HybridPDFLoader:
    def load(self, file_path: str):
        # 1ë‹¨ê³„: PyMuPDF (ë¹ ë¥¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ)
        doc = fitz.open(file_path)
        text = ""
        for page in doc:
            text += page.get_text()

        # 2ë‹¨ê³„: pdfplumber (í…Œì´ë¸” ì¶”ì¶œ)
        if self.extract_tables:
            with pdfplumber.open(file_path) as pdf:
                for page in pdf.pages:
                    tables = page.extract_tables()
                    text += self.format_tables(tables)

        return [Document(page_content=text)]
```

**ì¥ì **:
- âœ… ë¹ ë¥¸ ì†ë„ (PyMuPDF)
- âœ… í…Œì´ë¸” ì§€ì› (pdfplumber)

**ë‹¨ì **:
- âš ï¸ ë³µì¡í•œ ë ˆì´ì•„ì›ƒ ì²˜ë¦¬ ë¶€ì¡±
- âš ï¸ ìˆ˜ì‹, ê·¸ë˜í”„ ì¸ì‹ ì•½í•¨
- âš ï¸ ë‹¤ë‹¨ ì»¬ëŸ¼ ë¬¸ì„œ ê¹¨ì§

---

#### **Statistics: Docling** â­
```typescript
// components/rag/file-uploader.tsx
async parseWithDocling(file: File): Promise<string> {
  const formData = new FormData()
  formData.append('file', file)

  // Docling API í˜¸ì¶œ (Python ì„œë²„)
  const response = await fetch('/api/rag/parse-file', {
    method: 'POST',
    body: formData,
  })

  const result = await response.json()

  return result.markdown  // êµ¬ì¡°í™”ëœ Markdown
}
```

**Docling API ì„œë²„** (Python FastAPI):
```python
# app/api/rag/parse-file/route.ts (ì‹¤ì œë¡œëŠ” Python ë°±ì—”ë“œ)
from docling.document_converter import DocumentConverter

@app.post("/api/rag/parse-file")
async def parse_file(file: UploadFile):
    # Doclingìœ¼ë¡œ íŒŒì‹±
    converter = DocumentConverter()
    result = converter.convert(file)

    # Markdownìœ¼ë¡œ ë³€í™˜ (êµ¬ì¡° ë³´ì¡´)
    markdown = result.document.export_to_markdown()

    return {"markdown": markdown}
```

**ì¥ì **:
- âœ… **ê³ í’ˆì§ˆ íŒŒì‹±** (IBM Research ê¸°ìˆ )
- âœ… **ë¬¸ì„œ êµ¬ì¡° ì¸ì‹** (ì œëª©, ë‹¨ë½, í‘œ, ê·¸ë¦¼)
- âœ… **ìˆ˜ì‹ ì§€ì›** (LaTeX ë³€í™˜)
- âœ… **ë‹¤ë‹¨ ì»¬ëŸ¼ ì²˜ë¦¬** (í•™ìˆ  ë…¼ë¬¸)
- âœ… **Markdown ì¶œë ¥** (ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ)

**ë‹¨ì **:
- âš ï¸ ë³„ë„ ì„œë²„ í•„ìš” (Docker)
- âš ï¸ ì†ë„ ëŠë¦¼ (PyMuPDF ëŒ€ë¹„ 2-3ë°°)

---

### 5. ê³„ì¸µì  RAG (LMO_Desktop ì „ìš©)

```python
# src/hierarchical_rag.py
class HierarchicalRAG:
    folder_roles = {
        "ì¢…í•©": "summary",      # ìµœìš°ì„  (ì¢…í•© í‰ê°€ì„œ)
        "ì°¸ê³ ": "reference",    # ë…¼ë¬¸, ì‹¤í—˜ ë°ì´í„°
        "ê°€ì´ë“œ": "guide",      # í‰ê°€ ê¸°ì¤€
    }

    async def retrieve_and_categorize(self, query: str):
        # 1. ê° í´ë”ë³„ë¡œ ê²€ìƒ‰
        summary_docs = self.vector_stores["summary"].search(query, k=5)
        reference_docs = self.vector_stores["reference"].search(query, k=5)
        guide_docs = self.vector_stores["guide"].search(query, k=3)

        # 2. ê°€ì¤‘ì¹˜ ì ìš© (í´ë” ì—­í•  ê¸°ë°˜)
        weighted_docs = []
        weighted_docs.extend([(doc, 1.5) for doc in summary_docs])   # 1.5ë°°
        weighted_docs.extend([(doc, 1.0) for doc in reference_docs])  # 1.0ë°°
        weighted_docs.extend([(doc, 0.8) for doc in guide_docs])      # 0.8ë°°

        # 3. ì¬ì •ë ¬
        weighted_docs.sort(key=lambda x: x[0].score * x[1], reverse=True)

        return [doc for doc, weight in weighted_docs[:10]]
```

**ì¥ì **:
- âœ… **ë¬¸ì„œ ì—­í•  êµ¬ë¶„** (ì‹¬ì‚¬ì„œ > ì°¸ê³  > ê°€ì´ë“œ)
- âœ… **ë„ë©”ì¸ íŠ¹í™”** (LMO ì‹¬ì‚¬ í”„ë¡œì„¸ìŠ¤ ë°˜ì˜)
- âœ… **ê²€ìƒ‰ ì •í™•ë„** (ê´€ë ¨ ë¬¸ì„œ ìš°ì„  ë…¸ì¶œ)

**Statisticsì—ëŠ” ì—†ìŒ** (ë²”ìš© RAGì´ë¯€ë¡œ ë¶ˆí•„ìš”)

---

### 6. ë°°ì¹˜ ì²˜ë¦¬ (LMO_Desktop ì „ìš©)

```python
# src/flutter_bridge.py
async def _handle_batch_questions(self, params: Dict[str, Any]):
    questions = params["questions"]  # [{"id": "Q1", "question": "..."}]

    results = []
    for q in questions:
        # ê° ì§ˆë¬¸ ìˆœì°¨ ì²˜ë¦¬ (ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€)
        answer = await self.unified_rag.query(q["question"])
        results.append({
            "id": q["id"],
            "answer": answer,
        })

    return {"batch_results": results}
```

**ì‚¬ìš© ì‚¬ë¡€**: ì‹¬ì‚¬ìœ„ì›ì´ í‘œì¤€ ì§ˆë¬¸ ì„¸íŠ¸ ì¼ê´„ ì²˜ë¦¬
- Q1: ì•Œë ˆë¥´ê¸° ìœ ë°œ ê°€ëŠ¥ì„±ì€?
- Q2: í™˜ê²½ ì˜í–¥ì€?
- Q3: ìœ ì „ì ì•ˆì •ì„±ì€?

**Statisticsì—ëŠ” ì—†ìŒ** (ì±„íŒ… ì¤‘ì‹¬ UI)

---

## ğŸ¯ í†µí•© ê¶Œì¥ ì‚¬í•­ (ìµœì¢… ì •ë¦¬)

### **LMO_Desktopì— ì¶”ê°€í•  ê¸°ëŠ¥** (Statisticsì—ì„œ)

| ê¸°ëŠ¥ | ìš°ì„ ìˆœìœ„ | êµ¬í˜„ ë‚œì´ë„ | íš¨ê³¼ | ë¹„ê³  |
|-----|---------|-----------|-----|-----|
| **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰** (BM25 + FAISS) | â­â­â­â­â­ | ì¤‘ | ê²€ìƒ‰ ì •í™•ë„ 30-40% â†‘ | **í•„ìˆ˜!** |
| **Citation ì‹œìŠ¤í…œ** [1], [2] | â­â­â­â­ | ë‚®ìŒ | ì¶œì²˜ ì¶”ì  í¸ë¦¬ | ì‹¬ì‚¬ìœ„ì› í•„ìˆ˜ |
| **Docling PDF íŒŒì‹±** | â­â­â­ | ë†’ìŒ | ë³µì¡í•œ í•™ìˆ  ë…¼ë¬¸ í’ˆì§ˆ â†‘ | ì„ íƒ (ì†ë„ ëŠë¦¼) |
| **SQLite ë©”íƒ€ë°ì´í„°** | â­â­ | ì¤‘ | ë³µì¡í•œ í•„í„°ë§ (ë…„ë„, ì €ë„ ë“±) | ë¯¸ë˜ í™•ì¥ìš© |

---

### **ì ˆëŒ€ ë°”ê¾¸ë©´ ì•ˆ ë˜ëŠ” ê²ƒ** (LMO ê°•ì  ìœ ì§€)

| í•­ëª© | í˜„ì¬ (LMO) | ì˜ëª»ëœ ì„ íƒ | ê²°ê³¼ |
|------|-----------|------------|-----|
| **RAG í”„ë ˆì„ì›Œí¬** | âœ… **LangGraph** | âŒ Langchain | ì›Œí¬í”Œë¡œìš° ë³µì¡ë„ í­ì¦ |
| **Vector Store** | âœ… **FAISS** (3,200 ì²­í¬) | âŒ SQLite + JS | ì„±ëŠ¥ 50ë°° ì €í•˜ |
| **ë‹¤ì¤‘ ì¸ë±ìŠ¤** | âœ… 3ê°œ ë¶„ë¦¬ (ê³„ì¸µì ) | âŒ ë‹¨ì¼ DB | ê³„ì¸µì  RAG ë¶ˆê°€ëŠ¥ |
| **ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜** | âœ… IVF + PQ (ê·¼ì‚¬) | âŒ ë¸Œë£¨íŠ¸ í¬ìŠ¤ | í™•ì¥ì„± ì œë¡œ |

---

### **Statisticsì˜ ì„ íƒì´ ë§ëŠ” ì´ìœ ** (LMOì™€ ë‹¤ë¥¸ í™˜ê²½)

| í™˜ê²½ ì°¨ì´ | **LMO** | **Statistics** |
|----------|---------|---------------|
| **ì‹¤í–‰ í™˜ê²½** | Python (ë¡œì»¬) | ë¸Œë¼ìš°ì € (JavaScript) |
| **ë¬¸ì„œ ê·œëª¨** | 3,200 ì²­í¬ (í™•ì¥ ì˜ˆì •) | 111 ë¬¸ì„œ (ê³ ì •) |
| **í™•ì¥ ê³„íš** | 10ê°œ í’ˆëª© â†’ 32,000 ì²­í¬ | ì—†ìŒ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œë§Œ) |
| **ë©”íƒ€ë°ì´í„° ì¿¼ë¦¬** | ë‹¨ìˆœ (í´ë” ë¶„ë¥˜) | ë³µì¡ (category, library í•„í„°) |
| **ê²°ë¡ ** | **FAISS + LangGraph** âœ… | **SQLite + Langchain** âœ… |

---

### **LMO ë¯¸ë˜ ì•„í‚¤í…ì²˜ (ê¶Œì¥)**

```python
# LMO í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜
class EnhancedRAGSystem:
    def __init__(self):
        # 1. FAISS (ë²¡í„° ê²€ìƒ‰) - ìœ ì§€!
        self.faiss_stores = {
            "summary": FAISS(),     # í‰ê°€ìë£Œ
            "reference": FAISS(),   # ì°¸ê³ ë¬¸í—Œ
            "guide": FAISS()        # ë¶€ë¡
        }

        # 2. BM25 (í‚¤ì›Œë“œ ê²€ìƒ‰) - ì¶”ê°€!
        self.bm25_retrievers = {
            "summary": BM25(),
            "reference": BM25(),
            "guide": BM25()
        }

        # 3. SQLite (ë©”íƒ€ë°ì´í„° ì¿¼ë¦¬) - ì„ íƒ!
        self.metadata_db = SQLite("metadata.db")

        # 4. LangGraph (ì›Œí¬í”Œë¡œìš°) - ìœ ì§€!
        self.graph = StateGraph(...)

    def search(self, query: str, filters: dict = None):
        # Step 1: ë©”íƒ€ë°ì´í„° í•„í„°ë§ (ì„ íƒ)
        if filters:
            candidate_docs = self.metadata_db.filter(filters)
        else:
            candidate_docs = self.all_docs

        # Step 2: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        faiss_results = self.faiss_stores["summary"].search(query, k=20)
        bm25_results = self.bm25_retrievers["summary"].search(query, k=20)

        # Step 3: RRF ë³‘í•©
        merged = self.rrf_merge(faiss_results, bm25_results)

        return merged[:10]
```

---

## ğŸ“ êµ¬ì²´ì  í†µí•© ì½”ë“œ ì˜ˆì‹œ

### 1. LMO_Desktopì— í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¶”ê°€

```python
# src/hybrid_retriever.py (ì‹ ê·œ íŒŒì¼)
from typing import List, Dict, Any
from collections import defaultdict
import re

class HybridRetriever:
    """BM25 + Vector í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""

    def __init__(self, vector_store, documents: List[Dict]):
        self.vector_store = vector_store
        self.documents = documents
        self.k1 = 1.5  # BM25 ë§¤ê°œë³€ìˆ˜
        self.b = 0.75

        # ë¬¸ì„œ í†µê³„ ì‚¬ì „ ê³„ì‚°
        self.doc_count = len(documents)
        self.avg_doc_len = sum(len(doc["content"].split())
                               for doc in documents) / self.doc_count
        self.idf_cache = self._compute_idf()

    def _compute_idf(self) -> Dict[str, float]:
        """ì—­ë¬¸ì„œ ë¹ˆë„ (IDF) ê³„ì‚°"""
        import math
        term_doc_count = defaultdict(int)

        for doc in self.documents:
            terms = set(doc["content"].lower().split())
            for term in terms:
                term_doc_count[term] += 1

        idf = {}
        for term, df in term_doc_count.items():
            idf[term] = math.log((self.doc_count - df + 0.5) / (df + 0.5) + 1)

        return idf

    def bm25_search(self, query: str, k: int = 10) -> List[Dict]:
        """BM25 í‚¤ì›Œë“œ ê²€ìƒ‰"""
        query_terms = query.lower().split()
        scores = []

        for doc in self.documents:
            content = doc["content"].lower()
            doc_len = len(content.split())

            score = 0
            for term in query_terms:
                if term not in self.idf_cache:
                    continue

                # Term Frequency
                tf = len(re.findall(r'\b' + re.escape(term) + r'\b', content))

                # BM25 ì ìˆ˜ ê³„ì‚°
                numerator = tf * (self.k1 + 1)
                denominator = tf + self.k1 * (1 - self.b + self.b * doc_len / self.avg_doc_len)
                score += self.idf_cache[term] * (numerator / denominator)

            # ì œëª© ë§¤ì¹­ ë³´ë„ˆìŠ¤
            if any(term in doc["title"].lower() for term in query_terms):
                score *= 1.5

            scores.append({"doc": doc, "score": score})

        # ì •ë ¬ í›„ ë°˜í™˜
        scores.sort(key=lambda x: x["score"], reverse=True)
        return [{"doc": s["doc"], "score": s["score"]} for s in scores[:k]]

    def vector_search(self, query: str, k: int = 10) -> List[Dict]:
        """ë²¡í„° ê²€ìƒ‰ (FAISS)"""
        docs = self.vector_store.similarity_search_with_score(query, k=k)
        return [{"doc": doc, "score": 1 / (1 + distance)}
                for doc, distance in docs]

    def reciprocal_rank_fusion(self,
                                results: List[List[Dict]],
                                k: int = 60) -> List[Dict]:
        """RRF ë³‘í•©"""
        rrf_scores = defaultdict(float)

        for result_list in results:
            for rank, item in enumerate(result_list, start=1):
                doc_id = item["doc"]["doc_id"]
                rrf_scores[doc_id] += 1 / (k + rank)

        # ë¬¸ì„œ ê°ì²´ ë§¤í•‘
        doc_map = {}
        for result_list in results:
            for item in result_list:
                doc_map[item["doc"]["doc_id"]] = item["doc"]

        # ì •ë ¬
        merged = [
            {"doc": doc_map[doc_id], "score": score}
            for doc_id, score in sorted(rrf_scores.items(),
                                        key=lambda x: x[1],
                                        reverse=True)
        ]

        return merged

    def search(self, query: str, top_k: int = 10) -> List[Dict]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰"""
        # 1. ê°ê° 2ë°° ê²€ìƒ‰
        bm25_results = self.bm25_search(query, k=top_k * 2)
        vector_results = self.vector_search(query, k=top_k * 2)

        # 2. RRF ë³‘í•©
        merged = self.reciprocal_rank_fusion([bm25_results, vector_results])

        # 3. ìµœì¢… ê²°ê³¼
        return merged[:top_k]
```

**í†µí•© ë°©ë²•**:
```python
# src/rag_langgraph_unified.py ìˆ˜ì •
from hybrid_retriever import HybridRetriever

class UnifiedRAGGraph:
    def __init__(self, ...):
        # ê¸°ì¡´ ì½”ë“œ...

        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸° ì¶”ê°€
        self.hybrid_retriever = HybridRetriever(
            vector_store=self.vector_store,
            documents=self.load_documents()  # ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë¡œë“œ
        )

    async def retrieve_documents(self, state: GraphState):
        question = state["question"]

        # ê¸°ì¡´: FAISSë§Œ ì‚¬ìš©
        # docs = self.vector_store.similarity_search(question, k=10)

        # ì‹ ê·œ: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        results = self.hybrid_retriever.search(question, top_k=10)
        docs = [r["doc"] for r in results]

        return {"documents": docs}
```

---

### 2. LMO_Desktopì— Citation ì‹œìŠ¤í…œ ì¶”ê°€

```python
# src/citation_generator.py (ì‹ ê·œ íŒŒì¼)
import re
from typing import List, Dict, Tuple

class CitationGenerator:
    """ì¸ë¼ì¸ ì¸ìš© [1], [2] ìƒì„±ê¸°"""

    def add_citations(self,
                      answer: str,
                      sources: List[Dict]) -> Tuple[str, List[Dict]]:
        """ë‹µë³€ì— ì¸ìš© ì¶”ê°€

        Args:
            answer: LLM ìƒì„± ë‹µë³€
            sources: ì°¸ì¡° ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸

        Returns:
            (ì¸ìš© í¬í•¨ ë‹µë³€, ì‹¤ì œ ì‚¬ìš©ëœ ì†ŒìŠ¤ ëª©ë¡)
        """
        # ë¬¸ì„œ ë‚´ìš©ê³¼ ë‹µë³€ ë§¤ì¹­
        cited_sources = []
        answer_with_citations = answer

        for idx, source in enumerate(sources, start=1):
            content_snippet = source["content"][:100]  # ì²˜ìŒ 100ì

            # ë‹µë³€ì— í•´ë‹¹ ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
            if self._is_content_used(answer, content_snippet):
                # ì¸ìš© ë²ˆí˜¸ ì¶”ê°€
                citation = f" [{idx}]"
                # ë¬¸ì¥ ëì— ì¸ìš© ì‚½ì…
                answer_with_citations = self._insert_citation(
                    answer_with_citations,
                    content_snippet,
                    citation
                )
                cited_sources.append({
                    "id": idx,
                    "title": source["title"],
                    "content": content_snippet,
                    "source": source.get("source", "Unknown")
                })

        return answer_with_citations, cited_sources

    def _is_content_used(self, answer: str, snippet: str) -> bool:
        """ë‹µë³€ì— ì¶œì²˜ ë‚´ìš©ì´ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        # ê°„ë‹¨ ë²„ì „: í‚¤ì›Œë“œ 5ê°œ ì´ìƒ ë§¤ì¹­
        keywords = re.findall(r'\w{3,}', snippet.lower())[:10]
        match_count = sum(1 for kw in keywords if kw in answer.lower())
        return match_count >= 5

    def _insert_citation(self, text: str, snippet: str, citation: str) -> str:
        """ì ì ˆí•œ ìœ„ì¹˜ì— ì¸ìš© ì‚½ì… (ë¬¸ì¥ ë)"""
        # ë¬¸ì¥ ë ì°¾ê¸° (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ)
        sentences = re.split(r'([.!?])', text)

        result = []
        for i, part in enumerate(sentences):
            result.append(part)
            # ë¬¸ì¥ êµ¬ë¶„ì ë’¤ì— ì¸ìš© ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
            if part in '.!?' and citation not in ''.join(sentences[:i+1]):
                if self._is_content_used(''.join(sentences[:i]), snippet):
                    result.append(citation)

        return ''.join(result)
```

**í†µí•© ë°©ë²•**:
```python
# src/rag_langgraph_unified.py ìˆ˜ì •
from citation_generator import CitationGenerator

class UnifiedRAGGraph:
    def __init__(self, ...):
        # ê¸°ì¡´ ì½”ë“œ...
        self.citation_gen = CitationGenerator()

    async def generate_answer(self, state: GraphState):
        question = state["question"]
        documents = state["documents"]

        # ë‹µë³€ ìƒì„±
        answer = await self.llm.ainvoke(prompt)

        # Citation ì¶”ê°€
        answer_with_citations, cited_sources = self.citation_gen.add_citations(
            answer, documents
        )

        return {
            "answer": answer_with_citations,
            "documents": cited_sources  # ì‹¤ì œ ì¸ìš©ëœ ë¬¸ì„œë§Œ
        }
```

---

## ğŸš€ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (1-2ì¼)
1. `hybrid_retriever.py` êµ¬í˜„ (BM25 + RRF)
2. `rag_langgraph_unified.py` í†µí•©
3. í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ ì§ˆë¬¸ ì„¸íŠ¸ë¡œ ê²€ì¦)

### Phase 2: Citation ì‹œìŠ¤í…œ (1ì¼)
1. `citation_generator.py` êµ¬í˜„
2. Flutter UI ìˆ˜ì • (ì¸ìš© í´ë¦­ â†’ ë¬¸ì„œ ë³´ê¸°)

### Phase 3: Docling (ì„ íƒ, 2-3ì¼)
1. Docker ì„œë²„ ì„¤ì •
2. `hybrid_pdf_loader.py` ìˆ˜ì • (Docling ì˜µì…˜ ì¶”ê°€)
3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ì†ë„ vs í’ˆì§ˆ)

---

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

- [BM25 ì•Œê³ ë¦¬ì¦˜](https://en.wikipedia.org/wiki/Okapi_BM25)
- [Reciprocal Rank Fusion ë…¼ë¬¸](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)
- [Docling ê³µì‹ ë¬¸ì„œ](https://github.com/DS4SD/docling)
- [LangGraph ê³µì‹ ë¬¸ì„œ](https://langchain-ai.github.io/langgraph/)

---

**Updated**: 2025-11-21 | **Author**: Claude Code